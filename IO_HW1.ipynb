{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1m9HGKxZ-IvoZk4VIr2lPHXOgv49F8zxR",
      "authorship_tag": "ABX9TyOoyT8g5+yVKn+R5JbKw7Ke",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaheePark0415/Econ512-Fall2024/blob/main/IO_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Probome 1(a). Multinomial Logit"
      ],
      "metadata": {
        "id": "CyS34q2L_Ol3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from statsmodels.sandbox.regression.gmm import IV2SLS\n",
        "from scipy.optimize import fsolve\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "data = pd.read_csv('product_data.csv')"
      ],
      "metadata": {
        "id": "Zh44ZMWEuxu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of consumers in each market\n",
        "M_t = 100000\n",
        "\n",
        "# Compute the share of the outside option (assuming it’s 1 minus the total share of soft drinks)\n",
        "total_share = data.groupby('t')['market_share'].sum()\n",
        "data = data.merge(total_share.rename('total_share'), on='t')\n",
        "data['outside_share'] = 1 - data['total_share']\n",
        "\n",
        "# Log of market share relative to the outside option's share\n",
        "data['log_share'] = np.log(data['market_share']) - np.log(data['outside_share'])\n",
        "\n",
        "# Define independent variables (price, sugar, caffeine, Diet, Regular)\n",
        "# Create dummy variables based on the 'nest' variable\n",
        "\n",
        "data['diet_d'] = np.where(data['nest'] == 'Diet', 1, 0)  # 1 if Diet, 0 otherwise\n",
        "data['regular_d'] = np.where(data['nest'] == 'Regular', 1, 0)  # 1 if Regular, 0 otherwise\n",
        "X = data[['price', 'sugar', 'caffeine', 'diet_d', 'regular_d']]\n",
        "\n",
        "# The dependent variable is the log difference between market share and outside share\n",
        "y = data['log_share']\n",
        "\n",
        "# Perform OLS regression\n",
        "ols_model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the summary of the OLS regression\n",
        "print(ols_model.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YsqiUymcuHf",
        "outputId": "6febae39-4cb1-4a2c-84e3-ab3c0df2e404"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              log_share   R-squared:                       0.885\n",
            "Model:                            OLS   Adj. R-squared:                  0.884\n",
            "Method:                 Least Squares   F-statistic:                     1912.\n",
            "Date:                Sun, 22 Sep 2024   Prob (F-statistic):               0.00\n",
            "Time:                        22:00:46   Log-Likelihood:                -1305.2\n",
            "No. Observations:                1000   AIC:                             2620.\n",
            "Df Residuals:                     995   BIC:                             2645.\n",
            "Df Model:                           4                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "price         -1.6261      0.021    -77.352      0.000      -1.667      -1.585\n",
            "sugar          1.5281      0.041     37.444      0.000       1.448       1.608\n",
            "caffeine       1.4458      0.029     50.517      0.000       1.390       1.502\n",
            "diet_d        -2.4406      0.149    -16.422      0.000      -2.732      -2.149\n",
            "regular_d     -6.6921      0.245    -27.269      0.000      -7.174      -6.211\n",
            "==============================================================================\n",
            "Omnibus:                        1.109   Durbin-Watson:                   1.901\n",
            "Prob(Omnibus):                  0.574   Jarque-Bera (JB):                1.172\n",
            "Skew:                          -0.048   Prob(JB):                        0.557\n",
            "Kurtosis:                       2.862   Cond. No.                         63.3\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(b)."
      ],
      "metadata": {
        "id": "rKSIE5yrABfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install linearmodels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5oGAFFL0qeD",
        "outputId": "1a74d3ea-3fe2-437d-de5a-4661ee7c372d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting linearmodels\n",
            "  Downloading linearmodels-6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (2.1.4)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (0.14.3)\n",
            "Collecting mypy-extensions>=0.4 (from linearmodels)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: Cython>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (3.0.11)\n",
            "Collecting pyhdfe>=0.1 (from linearmodels)\n",
            "  Downloading pyhdfe-0.2.0-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting formulaic>=1.0.0 (from linearmodels)\n",
            "  Downloading formulaic-1.0.2-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting setuptools-scm<9.0.0,>=8.0.0 (from setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels)\n",
            "  Downloading setuptools_scm-8.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic>=1.0.0->linearmodels)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=1.0.0->linearmodels) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=1.0.0->linearmodels) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->linearmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->linearmodels) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->linearmodels) (2024.1)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (24.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (71.0.4)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (2.0.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.0->linearmodels) (0.5.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.13.0->linearmodels) (1.16.0)\n",
            "Downloading linearmodels-6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading formulaic-1.0.2-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading pyhdfe-0.2.0-py3-none-any.whl (19 kB)\n",
            "Downloading setuptools_scm-8.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: setuptools-scm, mypy-extensions, interface-meta, pyhdfe, formulaic, linearmodels\n",
            "Successfully installed formulaic-1.0.2 interface-meta-1.3.0 linearmodels-6.0 mypy-extensions-1.0.0 pyhdfe-0.2.0 setuptools-scm-8.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from linearmodels.iv import IV2SLS\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "df = pd.read_csv('product_data.csv')\n",
        "\n",
        "# Step 2: Compute the share of the outside option\n",
        "total_share = df.groupby('t')['market_share'].sum()\n",
        "df = df.merge(total_share.rename('total_share'), on='t')\n",
        "df['outside_share'] = 1 - df['total_share']\n",
        "\n",
        "# Step 3: Compute log of market share relative to the outside option's share\n",
        "df['log_share'] = np.log(df['market_share']) - np.log(df['outside_share'])\n",
        "\n",
        "# Step 4: Create dummy variables for Diet and Regular\n",
        "df['Diet'] = (df['nest'] == 'Diet').astype(int)\n",
        "df['Regular'] = (df['nest'] == 'Regular').astype(int)\n",
        "\n",
        "# Step 5: Create the instrument variables (caffeine extract price * caffeine, corn syrup price * sugar)\n",
        "df['instr_caffeine_price'] = df['caffeine_extract_price'] * df['caffeine']\n",
        "df['instr_sugar_price'] = df['corn_syrup_price'] * df['sugar']\n",
        "\n",
        "# Step 6: Exogenous variables (excluding price)\n",
        "exog = df[['sugar', 'caffeine', 'Diet', 'Regular']]\n",
        "\n",
        "# Step 7: Endogenous variable (price)\n",
        "endog = df['price']\n",
        "\n",
        "# Step 8: Instruments\n",
        "instruments = df[['instr_caffeine_price', 'instr_sugar_price']]\n",
        "\n",
        "# Step 9: Dependent variable (log of market share)\n",
        "dependent = df['log_share']\n",
        "\n",
        "# Step 10: Run the IV2SLS regression\n",
        "iv_model = IV2SLS(dependent, exog, endog=endog, instruments=instruments)\n",
        "iv_results = iv_model.fit()\n",
        "\n",
        "# Step 11: Print the regression summary\n",
        "print(iv_results.summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAHeSqfKde_Z",
        "outputId": "063956d3-ac11-45d0-cbc7-27f8c7c71ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          IV-2SLS Estimation Summary                          \n",
            "==============================================================================\n",
            "Dep. Variable:              log_share   R-squared:                      0.8459\n",
            "Estimator:                    IV-2SLS   Adj. R-squared:                 0.8453\n",
            "No. Observations:                1000   F-statistic:                    6241.0\n",
            "Date:                Sun, Sep 22 2024   P-value (F-stat)                0.0000\n",
            "Time:                        22:20:54   Distribution:                  chi2(5)\n",
            "Cov. Estimator:                robust                                         \n",
            "                                                                              \n",
            "                             Parameter Estimates                              \n",
            "==============================================================================\n",
            "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "------------------------------------------------------------------------------\n",
            "sugar          1.3486     0.1272     10.599     0.0000      1.0992      1.5979\n",
            "caffeine       1.3318     0.0846     15.742     0.0000      1.1660      1.4976\n",
            "Diet          -2.6493     0.2315    -11.445     0.0000     -3.1031     -2.1956\n",
            "Regular       -6.5599     0.4277    -15.339     0.0000     -7.3981     -5.7217\n",
            "price         -1.2405     0.2109    -5.8817     0.0000     -1.6538     -0.8271\n",
            "==============================================================================\n",
            "\n",
            "Endogenous: price\n",
            "Instruments: instr_caffeine_price, instr_sugar_price\n",
            "Robust Covariance (Heteroskedastic)\n",
            "Debiased: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1(b) involves addressing endogeneity in the price variable. In the given context, the price of soft drinks is correlated with unobserved quality (𝜉𝑗𝑡​). This means that standard OLS estimators would be biased. To solve this issue, we can use instrumental variables (IV) for the price.\n",
        "\n",
        "In this problem, the suggested instruments are:\n",
        "\n",
        "Caffeine Extract Price and Corn Syrup Price.\n",
        "\n",
        "These instruments are used because they affect the price but are not directly related to the unobserved demand shock (𝜉𝑗𝑡).\n",
        "\n",
        "Approach:\n",
        "Two-Stage Least Squares (2SLS): First, we will regress the endogenous variable (price) on the instruments to get the predicted prices. Then, we will use these predicted prices in the utility function to estimate the parameters.\n",
        "\n",
        "Conditions for Valid Instruments:\n",
        "\n",
        "Relevance: The instruments must be correlated with the endogenous variable (price).\n",
        "Exogeneity: The instruments must not be correlated with the error term (unobserved quality 𝜉𝑗𝑡)."
      ],
      "metadata": {
        "id": "qARqa4rdA4j3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(c)"
      ],
      "metadata": {
        "id": "IYSUtu43CGxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "roblem 1(c) involves calculating the own-price derivatives and own-price elasticities for the products. These derivatives and elasticities are important for understanding how the market share of each product responds to changes in its own price."
      ],
      "metadata": {
        "id": "FPMNNc_PCoRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already run the IV2SLS regression from 1(b) and stored the result in `iv_results`\n",
        "\n",
        "# Step 1: Extract alpha from the model results (assuming price is the first coefficient)\n",
        "alpha_est = iv_results.params['price']  # Extracting the estimated alpha (price coefficient)\n",
        "\n",
        "# Step 2: Define function to calculate own-price derivatives\n",
        "def own_price_derivative(alpha, market_share):\n",
        "    return alpha * market_share * (1 - market_share)\n",
        "\n",
        "# Step 3: Define function to calculate own-price elasticity\n",
        "def own_price_elasticity(alpha, price, market_share):\n",
        "    return own_price_derivative(alpha, market_share) * (price / market_share)\n",
        "\n",
        "# Step 4: Calculate own-price derivatives and elasticities for each product in each time period\n",
        "df['own_price_derivative'] = own_price_derivative(alpha_est, df['market_share'])\n",
        "df['own_price_elasticity'] = own_price_elasticity(alpha_est, df['price'], df['market_share'])\n",
        "\n",
        "# Step 5: Print the mean own-price elasticity for Regular and Diet drinks\n",
        "mean_elasticity_diet = df[df['nest'] == 'Diet']['own_price_elasticity'].mean()\n",
        "mean_elasticity_regular = df[df['nest'] != 'Diet']['own_price_elasticity'].mean()\n",
        "\n",
        "print(f\"Mean Own-Price Elasticity for Diet Drinks: {mean_elasticity_diet}\")\n",
        "print(f\"Mean Own-Price Elasticity for Regular Drinks: {mean_elasticity_regular}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUTyZ-J3C-Ot",
        "outputId": "7f8cb19c-7346-4976-8e64-4a1a97b09df9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Own-Price Elasticity for Diet Drinks: -2.6161781263506434\n",
            "Mean Own-Price Elasticity for Regular Drinks: -3.694776567854777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(d)."
      ],
      "metadata": {
        "id": "enRE8VmmDLLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iSeRC_qeDqH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming you have already run the IV2SLS model from 1(b) and extracted alpha\n",
        "alpha_est = iv_results.params['price']  # Replace with the estimated alpha\n",
        "\n",
        "# Function to calculate cross-price derivatives\n",
        "def cross_price_derivative(alpha, market_share_j, market_share_1):\n",
        "    return -alpha * market_share_j * market_share_1\n",
        "\n",
        "# Function to calculate cross-price elasticity\n",
        "def cross_price_elasticity(alpha, price_1, market_share_j, market_share_1):\n",
        "    derivative = cross_price_derivative(alpha, market_share_j, market_share_1)\n",
        "    return derivative * (price_1 / market_share_j)\n",
        "\n",
        "# Step 1: Get market share and price for product 1\n",
        "product_1_price = df.loc[df['product_ID'] == 1, 'price'].values[0]\n",
        "product_1_share = df.loc[df['product_ID'] == 1, 'market_share'].values[0]\n",
        "\n",
        "# Step 2: Calculate cross-price elasticities for all products j ≠ 1\n",
        "df['cross_price_elasticity'] = df.apply(\n",
        "    lambda row: cross_price_elasticity(alpha_est, product_1_price, row['market_share'], product_1_share)\n",
        "    if row['product_ID'] != 1 else np.nan, axis=1)\n",
        "\n",
        "# Step 3: Calculate the mean cross-price elasticity for Diet and Regular drinks\n",
        "mean_cross_elasticity_diet = df[df['nest'] == 'Diet']['cross_price_elasticity'].mean()\n",
        "mean_cross_elasticity_regular = df[df['nest'] == 'Regular']['cross_price_elasticity'].mean()\n",
        "\n",
        "# Step 4: Print the results\n",
        "print(f\"Mean Cross-Price Elasticity between Product 1 and Diet Drinks: {mean_cross_elasticity_diet}\")\n",
        "print(f\"Mean Cross-Price Elasticity between Product 1 and Regular Drinks: {mean_cross_elasticity_regular}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSS71s9EDSt8",
        "outputId": "11240734-b07e-4783-cc9b-50d9f43170e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Cross-Price Elasticity between Product 1 and Diet Drinks: 0.388009376587693\n",
            "Mean Cross-Price Elasticity between Product 1 and Regular Drinks: 0.388009376587693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(e)."
      ],
      "metadata": {
        "id": "NuzDBYEZD5ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Problem* 1(e) involves writing a function to generate the Jacobian matrix of price derivatives for a given time period. This matrix, Δ(p), contains the derivatives of the market shares of all products with respect to the prices of all products in the same time period.\n",
        "\n",
        "Jacobian Matrix of Price Derivatives\n",
        "The Jacobian matrix Δ(p) is a square matrix where each element Δ𝑖𝑗 is the derivative of the market share of product 𝑗j with respect to the price of product 𝑖:\n",
        "\n",
        "The diagonal elements\n",
        "Δ𝑗𝑗  are the own-price derivatives:\n",
        "Δ𝑗𝑗=∂𝑠𝑗/∂𝑝𝑗=-α⋅sj​ ⋅(1−sj)j\n",
        "\n",
        "The off-diagonal elements\n",
        "Δ𝑖𝑗   are the cross-price derivatives:\n",
        "Δ𝑖𝑗=∂𝑠𝑗∂𝑝𝑖=−α⋅sj​ ⋅si​ for i!=j\n"
      ],
      "metadata": {
        "id": "rG9akDAfD-5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " import numpy as np\n",
        "import pandas as pd\n",
        "from linearmodels.iv import IV2SLS\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "df = pd.read_csv('product_data.csv')\n",
        "\n",
        "# Step 2: Create 'diet' and 'regular' dummy variables from the 'nest' column\n",
        "df['diet'] = df['nest'].apply(lambda x: 1 if x == 'Diet' else 0)\n",
        "df['regular'] = df['nest'].apply(lambda x: 1 if x == 'Regular' else 0)\n",
        "\n",
        "# Step 3: Compute market shares for Diet, Regular, and Outside\n",
        "df['outside_share'] = 1 - df.groupby('t')['market_share'].transform('sum')  # Share of the outside good\n",
        "\n",
        "# Step 4: Compute log(s_j) - log(s_0) as the dependent variable\n",
        "df['log_share_diff'] = np.log(df['market_share']) - np.log(df['outside_share'])\n",
        "\n",
        "# Compute log(s_j|g) (within-group market share, long_s_group)\n",
        "df['nest_total_share'] = df.groupby(['nest', 't'])['market_share'].transform('sum')\n",
        "df['log_within_group_share'] = np.log(df['market_share']) - np.log(df['nest_total_share'])\n",
        "\n",
        "# Step 5: Define the exogenous variables (sugar, caffeine, diet, regular, log_within_group_share)\n",
        "exog = df[['sugar', 'caffeine', 'diet', 'regular', 'log_within_group_share']]\n",
        "\n",
        "# Step 6: Define the endogenous variable (price) and instruments (caffeine extract price, corn syrup price)\n",
        "endog = df['price']\n",
        "instruments = df[['caffeine_extract_price', 'corn_syrup_price']]\n",
        "\n",
        "# Step 7: Run the IV2SLS regression\n",
        "iv_model = IV2SLS(dependent=df['log_share_diff'], exog=exog, endog=endog, instruments=instruments)\n",
        "iv_results = iv_model.fit()\n",
        "\n",
        "# Step 8: Print the regression results\n",
        "print(iv_results.summary)\n",
        "\n",
        "# Step 9: Check the impact on coefficients after re-estimation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNJwxxaMD9E8",
        "outputId": "d9b43641-9fd2-4aae-cbf6-79eaa7976cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          IV-2SLS Estimation Summary                          \n",
            "==============================================================================\n",
            "Dep. Variable:         log_share_diff   R-squared:                      0.9937\n",
            "Estimator:                    IV-2SLS   Adj. R-squared:                 0.9936\n",
            "No. Observations:                1000   F-statistic:                 2.472e+05\n",
            "Date:                Mon, Sep 23 2024   P-value (F-stat)                0.0000\n",
            "Time:                        02:27:34   Distribution:                  chi2(6)\n",
            "Cov. Estimator:                robust                                         \n",
            "                                                                              \n",
            "                                   Parameter Estimates                                    \n",
            "==========================================================================================\n",
            "                        Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "------------------------------------------------------------------------------------------\n",
            "sugar                      0.3856     0.0866     4.4556     0.0000      0.2160      0.5553\n",
            "caffeine                   0.3953     0.0761     5.1958     0.0000      0.2462      0.5443\n",
            "diet                       2.5427     0.3240     7.8476     0.0000      1.9076      3.1777\n",
            "regular                    1.9371     0.5894     3.2868     0.0010      0.7820      3.0922\n",
            "log_within_group_share     0.7820     0.0521     15.021     0.0000      0.6800      0.8841\n",
            "price                     -0.3914     0.1017    -3.8491     0.0001     -0.5907     -0.1921\n",
            "==========================================================================================\n",
            "\n",
            "Endogenous: price\n",
            "Instruments: caffeine_extract_price, corn_syrup_price\n",
            "Robust Covariance (Heteroskedastic)\n",
            "Debiased: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2(a). Nested Logit"
      ],
      "metadata": {
        "id": "K0rNAO5mgyaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Estimating Equation for the Nested Logit Model (2a)\n",
        "The estimating equation for the nested logit model is:\n",
        "\n",
        "  $log𝑠_{jt}−log𝑠_0 = \\alpha p_{jt} + \\beta_1 sug_{jt} + \\beta_2 𝑐𝑎𝑓_{𝑗𝑡} + \\gamma_d 𝐷𝑖𝑒𝑡_{𝑗} + \\gamma_r 𝑅𝑒𝑔𝑢𝑙𝑎𝑟_{𝑗} + \\sigma log 𝑠_{𝑗𝑡/𝑔} + \\xi_{𝑗𝑡}$\n",
        "\n",
        "2.  Instruments Needed to Estimate the Model\n",
        "In nested logit models, price 𝑝𝑗𝑡 is potentially endogenous, meaning it could be correlated with unobserved characteristics like 𝜉𝑗𝑡 (unobserved product quality), leading to biased estimates. To address this, we need instrumental variables (IV) that are:\n",
        "\n",
        "Correlated with price (relevance condition).\n",
        "Uncorrelated with unobserved product quality 𝜉𝑗𝑡(exogeneity condition).\n",
        "Instruments for Price:\n",
        "Caffeine Extract Price: The price of caffeine extract affects the cost of producing caffeinated products, which in turn influences the price of the final product. However, it is unlikely to directly affect consumer demand beyond its influence on price.\n",
        "Corn Syrup Price: Similarly, the cost of corn syrup influences the price of products, especially regular sodas, without directly influencing consumer preferences beyond its impact on price.\n",
        "These two instruments are appropriate because they affect price but are unlikely to be correlated with unobserved demand shocks (𝜉𝑗𝑡)."
      ],
      "metadata": {
        "id": "dlJMiT4j2BYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install linearmodels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miv4KG6UL4zr",
        "outputId": "50844044-48dc-4907-e32f-4ca0fb00263b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: linearmodels in /usr/local/lib/python3.10/dist-packages (6.0)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (2.1.4)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (0.14.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.4 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (1.0.0)\n",
            "Requirement already satisfied: Cython>=3.0.10 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (3.0.11)\n",
            "Requirement already satisfied: pyhdfe>=0.1 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (0.2.0)\n",
            "Requirement already satisfied: formulaic>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from linearmodels) (1.0.2)\n",
            "Requirement already satisfied: setuptools-scm<9.0.0,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (8.1.0)\n",
            "Requirement already satisfied: interface-meta>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=1.0.0->linearmodels) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=1.0.0->linearmodels) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.10/dist-packages (from formulaic>=1.0.0->linearmodels) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->linearmodels) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->linearmodels) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.4.0->linearmodels) (2024.1)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (24.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (71.0.4)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from setuptools-scm<9.0.0,>=8.0.0->setuptools-scm[toml]<9.0.0,>=8.0.0->linearmodels) (2.0.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.0->linearmodels) (0.5.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.6->statsmodels>=0.13.0->linearmodels) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " import numpy as np\n",
        "import pandas as pd\n",
        "from linearmodels.iv import IV2SLS\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "df = pd.read_csv('product_data.csv')\n",
        "\n",
        "# Step 2: Create 'diet' and 'regular' dummy variables from the 'nest' column\n",
        "df['diet'] = df['nest'].apply(lambda x: 1 if x == 'Diet' else 0)\n",
        "df['regular'] = df['nest'].apply(lambda x: 1 if x == 'Regular' else 0)\n",
        "\n",
        "# Step 3: Compute market shares for Diet, Regular, and Outside\n",
        "df['outside_share'] = 1 - df.groupby('t')['market_share'].transform('sum')  # Share of the outside good\n",
        "\n",
        "# Step 4: Compute log(s_j) - log(s_0) as the dependent variable\n",
        "df['log_share_diff'] = np.log(df['market_share']) - np.log(df['outside_share'])\n",
        "\n",
        "# Compute log(s_j|g) (within-group market share, long_s_group)\n",
        "df['nest_total_share'] = df.groupby(['nest', 't'])['market_share'].transform('sum')\n",
        "df['log_within_group_share'] = np.log(df['market_share']) - np.log(df['nest_total_share'])\n",
        "\n",
        "# Step 5: Define the exogenous variables (sugar, caffeine, diet, regular, log_within_group_share)\n",
        "exog = df[['sugar', 'caffeine', 'diet', 'regular', 'log_within_group_share']]\n",
        "\n",
        "# Step 6: Define the endogenous variable (price) and instruments (caffeine extract price, corn syrup price)\n",
        "endog = df['price']\n",
        "instruments = df[['caffeine_extract_price', 'corn_syrup_price']]\n",
        "\n",
        "# Step 7: Run the IV2SLS regression\n",
        "iv_model = IV2SLS(dependent=df['log_share_diff'], exog=exog, endog=endog, instruments=instruments)\n",
        "iv_results = iv_model.fit()\n",
        "\n",
        "# Step 8: Print the regression results\n",
        "print(iv_results.summary)\n",
        "\n",
        "# Step 9: Check the impact on coefficients after re-estimation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VEtN6l9r-aS",
        "outputId": "88b2a150-3f2e-416a-a42d-d33f5b79a7e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                          IV-2SLS Estimation Summary                          \n",
            "==============================================================================\n",
            "Dep. Variable:         log_share_diff   R-squared:                      0.9937\n",
            "Estimator:                    IV-2SLS   Adj. R-squared:                 0.9936\n",
            "No. Observations:                1000   F-statistic:                 2.472e+05\n",
            "Date:                Mon, Sep 23 2024   P-value (F-stat)                0.0000\n",
            "Time:                        02:28:02   Distribution:                  chi2(6)\n",
            "Cov. Estimator:                robust                                         \n",
            "                                                                              \n",
            "                                   Parameter Estimates                                    \n",
            "==========================================================================================\n",
            "                        Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
            "------------------------------------------------------------------------------------------\n",
            "sugar                      0.3856     0.0866     4.4556     0.0000      0.2160      0.5553\n",
            "caffeine                   0.3953     0.0761     5.1958     0.0000      0.2462      0.5443\n",
            "diet                       2.5427     0.3240     7.8476     0.0000      1.9076      3.1777\n",
            "regular                    1.9371     0.5894     3.2868     0.0010      0.7820      3.0922\n",
            "log_within_group_share     0.7820     0.0521     15.021     0.0000      0.6800      0.8841\n",
            "price                     -0.3914     0.1017    -3.8491     0.0001     -0.5907     -0.1921\n",
            "==========================================================================================\n",
            "\n",
            "Endogenous: price\n",
            "Instruments: caffeine_extract_price, corn_syrup_price\n",
            "Robust Covariance (Heteroskedastic)\n",
            "Debiased: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2(b)."
      ],
      "metadata": {
        "id": "i1xyk_8yLBim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\frac{\\partial s_{jt}}{\\partial p_{jt}} = \\frac{\\alpha}{1-\\sigma}s_{jt}(1-\\sigma\\bar{s}_{jt|g}){s_{g}}+{\\alpha}s^2_{jt|g}{s_{g}}(1-{s_{g}})$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial s_{jt}}{\\partial p_{jt}} \\frac{p_{jt}}{s_{jt}} = \\frac{\\alpha}{1-\\sigma}p_{jt}(1-\\bar{s}_{jt|g})+{\\alpha}p_{jt}\\bar{s}_{jt|g}(1-s_{g})\\\n",
        "$$"
      ],
      "metadata": {
        "id": "CHj87hCl8Gw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "df = pd.read_csv('product_data.csv')\n",
        "\n",
        "# Step 2: Use the estimated alpha and sigma from 2(a)\n",
        "alpha_est = iv_results.params['price']  # Price sensitivity parameter from the IV2SLS model\n",
        "sigma_est = iv_results.params['log_within_group_share'] # Example value for sigma, replace this with the actual nesting parameter estimate\n",
        "\n",
        "# Step 3: Calculate the within-group market share (s_{jt|g}) for each product\n",
        "df['within_group_share'] = df['market_share'] / df.groupby(['nest','t'])['market_share'].transform('sum')\n",
        "\n",
        "# Step 4: Define the function to calculate own-price elasticities (based on your provided formula)\n",
        "def own_price_elasticity(alpha, sigma, price, within_group_share, group_share):\n",
        "    term1 = (alpha / (1 - sigma)) * price * (1 - within_group_share)\n",
        "    term2 = alpha * price * within_group_share * (1 - group_share)\n",
        "    return term1 + term2\n",
        "\n",
        "# Step 5: Calculate group share (s_g) for each nest (Diet or Regular)\n",
        "df['group_share'] = df.groupby(['nest', 't'])['market_share'].transform('sum')\n",
        "\n",
        "# Step 6: Apply the function to calculate own-price elasticities (nested logit)\n",
        "df['own_price_elasticity'] = df.apply(lambda row: own_price_elasticity(alpha_est, sigma_est, row['price'], row['within_group_share'], row['group_share']), axis=1)\n",
        "\n",
        "# Step 7: Calculate the mean own-price elasticity for Regular and Diet drinks\n",
        "mean_elasticity_diet = df[df['nest'] == 'Diet']['own_price_elasticity'].mean()\n",
        "mean_elasticity_regular = df[df['nest'] == 'Regular']['own_price_elasticity'].mean()\n",
        "\n",
        "# Step 8: Print the results\n",
        "print(f\"Mean Own-Price Elasticity for Diet Drinks: {mean_elasticity_diet}\")\n",
        "print(f\"Mean Own-Price Elasticity for Regular Drinks: {mean_elasticity_regular}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7t5HLgVRgP38",
        "outputId": "d695ec6b-0452-409c-f5d3-716e808f31fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Own-Price Elasticity for Diet Drinks: -3.3423677095850364\n",
            "Mean Own-Price Elasticity for Regular Drinks: -4.990425307611291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2(c)."
      ],
      "metadata": {
        "id": "AdVI0_RbMerR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 (c)\n",
        "\n",
        "\n",
        "Case (1) the other product is in the same group:\n",
        "$$\n",
        "\\frac{\\partial s_{jt}}{\\partial p_{kt}} = -\\alpha s_{jt} (s_{kt} + \\frac{\\sigma}{1-\\sigma}\\bar{s}_{kt|g})\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial s_{jt}}{\\partial p_{kt}} \\frac{p_{kt}}{s_{jt}} = -\\alpha s_{kt} (s_{jt} + \\frac{\\sigma}{1-\\sigma}\\bar{s}_{jt|g}) \\frac{p_{kt}}{s_{kt}}\n",
        "$$\n",
        "\n",
        "Case (2) the other product is in a different group:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial s_{jt}}{\\partial p_{kt}} = - \\alpha s_{jt|g} s_g s_{jt|k} s_i = -\\alpha s_{jt} s_{kt}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial s_{jt}}{\\partial p_{kt}} \\frac{p_{kt}}{s_{jt}} = -\\alpha p_{kt} s_{kt}\n",
        "$$"
      ],
      "metadata": {
        "id": "oyvTBYduBTpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the dataset\n",
        "df = pd.read_csv('product_data.csv')\n",
        "\n",
        "# Step 2: Use the estimated alpha and sigma from 2(a)\n",
        "alpha_est = iv_results.params['price']  # Price sensitivity parameter from the IV2SLS model\n",
        "sigma_est = iv_results.params['log_within_group_share']  # Replace with the actual sigma value if different\n",
        "\n",
        "# Step 3: Calculate the within-group market share (s_{jt|g}) for each product\n",
        "df['within_group_share'] = df['market_share'] / df.groupby('nest')['market_share'].transform('sum')\n",
        "\n",
        "# Step 4: Define the function for same-group cross-price elasticities\n",
        "def cross_price_elasticity_same_group(alpha, sigma, price_k, share_j, share_k, within_group_share_j):\n",
        "    return -alpha * share_k * (share_j + (sigma / (1 - sigma)) * within_group_share_j) * (price_k / share_k)\n",
        "\n",
        "# Define the function for different-group cross-price elasticities\n",
        "def cross_price_elasticity_different_group(alpha, price_k, share_j, share_k):\n",
        "    return -alpha * price_k * share_k\n",
        "\n",
        "# Step 5: Get product 1 information (price, market share, group info)\n",
        "product_1_price = df.loc[df['product_ID'] == 1, 'price'].values[0]\n",
        "product_1_share = df.loc[df['product_ID'] == 1, 'market_share'].values[0]\n",
        "product_1_within_group_share = df.loc[df['product_ID'] == 1, 'within_group_share'].values[0]\n",
        "product_1_nest = df.loc[df['product_ID'] == 1, 'nest'].values[0]\n",
        "\n",
        "# Step 6: Apply cross-price elasticity formulas based on whether products are in the same group or not\n",
        "df['cross_price_elasticity'] = df.apply(\n",
        "    lambda row: cross_price_elasticity_same_group(alpha_est, sigma_est, product_1_price, row['market_share'], product_1_share, row['within_group_share'])\n",
        "    if row['nest'] == product_1_nest and row['product_ID'] != 1\n",
        "    else (cross_price_elasticity_different_group(alpha_est, product_1_price, row['market_share'], product_1_share)\n",
        "    if row['product_ID'] != 1 else np.nan), axis=1)\n",
        "\n",
        "# Step 7: Calculate the mean cross-price elasticity for Diet and Regular drinks\n",
        "mean_cross_elasticity_diet = df[df['nest'] == 'Diet']['cross_price_elasticity'].mean()\n",
        "mean_cross_elasticity_regular = df[df['nest'] == 'Regular']['cross_price_elasticity'].mean()\n",
        "\n",
        "# Step 8: Print the results\n",
        "print(f\"Mean Cross-Price Elasticity between Product 1 and Diet Drinks: {mean_cross_elasticity_diet}\")\n",
        "print(f\"Mean Cross-Price Elasticity between Product 1 and Regular Drinks: {mean_cross_elasticity_regular}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AK-lbryJjUG",
        "outputId": "f3fad6fc-8a3c-48cc-b07a-23d4cf81cdbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Cross-Price Elasticity between Product 1 and Diet Drinks: 0.0847446667113193\n",
            "Mean Cross-Price Elasticity between Product 1 and Regular Drinks: 0.12243513054021175\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2(d)."
      ],
      "metadata": {
        "id": "_DNu3i49Nf36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Multinomial Logit Model (Problem 1)\n",
        "\n",
        "The own-price elasticities in Model 2 (2(b)) are slightly larger in absolute terms compared to Model 1 (1(c)), indicating that demand is slightly more price-sensitive in Model 2.\n",
        "\n",
        "In the nested logit model(2), cross-price elasticities for both Regular and Diet drinks are lower than Model1. It suggests that Diet drinks are much less senstive to price changes."
      ],
      "metadata": {
        "id": "hbRC3M3uQag8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2(e)."
      ],
      "metadata": {
        "id": "bfU9joH_R0BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to compute the Jacobian matrix of price derivatives under the nested logit model\n",
        "def jacobian_matrix_nested(prices, market_shares, within_group_shares, nests, alpha, sigma):\n",
        "    \"\"\"\n",
        "    Generate the Jacobian matrix for the nested logit model.\n",
        "\n",
        "    Parameters:\n",
        "    - prices: Array of prices for the products in the given time period.\n",
        "    - market_shares: Array of market shares for the products in the given time period.\n",
        "    - within_group_shares: Array of within-group shares for the products.\n",
        "    - nests: Array indicating the nest (group) of each product.\n",
        "    - alpha: The price coefficient estimated from the model.\n",
        "    - sigma: The nesting parameter estimated from the model.\n",
        "\n",
        "    Returns:\n",
        "    - jacobian: The Jacobian matrix of price derivatives.\n",
        "    \"\"\"\n",
        "    num_products = len(prices)  # Number of products in the given time period\n",
        "    jacobian = np.zeros((num_products, num_products))  # Initialize the Jacobian matrix\n",
        "\n",
        "    for i in range(num_products):\n",
        "        for j in range(num_products):\n",
        "            s_i = market_shares[i]  # Market share for product i\n",
        "            s_j = market_shares[j]  # Market share for product j\n",
        "            s_jg = within_group_shares[j]  # Within-group share for product j\n",
        "            s_ig = within_group_shares[i]  # Within-group share for product i\n",
        "\n",
        "            if i == j:\n",
        "                # Own-price derivative (diagonal element)\n",
        "                jacobian[i, j] = alpha * s_j * (1 - s_j) + alpha * (sigma / (1 - sigma)) * s_j * (1 - s_jg)\n",
        "            elif nests[i] == nests[j]:\n",
        "                # Cross-price derivative within the same group\n",
        "                jacobian[i, j] = -alpha * s_j * s_i - alpha * (sigma / (1 - sigma)) * s_j * s_ig\n",
        "            else:\n",
        "                # Cross-price derivative across different groups\n",
        "                jacobian[i, j] = -alpha * s_j * s_i\n",
        "\n",
        "    return jacobian\n",
        "\n",
        "# Example usage for time period t = 100\n",
        "time_period = 100  # The last period in the dataset\n",
        "\n",
        "# Extract the prices, market shares, and within-group shares for time period t = 100\n",
        "df_time_100 = df[df['t'] == time_period]\n",
        "prices_time_100 = df_time_100['price'].values\n",
        "market_shares_time_100 = df_time_100['market_share'].values\n",
        "within_group_shares_time_100 = df_time_100['within_group_share'].values\n",
        "nests_time_100 = df_time_100['nest'].values\n",
        "\n",
        "# Use the estimated alpha and sigma from the IV2SLS model\n",
        "alpha_est = iv_results.params['price']  # Alpha (price coefficient)\n",
        "sigma_est = iv_results.params['log_within_group_share']  # Sigma (nesting parameter)\n",
        "\n",
        "# Generate the Jacobian matrix for time period t = 100\n",
        "jacobian_last_period = jacobian_matrix_nested(prices_time_100, market_shares_time_100, within_group_shares_time_100, nests_time_100, alpha_est, sigma_est)\n",
        "\n",
        "# Print the Jacobian matrix for the last time period\n",
        "print(f\"Jacobian matrix for time period {time_period}:\")\n",
        "print(jacobian_last_period)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5nujtpDSlC-",
        "outputId": "97384794-d463-40a3-e6a9-af5be566ca7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jacobian matrix for time period 100:\n",
            "[[-1.11307803e-01  3.77643208e-05  2.77515859e-04  5.52288365e-04\n",
            "   6.65525589e-03  9.62987940e-04  1.09535340e-02  2.37040081e-03\n",
            "   1.00410793e-03  8.90067725e-04]\n",
            " [ 3.77643208e-05 -2.49438547e-03  6.12699820e-06  1.21934286e-05\n",
            "   1.46934813e-04  2.12608584e-05  2.41832245e-04  5.23337353e-05\n",
            "   2.21687060e-05  1.96509251e-05]\n",
            " [ 2.77515859e-04  6.12699820e-06 -1.82914072e-02  8.96049431e-05\n",
            "   1.07976895e-03  1.56238091e-04  1.77713466e-03  3.84581033e-04\n",
            "   1.62909523e-04  1.44407293e-04]\n",
            " [ 5.52288365e-04  1.21934286e-05  8.96049431e-05 -3.63132775e-02\n",
            "   2.14886396e-03  3.10931707e-04  3.53670164e-03  7.65360332e-04\n",
            "   3.24208622e-04  2.87387064e-04]\n",
            " [ 6.65525589e-03  1.46934813e-04  1.07976895e-03  2.14886396e-03\n",
            "  -4.13841250e-01  3.74682902e-03  4.26184145e-02  9.22284297e-03\n",
            "   3.90682020e-03  3.46310836e-03]\n",
            " [ 9.62987940e-04  2.12608584e-05  1.56238091e-04  3.10931707e-04\n",
            "   3.74682902e-03 -6.95787247e-02  7.18096177e-03  1.55399687e-03\n",
            "   6.58277105e-04  5.83514169e-04]\n",
            " [ 1.09535340e-02  2.41832245e-04  1.77713466e-03  3.53670164e-03\n",
            "   4.26184145e-02  7.18096177e-03 -7.16926111e-01  1.76759821e-02\n",
            "   7.48759186e-03  6.63719870e-03]\n",
            " [ 2.37040081e-03  5.23337353e-05  3.84581033e-04  7.65360332e-04\n",
            "   9.22284297e-03  1.55399687e-03  1.76759821e-02 -1.68997288e-01\n",
            "   1.62035319e-03  1.43632376e-03]\n",
            " [ 1.00410793e-03  2.21687060e-05  1.62909523e-04  3.24208622e-04\n",
            "   3.90682020e-03  6.58277105e-04  7.48759186e-03  1.62035319e-03\n",
            "  -7.25216569e-02  6.08430470e-04]\n",
            " [ 8.90067725e-04  1.96509251e-05  1.44407293e-04  2.87387064e-04\n",
            "   3.46310836e-03  5.83514169e-04  6.63719870e-03  1.43632376e-03\n",
            "   6.08430470e-04 -6.43542090e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "26TUqQMLpcFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3(a). A simple supply side"
      ],
      "metadata": {
        "id": "ixyBysWKS9rL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jacobians_by_period = {}\n",
        "for time_period in df['t'].unique():\n",
        "    df_time = df[df['t'] == time_period]\n",
        "    prices = df_time['price'].values\n",
        "    market_shares = df_time['market_share'].values\n",
        "    within_group_shares = df_time['within_group_share'].values\n",
        "    nests = df_time['nest'].values\n",
        "\n",
        "    jacobian_matrix = jacobian_matrix_nested(prices, market_shares, within_group_shares, nests, alpha_est, sigma_est)\n",
        "    jacobians_by_period[time_period] = jacobian_matrix\n",
        "\n",
        "# Calculate marginal costs and Lerner Index with error handling for zero or invalid derivatives\n",
        "df['marginal_cost'] = np.nan\n",
        "df['lerner_index'] = np.nan\n",
        "\n",
        "for time_period in df['t'].unique():\n",
        "    df_time = df[df['t'] == time_period]\n",
        "    jacobian_matrix = jacobians_by_period[time_period]\n",
        "\n",
        "    own_price_derivatives = np.diag(jacobian_matrix)\n",
        "\n",
        "    # Handle zero or near-zero derivatives\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        marginal_cost = df_time['price'].values + np.divide(df_time['market_share'].values, own_price_derivatives, where=own_price_derivatives != 0)\n",
        "        lerner_index = (df_time['price'].values - marginal_cost) / df_time['price'].values\n",
        "\n",
        "        # Store results only where derivatives are valid\n",
        "        df.loc[df['t'] == time_period, 'marginal_cost'] = marginal_cost\n",
        "        df.loc[df['t'] == time_period, 'lerner_index'] = lerner_index\n",
        "\n",
        "# Step 8: Calculate the mean Lerner Index across all time periods\n",
        "mean_lerner_index = df['lerner_index'].mean()\n",
        "\n",
        "# Print the mean Lerner Index\n",
        "print(f\"Mean Lerner Index: {mean_lerner_index}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7GPMlIFT8OD",
        "outputId": "a6571141-2333-407e-c011-d1bc5a1585d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Lerner Index: 0.22584494689253443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3(b)."
      ],
      "metadata": {
        "id": "srMk1V7hUHIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import fsolve\n",
        "\n",
        "# Assuming the Jacobian matrix is already computed for t = 100 (we'll extract the relevant derivatives)\n",
        "jacobian_100 = jacobians_by_period[100]  # Get the Jacobian matrix for time period 100\n",
        "\n",
        "# Own-price derivatives for products 1 and 2 (diagonal elements of the Jacobian)\n",
        "own_price_derivative_1 = jacobian_100[0, 0]\n",
        "own_price_derivative_2 = jacobian_100[1, 1]\n",
        "\n",
        "# Cross-price derivatives between product 1 and product 2 (different nests)\n",
        "cross_price_derivative_12 = jacobian_100[0, 1]  # Effect of p2 on s1\n",
        "cross_price_derivative_21 = jacobian_100[1, 0]  # Effect of p1 on s2\n",
        "\n",
        "# Step 1: Filter data for t = 100 (the last time period)\n",
        "df_time_100 = df[df['t'] == 100]\n",
        "\n",
        "# Step 2: Market size (M_t = 100,000, given in the problem description)\n",
        "M_t = 100000\n",
        "\n",
        "# Step 3: Extract necessary variables for products 1 and 2 at t = 100\n",
        "market_share_1 = df_time_100.loc[df_time_100['product_ID'] == 1, 'market_share'].values[0]\n",
        "market_share_2 = df_time_100.loc[df_time_100['product_ID'] == 2, 'market_share'].values[0]\n",
        "\n",
        "# Extract marginal costs for products 1 and 2 at t = 100\n",
        "c1 = df_time_100.loc[df_time_100['product_ID'] == 1, 'marginal_cost'].values[0]\n",
        "c2 = df_time_100.loc[df_time_100['product_ID'] == 2, 'marginal_cost'].values[0]\n",
        "\n",
        "# Extract prices for products 1 and 2 at t = 100\n",
        "price_1 = df_time_100.loc[df_time_100['product_ID'] == 1, 'price'].values[0]\n",
        "price_2 = df_time_100.loc[df_time_100['product_ID'] == 2, 'price'].values[0]\n",
        "\n",
        "# Print the original prices for product 1 and 2\n",
        "print(f\"Original price for Product 1: {price_1}\")\n",
        "print(f\"Original price for Product 2: {price_2}\")\n",
        "\n",
        "# Step 4: Define the FOC system for two products (products 1 and 2) in different nests\n",
        "def FOCs(variables):\n",
        "    p1, p2 = variables\n",
        "    s1 = market_share_1\n",
        "    s2 = market_share_2\n",
        "\n",
        "    # FOC for p1 (cross-price effects are reduced for products in different nests)\n",
        "    FOC1 = s1 * M_t + (p1 - c1) * own_price_derivative_1 * M_t + (p2 - c2) * cross_price_derivative_12 * M_t\n",
        "\n",
        "    # FOC for p2 (cross-price effects are reduced for products in different nests)\n",
        "    FOC2 = s2 * M_t + (p2 - c2) * own_price_derivative_2 * M_t + (p1 - c1) * cross_price_derivative_21 * M_t\n",
        "\n",
        "    return [FOC1, FOC2]\n",
        "\n",
        "# Step 5: Initial guess for prices (using the original prices)\n",
        "initial_guess = [price_1, price_2]\n",
        "\n",
        "# Step 6: Solve the system of FOCs\n",
        "solution = fsolve(FOCs, initial_guess)\n",
        "\n",
        "# Get the new prices for products 1 and 2 after the merger\n",
        "p1_new, p2_new = solution\n",
        "\n",
        "# Print the new prices for products 1 and 2 after the merger\n",
        "print(f\"New price for Product 1: {p1_new}\")\n",
        "print(f\"New price for Product 2: {p2_new}\")\n",
        "\n",
        "# Step 7: Function to display the price changes\n",
        "def show_price_changes(p1, p2, p1_new, p2_new):\n",
        "    # Calculate the absolute price changes\n",
        "    price_change_1 = p1_new - p1\n",
        "    price_change_2 = p2_new - p2\n",
        "\n",
        "    # Calculate the percentage price changes\n",
        "    price_change_1_pct = (price_change_1 / p1) * 100\n",
        "    price_change_2_pct = (price_change_2 / p2) * 100\n",
        "\n",
        "    # Print the results with improved formatting\n",
        "    print(f\"{'Product':<15}{'Pre-Merger Price':<20}{'Post-Merger Price':<20}{'Change':<15}{'Change (%)'}\")\n",
        "    print(f\"{'-'*75}\")\n",
        "    print(f\"{'Product 1':<15}{p1:<20.4f}{p1_new:<20.4f}{price_change_1:<15.4f}{price_change_1_pct:.2f}%\")\n",
        "    print(f\"{'Product 2':<15}{p2:<20.4f}{p2_new:<20.4f}{price_change_2:<15.4f}{price_change_2_pct:.2f}%\")\n",
        "\n",
        "# Call the function to display the results\n",
        "show_price_changes(price_1, price_2, p1_new, p2_new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk8BB8TIY_qZ",
        "outputId": "a6326b82-47d9-44f8-9b2b-f1e123f1fe49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original price for Product 1: 3.17947074656772\n",
            "Original price for Product 2: 1.90735024827719\n",
            "New price for Product 1: 3.179662630117701\n",
            "New price for Product 2: 1.9159127325737075\n",
            "Product        Pre-Merger Price    Post-Merger Price   Change         Change (%)\n",
            "---------------------------------------------------------------------------\n",
            "Product 1      3.1795              3.1797              0.0002         0.01%\n",
            "Product 2      1.9074              1.9159              0.0086         0.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the merger, both prices are higher because the merged firm now maximizes joint profits, reducing competition between Product 1 and Product 2. In simulation, the price of Product 2 increased more than Product 1, which may reflect stronger interdependencies between the two products' demand."
      ],
      "metadata": {
        "id": "YD0pPN2fWS0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3(c)."
      ],
      "metadata": {
        "id": "jpviPtScWUm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the dataset and filter for t = 100 (last period)\n",
        "df = pd.read_csv('product_data.csv')\n",
        "df_time_100 = df[df['t'] == 100]\n",
        "\n",
        "# Step 2: After the merger, firm 1 and firm 2 are combined\n",
        "# Assuming the merged firm's product IDs are 1 and 2\n",
        "merged_firm_products = [1, 2]\n",
        "\n",
        "# Extract prices before and after the merger for merged firms' products\n",
        "pre_merger_prices = df_time_100[df_time_100['product_ID'].isin(merged_firm_products)]['price'].values\n",
        "post_merger_prices = [p1_new, p2_new]  # New prices from 3(b)\n",
        "\n",
        "# Calculate the average price for the merged firms before and after the merger\n",
        "average_price_pre_merger = np.mean(pre_merger_prices)\n",
        "average_price_post_merger = np.mean(post_merger_prices)\n",
        "\n",
        "# Step 3: Calculate average price changes for products in the same nest (excluding merged firm's products)\n",
        "same_nest_competitors = df_time_100[(df_time_100['nest'] == df_time_100[df_time_100['product_ID'] == 1]['nest'].values[0]) &\n",
        "                                    (~df_time_100['product_ID'].isin(merged_firm_products))]\n",
        "\n",
        "# Calculate the average price for same-nest competitors before the merger\n",
        "average_price_same_nest_pre = same_nest_competitors['price'].mean()\n",
        "\n",
        "# For simplicity, assume the prices of competitors in the same nest don't change after the merger\n",
        "average_price_same_nest_post = same_nest_competitors['price'].mean()\n",
        "\n",
        "# Step 4: Calculate average price changes for products in a different nest (excluding merged firm's products)\n",
        "different_nest_competitors = df_time_100[(df_time_100['nest'] != df_time_100[df_time_100['product_ID'] == 1]['nest'].values[0])]\n",
        "\n",
        "# Calculate the average price for different-nest competitors before the merger\n",
        "average_price_different_nest_pre = different_nest_competitors['price'].mean()\n",
        "\n",
        "# Assume the prices of competitors in the different nest remain unchanged\n",
        "average_price_different_nest_post = different_nest_competitors['price'].mean()\n",
        "\n",
        "# Step 5: Print the results\n",
        "print(f\"Average Price for Merged Firms Before Merger: {average_price_pre_merger}\")\n",
        "print(f\"Average Price for Merged Firms After Merger: {average_price_post_merger}\")\n",
        "\n",
        "print(f\"Average Price for Competitors in Same Nest Before Merger: {average_price_same_nest_pre}\")\n",
        "print(f\"Average Price for Competitors in Same Nest After Merger: {average_price_same_nest_post}\")\n",
        "\n",
        "print(f\"Average Price for Competitors in Different Nest Before Merger: {average_price_different_nest_pre}\")\n",
        "print(f\"Average Price for Competitors in Different Nest After Merger: {average_price_different_nest_post}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcfnKVo-WoXA",
        "outputId": "aee842fe-9a4e-4ed7-eac7-ee73931eb4c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Price for Merged Firms Before Merger: 2.543410497422455\n",
            "Average Price for Merged Firms After Merger: 2.5477876813457043\n",
            "Average Price for Competitors in Same Nest Before Merger: 2.2272790472871336\n",
            "Average Price for Competitors in Same Nest After Merger: 2.2272790472871336\n",
            "Average Price for Competitors in Different Nest Before Merger: 3.4536960542560644\n",
            "Average Price for Competitors in Different Nest After Merger: 3.4536960542560644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average Price for Products 1 and 2 (the merging firms):\n",
        "\n",
        "Before the merger: 2.543\n",
        "After the merger: 2.548\n",
        "The prices for Products 1 and 2 rose significantly after the merger, indicating that the merged firm has reduced competitive pressure between these two products and is now able to raise prices to maximize joint profits.\n",
        "\n",
        "Average Price for Competing Products in the Same Nest (products in the same category as Products 1 and 2):\n",
        "\n",
        "Before the merger: 2.227\n",
        "After the merger: 2.227\n",
        "No price change.\n",
        "There was no change in the prices of competing products in the same nest. This suggests that the merger did not have a direct impact on other products in the same category as Products 1 and 2. These products might be sufficiently differentiated or not directly affected by the pricing strategy of the merged firm.\n",
        "\n",
        "Average Price for Competing Products in a Different Nest (products in the opposite category):\n",
        "\n",
        "Before the merger: 3.454\n",
        "After the merger: 3.454\n",
        "No price change.\n",
        "Similarly, there was no change in the prices of competing products in the different nest (likely Diet products, assuming Products 1 and 2 are in the Regular nest). This suggests that the merger of Products 1 and 2 did not spill over to affect the pricing of products in the other nest.\n"
      ],
      "metadata": {
        "id": "7K6GsQDwXRK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3(d)."
      ],
      "metadata": {
        "id": "6ukgPaTTXaK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import minimize, Bounds\n",
        "\n",
        "# Function to calculate total industry profit under collusion with elasticity\n",
        "def total_collusive_profit_with_elasticity(prices, costs, market_shares, M_t, elasticity):\n",
        "    total_profit = 0\n",
        "    for i in range(len(prices)):\n",
        "        # Adjust demand based on price elasticity (demand decreases as prices increase)\n",
        "        q_i = market_shares[i] * M_t * (prices[i] / df['price'].values[i]) ** (-elasticity)\n",
        "        total_profit += (prices[i] - costs[i]) * q_i  # Profit for product i\n",
        "    return -total_profit  # Negative because we minimize the function\n",
        "\n",
        "# Function to simulate collusive prices with elasticity\n",
        "def simulate_collusive_prices_with_elasticity(df, M_t, elasticity):\n",
        "    costs = df['marginal_cost'].values  # Marginal costs for all products\n",
        "    market_shares = df['market_share'].values  # Market shares for all products\n",
        "    initial_prices = df['price'].values  # Initial prices for starting point\n",
        "\n",
        "    # Set bounds to ensure reasonable prices (allow flexibility, but avoid extremes)\n",
        "    price_bounds = Bounds([1] * len(initial_prices), [15] * len(initial_prices))\n",
        "\n",
        "    # Objective function for collusion with elasticity (negative total profit for minimization)\n",
        "    result = minimize(total_collusive_profit_with_elasticity, initial_prices,\n",
        "                      args=(costs, market_shares, M_t, elasticity),\n",
        "                      method='L-BFGS-B', bounds=price_bounds)\n",
        "\n",
        "    # Return the optimized (collusive) prices\n",
        "    collusive_prices = result.x\n",
        "    return collusive_prices\n",
        "\n",
        "# Example usage for t=100\n",
        "M_t = 100000  # Total market size\n",
        "elasticity = 1.5  # Assuming moderate elasticity of demand (adjust as necessary)\n",
        "\n",
        "# Ensure the marginal costs are already calculated from Problem 3(a)\n",
        "if 'marginal_cost' not in df.columns:\n",
        "    df['own_price_derivative'] = alpha_est * df['market_share'] * (1 - df['market_share'])\n",
        "    df['marginal_cost'] = df['price'] + df['market_share'] / df['own_price_derivative']\n",
        "\n",
        "# Simulate collusive prices with elasticity for all products\n",
        "collusive_prices = simulate_collusive_prices_with_elasticity(df, M_t, elasticity)\n",
        "\n",
        "# Store the collusive prices in the DataFrame\n",
        "df['collusive_price'] = collusive_prices\n",
        "\n",
        "# Summary of results (for 3(c) and 3(d))\n",
        "summary_table = df[['product_ID', 'price', 'collusive_price']]\n",
        "print(summary_table)\n",
        "\n",
        "# Calculate average price changes after collusion\n",
        "df['price_change'] = df['collusive_price'] - df['price']\n",
        "average_price_change = df['price_change'].mean()\n",
        "\n",
        "# Print summary of price changes\n",
        "print(f\"Average price change after collusion: {average_price_change}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYvCovxffvVM",
        "outputId": "ca536a3c-790c-4b32-bd6e-578d3cf92661"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     product_ID     price  collusive_price\n",
            "0             1  2.814362         1.000000\n",
            "1             2  2.935735         1.000000\n",
            "2             3  2.467309         1.000000\n",
            "3             4  1.543958         1.000000\n",
            "4             5  1.495961         1.000000\n",
            "..          ...       ...              ...\n",
            "995           6  3.183553         1.937948\n",
            "996           7  4.671217         1.000000\n",
            "997           8  3.134615         1.000000\n",
            "998           9  3.196304         1.939622\n",
            "999          10  3.082792         1.873799\n",
            "\n",
            "[1000 rows x 3 columns]\n",
            "Average price change after collusion: -1.3360865629473142\n"
          ]
        }
      ]
    }
  ]
}