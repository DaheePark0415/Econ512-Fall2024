{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOUovgtCzhNHinLtvwddjVi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaheePark0415/Econ512-Fall2024/blob/main/IO_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(a)."
      ],
      "metadata": {
        "id": "CyS34q2L_Ol3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('product_data.csv')\n",
        "\n",
        "# Check the structure of the data to ensure it has the correct columns\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1Aa_wRD_X-f",
        "outputId": "8e727cf6-9211-4f75-a50c-d82e3c072fad"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   product_ID  nest     price     sugar  caffeine  market_share  \\\n",
            "0           1  Diet  2.814362  0.631224  6.752525      0.111141   \n",
            "1           2  Diet  2.935735  0.004553  6.784396      0.081787   \n",
            "2           3  Diet  2.467309  0.739947  5.761261      0.085727   \n",
            "3           4  Diet  1.543958  0.103660  4.468299      0.007187   \n",
            "4           5  Diet  1.495961  0.971926  4.052750      0.015912   \n",
            "\n",
            "   caffeine_extract_price  corn_syrup_price  t  \n",
            "0                0.267468          0.251714  1  \n",
            "1                0.320000          0.253146  1  \n",
            "2                0.252531          0.314781  1  \n",
            "3                0.203220          0.227481  1  \n",
            "4                0.156466          0.244453  1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n"
      ],
      "metadata": {
        "id": "KYbfQkx5_lia"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/product_data.csv')\n",
        "\n",
        "# Show the first few rows of the dataset to verify\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHur1_VG_ogT",
        "outputId": "2a7a0eba-bd70-4da7-c0cb-4d3772167c8f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   product_ID  nest     price     sugar  caffeine  market_share  \\\n",
            "0           1  Diet  2.814362  0.631224  6.752525      0.111141   \n",
            "1           2  Diet  2.935735  0.004553  6.784396      0.081787   \n",
            "2           3  Diet  2.467309  0.739947  5.761261      0.085727   \n",
            "3           4  Diet  1.543958  0.103660  4.468299      0.007187   \n",
            "4           5  Diet  1.495961  0.971926  4.052750      0.015912   \n",
            "\n",
            "   caffeine_extract_price  corn_syrup_price  t  \n",
            "0                0.267468          0.251714  1  \n",
            "1                0.320000          0.253146  1  \n",
            "2                0.252531          0.314781  1  \n",
            "3                0.203220          0.227481  1  \n",
            "4                0.156466          0.244453  1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the utility function with corrected handling for Diet and Regular using the 'nest' column\n",
        "def utility(params, price, sugar, caffeine, nest):\n",
        "    alpha, beta1, beta2, gamma_d, gamma_r = params\n",
        "    diet = (nest == 'Diet').astype(int)\n",
        "    regular = (nest != 'Diet').astype(int)  # Assuming the other category is Regular\n",
        "    return alpha * price + beta1 * sugar + beta2 * caffeine + gamma_d * diet + gamma_r * regular\n",
        "\n",
        "# Define the log-likelihood function for the multinomial logit model\n",
        "def log_likelihood(params, df):\n",
        "    # Calculate utility for each product in each time period\n",
        "    df['utility'] = utility(params, df['price'], df['sugar'], df['caffeine'], df['nest'])\n",
        "\n",
        "    # Exponentiate utility\n",
        "    df['exp_utility'] = np.exp(df['utility'])\n",
        "\n",
        "    # Group by time period, sum over products to get the denominator for each period\n",
        "    df['sum_exp_util'] = df.groupby('t')['exp_utility'].transform('sum') + 1  # Add 1 for the outside option\n",
        "\n",
        "    # Probability of choosing product j at time t\n",
        "    df['prob'] = df['exp_utility'] / df['sum_exp_util']\n",
        "\n",
        "    # Log of the probability weighted by quantity (here using 'market_share')\n",
        "    df['log_prob'] = np.log(df['prob']) * df['market_share']\n",
        "\n",
        "    # Negative log-likelihood (since we minimize)\n",
        "    return -df['log_prob'].sum()\n",
        "\n",
        "# Initialize the parameters: [alpha, beta1, beta2, gamma_d, gamma_r]\n",
        "initial_guess = [0.1, 0.1, 0.1, 0.1, 0.1]\n",
        "\n",
        "# Estimate the parameters by minimizing the negative log-likelihood\n",
        "result = minimize(log_likelihood, initial_guess, args=(df,), method='BFGS')\n",
        "\n",
        "# Print the estimated parameters\n",
        "print(\"Estimated parameters:\", result.x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82XuplM8_wpJ",
        "outputId": "dc0915f0-5ae6-4f07-9406-2d0d9a55d5e4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated parameters: [-0.32866229  0.85382714  0.8080273  11.61252541  8.8465584 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(b)."
      ],
      "metadata": {
        "id": "rKSIE5yrABfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Define the exogenous variables (instruments + other exogenous variables)\n",
        "exog_vars = ['sugar', 'caffeine', 'caffeine_extract_price', 'corn_syrup_price']\n",
        "\n",
        "# First stage: Regress price on instruments and other exogenous variables\n",
        "model_stage_1 = LinearRegression()\n",
        "model_stage_1.fit(df[exog_vars], df['price'])\n",
        "\n",
        "# Get the predicted price from the first stage\n",
        "df['predicted_price'] = model_stage_1.predict(df[exog_vars])\n"
      ],
      "metadata": {
        "id": "qepcLR6SAGXG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the utility function to use the predicted price\n",
        "def utility_iv(params, predicted_price, sugar, caffeine, nest):\n",
        "    alpha, beta1, beta2, gamma_d, gamma_r = params\n",
        "    diet = (nest == 'Diet').astype(int)\n",
        "    regular = (nest != 'Diet').astype(int)\n",
        "    return alpha * predicted_price + beta1 * sugar + beta2 * caffeine + gamma_d * diet + gamma_r * regular\n",
        "\n",
        "# Adjust the log-likelihood function to use the predicted price\n",
        "def log_likelihood_iv(params, df):\n",
        "    # Calculate utility for each product in each time period using predicted price\n",
        "    df['utility'] = utility_iv(params, df['predicted_price'], df['sugar'], df['caffeine'], df['nest'])\n",
        "\n",
        "    # Exponentiate utility\n",
        "    df['exp_utility'] = np.exp(df['utility'])\n",
        "\n",
        "    # Group by time period, sum over products to get the denominator for each period\n",
        "    df['sum_exp_util'] = df.groupby('t')['exp_utility'].transform('sum') + 1  # Add 1 for the outside option\n",
        "\n",
        "    # Probability of choosing product j at time t\n",
        "    df['prob'] = df['exp_utility'] / df['sum_exp_util']\n",
        "\n",
        "    # Log of the probability weighted by market share\n",
        "    df['log_prob'] = np.log(df['prob']) * df['market_share']\n",
        "\n",
        "    # Negative log-likelihood (since we minimize)\n",
        "    return -df['log_prob'].sum()\n",
        "\n",
        "# Initialize the parameters: [alpha, beta1, beta2, gamma_d, gamma_r]\n",
        "initial_guess_iv = [0.1, 0.1, 0.1, 0.1, 0.1]\n",
        "\n",
        "# Estimate the parameters by minimizing the negative log-likelihood\n",
        "result_iv = minimize(log_likelihood_iv, initial_guess_iv, args=(df,), method='BFGS')\n",
        "\n",
        "# Print the estimated parameters\n",
        "print(\"Estimated parameters (IV):\", result_iv.x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkYWRQmvAUmI",
        "outputId": "d20de59e-c8a1-4f6b-e386-40d96fbe5196"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated parameters (IV): [-1.33114723  1.03226555  1.02240006 14.35370063 12.09851264]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1(b) involves addressing endogeneity in the price variable. In the given context, the price of soft drinks is correlated with unobserved quality (ùúâùëóùë°‚Äã). This means that standard OLS estimators would be biased. To solve this issue, we can use instrumental variables (IV) for the price.\n",
        "\n",
        "In this problem, the suggested instruments are:\n",
        "\n",
        "Caffeine Extract Price and Corn Syrup Price.\n",
        "\n",
        "These instruments are used because they affect the price but are not directly related to the unobserved demand shock (ùúâùëóùë°).\n",
        "\n",
        "Approach:\n",
        "Two-Stage Least Squares (2SLS): First, we will regress the endogenous variable (price) on the instruments to get the predicted prices. Then, we will use these predicted prices in the utility function to estimate the parameters.\n",
        "\n",
        "Conditions for Valid Instruments:\n",
        "\n",
        "Relevance: The instruments must be correlated with the endogenous variable (price).\n",
        "Exogeneity: The instruments must not be correlated with the error term (unobserved quality ùúâùëóùë°)."
      ],
      "metadata": {
        "id": "qARqa4rdA4j3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ÏÉà ÏÑπÏÖò"
      ],
      "metadata": {
        "id": "IYSUtu43CGxd"
      }
    }
  ]
}