{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMWPhf2DCJAfuGlr77b/fJh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaheePark0415/Econ512-Fall2024/blob/main/IO_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Probome 1(a). Multinomial Logit"
      ],
      "metadata": {
        "id": "CyS34q2L_Ol3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('product_data.csv')\n",
        "\n",
        "# Check the structure of the data to ensure it has the correct columns\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1Aa_wRD_X-f",
        "outputId": "8e727cf6-9211-4f75-a50c-d82e3c072fad"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   product_ID  nest     price     sugar  caffeine  market_share  \\\n",
            "0           1  Diet  2.814362  0.631224  6.752525      0.111141   \n",
            "1           2  Diet  2.935735  0.004553  6.784396      0.081787   \n",
            "2           3  Diet  2.467309  0.739947  5.761261      0.085727   \n",
            "3           4  Diet  1.543958  0.103660  4.468299      0.007187   \n",
            "4           5  Diet  1.495961  0.971926  4.052750      0.015912   \n",
            "\n",
            "   caffeine_extract_price  corn_syrup_price  t  \n",
            "0                0.267468          0.251714  1  \n",
            "1                0.320000          0.253146  1  \n",
            "2                0.252531          0.314781  1  \n",
            "3                0.203220          0.227481  1  \n",
            "4                0.156466          0.244453  1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n"
      ],
      "metadata": {
        "id": "KYbfQkx5_lia"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/product_data.csv')\n",
        "\n",
        "# Show the first few rows of the dataset to verify\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHur1_VG_ogT",
        "outputId": "2a7a0eba-bd70-4da7-c0cb-4d3772167c8f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   product_ID  nest     price     sugar  caffeine  market_share  \\\n",
            "0           1  Diet  2.814362  0.631224  6.752525      0.111141   \n",
            "1           2  Diet  2.935735  0.004553  6.784396      0.081787   \n",
            "2           3  Diet  2.467309  0.739947  5.761261      0.085727   \n",
            "3           4  Diet  1.543958  0.103660  4.468299      0.007187   \n",
            "4           5  Diet  1.495961  0.971926  4.052750      0.015912   \n",
            "\n",
            "   caffeine_extract_price  corn_syrup_price  t  \n",
            "0                0.267468          0.251714  1  \n",
            "1                0.320000          0.253146  1  \n",
            "2                0.252531          0.314781  1  \n",
            "3                0.203220          0.227481  1  \n",
            "4                0.156466          0.244453  1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the utility function with corrected handling for Diet and Regular using the 'nest' column\n",
        "def utility(params, price, sugar, caffeine, nest):\n",
        "    alpha, beta1, beta2, gamma_d, gamma_r = params\n",
        "    diet = (nest == 'Diet').astype(int)\n",
        "    regular = (nest != 'Diet').astype(int)  # Assuming the other category is Regular\n",
        "    return alpha * price + beta1 * sugar + beta2 * caffeine + gamma_d * diet + gamma_r * regular\n",
        "\n",
        "# Define the log-likelihood function for the multinomial logit model\n",
        "def log_likelihood(params, df):\n",
        "    # Calculate utility for each product in each time period\n",
        "    df['utility'] = utility(params, df['price'], df['sugar'], df['caffeine'], df['nest'])\n",
        "\n",
        "    # Exponentiate utility\n",
        "    df['exp_utility'] = np.exp(df['utility'])\n",
        "\n",
        "    # Group by time period, sum over products to get the denominator for each period\n",
        "    df['sum_exp_util'] = df.groupby('t')['exp_utility'].transform('sum') + 1  # Add 1 for the outside option\n",
        "\n",
        "    # Probability of choosing product j at time t\n",
        "    df['prob'] = df['exp_utility'] / df['sum_exp_util']\n",
        "\n",
        "    # Log of the probability weighted by quantity (here using 'market_share')\n",
        "    df['log_prob'] = np.log(df['prob']) * df['market_share']\n",
        "\n",
        "    # Negative log-likelihood (since we minimize)\n",
        "    return -df['log_prob'].sum()\n",
        "\n",
        "# Initialize the parameters: [alpha, beta1, beta2, gamma_d, gamma_r]\n",
        "initial_guess = [0.1, 0.1, 0.1, 0.1, 0.1]\n",
        "\n",
        "# Estimate the parameters by minimizing the negative log-likelihood\n",
        "result = minimize(log_likelihood, initial_guess, args=(df,), method='BFGS')\n",
        "\n",
        "# Print the estimated parameters\n",
        "print(\"Estimated parameters:\", result.x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82XuplM8_wpJ",
        "outputId": "dc0915f0-5ae6-4f07-9406-2d0d9a55d5e4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated parameters: [-0.32866229  0.85382714  0.8080273  11.61252541  8.8465584 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(b)."
      ],
      "metadata": {
        "id": "rKSIE5yrABfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Define the exogenous variables (instruments + other exogenous variables)\n",
        "exog_vars = ['sugar', 'caffeine', 'caffeine_extract_price', 'corn_syrup_price']\n",
        "\n",
        "# First stage: Regress price on instruments and other exogenous variables\n",
        "model_stage_1 = LinearRegression()\n",
        "model_stage_1.fit(df[exog_vars], df['price'])\n",
        "\n",
        "# Get the predicted price from the first stage\n",
        "df['predicted_price'] = model_stage_1.predict(df[exog_vars])\n"
      ],
      "metadata": {
        "id": "qepcLR6SAGXG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the utility function to use the predicted price\n",
        "def utility_iv(params, predicted_price, sugar, caffeine, nest):\n",
        "    alpha, beta1, beta2, gamma_d, gamma_r = params\n",
        "    diet = (nest == 'Diet').astype(int)\n",
        "    regular = (nest != 'Diet').astype(int)\n",
        "    return alpha * predicted_price + beta1 * sugar + beta2 * caffeine + gamma_d * diet + gamma_r * regular\n",
        "\n",
        "# Adjust the log-likelihood function to use the predicted price\n",
        "def log_likelihood_iv(params, df):\n",
        "    # Calculate utility for each product in each time period using predicted price\n",
        "    df['utility'] = utility_iv(params, df['predicted_price'], df['sugar'], df['caffeine'], df['nest'])\n",
        "\n",
        "    # Exponentiate utility\n",
        "    df['exp_utility'] = np.exp(df['utility'])\n",
        "\n",
        "    # Group by time period, sum over products to get the denominator for each period\n",
        "    df['sum_exp_util'] = df.groupby('t')['exp_utility'].transform('sum') + 1  # Add 1 for the outside option\n",
        "\n",
        "    # Probability of choosing product j at time t\n",
        "    df['prob'] = df['exp_utility'] / df['sum_exp_util']\n",
        "\n",
        "    # Log of the probability weighted by market share\n",
        "    df['log_prob'] = np.log(df['prob']) * df['market_share']\n",
        "\n",
        "    # Negative log-likelihood (since we minimize)\n",
        "    return -df['log_prob'].sum()\n",
        "\n",
        "# Initialize the parameters: [alpha, beta1, beta2, gamma_d, gamma_r]\n",
        "initial_guess_iv = [0.1, 0.1, 0.1, 0.1, 0.1]\n",
        "\n",
        "# Estimate the parameters by minimizing the negative log-likelihood\n",
        "result_iv = minimize(log_likelihood_iv, initial_guess_iv, args=(df,), method='BFGS')\n",
        "\n",
        "# Print the estimated parameters\n",
        "print(\"Estimated parameters (IV):\", result_iv.x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkYWRQmvAUmI",
        "outputId": "d20de59e-c8a1-4f6b-e386-40d96fbe5196"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated parameters (IV): [-1.33114723  1.03226555  1.02240006 14.35370063 12.09851264]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1(b) involves addressing endogeneity in the price variable. In the given context, the price of soft drinks is correlated with unobserved quality (𝜉𝑗𝑡​). This means that standard OLS estimators would be biased. To solve this issue, we can use instrumental variables (IV) for the price.\n",
        "\n",
        "In this problem, the suggested instruments are:\n",
        "\n",
        "Caffeine Extract Price and Corn Syrup Price.\n",
        "\n",
        "These instruments are used because they affect the price but are not directly related to the unobserved demand shock (𝜉𝑗𝑡).\n",
        "\n",
        "Approach:\n",
        "Two-Stage Least Squares (2SLS): First, we will regress the endogenous variable (price) on the instruments to get the predicted prices. Then, we will use these predicted prices in the utility function to estimate the parameters.\n",
        "\n",
        "Conditions for Valid Instruments:\n",
        "\n",
        "Relevance: The instruments must be correlated with the endogenous variable (price).\n",
        "Exogeneity: The instruments must not be correlated with the error term (unobserved quality 𝜉𝑗𝑡)."
      ],
      "metadata": {
        "id": "qARqa4rdA4j3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(c)"
      ],
      "metadata": {
        "id": "IYSUtu43CGxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "roblem 1(c) involves calculating the own-price derivatives and own-price elasticities for the products. These derivatives and elasticities are important for understanding how the market share of each product responds to changes in its own price."
      ],
      "metadata": {
        "id": "FPMNNc_PCoRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the estimated alpha from the previous results\n",
        "alpha_est = result_iv.x[0]  # Assuming alpha is the first estimated parameter from the IV model\n",
        "\n",
        "# Function to calculate own-price derivatives\n",
        "def own_price_derivative(alpha, market_share):\n",
        "    return alpha * market_share * (1 - market_share)\n",
        "\n",
        "# Function to calculate own-price elasticity\n",
        "def own_price_elasticity(alpha, price, market_share):\n",
        "    return own_price_derivative(alpha, market_share) * (price / market_share)\n",
        "\n",
        "# Calculate own-price derivatives and elasticities for each product in each time period\n",
        "df['own_price_derivative'] = own_price_derivative(alpha_est, df['market_share'])\n",
        "df['own_price_elasticity'] = own_price_elasticity(alpha_est, df['price'], df['market_share'])\n",
        "\n",
        "# Print the mean own-price elasticity for Regular and Diet drinks\n",
        "mean_elasticity_diet = df[df['nest'] == 'Diet']['own_price_elasticity'].mean()\n",
        "mean_elasticity_regular = df[df['nest'] != 'Diet']['own_price_elasticity'].mean()\n",
        "\n",
        "print(f\"Mean Own-Price Elasticity for Diet Drinks: {mean_elasticity_diet}\")\n",
        "print(f\"Mean Own-Price Elasticity for Regular Drinks: {mean_elasticity_regular}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUTyZ-J3C-Ot",
        "outputId": "687e1f6b-1625-422f-fb85-4246aa91cd38"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Own-Price Elasticity for Diet Drinks: -2.807415569584785\n",
            "Mean Own-Price Elasticity for Regular Drinks: -3.9648574224575888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(d)."
      ],
      "metadata": {
        "id": "enRE8VmmDLLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iSeRC_qeDqH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate cross-price derivatives\n",
        "def cross_price_derivative(alpha, market_share_j, market_share_k):\n",
        "    return -alpha * market_share_j * market_share_k\n",
        "\n",
        "# Function to calculate cross-price elasticity\n",
        "def cross_price_elasticity(alpha, price_k, market_share_j, market_share_k):\n",
        "    return cross_price_derivative(alpha, market_share_j, market_share_k) * (price_k / market_share_j)\n",
        "\n",
        "# Calculate cross-price elasticities between product 1 and all other products\n",
        "def calculate_cross_price_elasticities(df, product_id):\n",
        "    # Get the market share and price for the specific product (product 1 in this case)\n",
        "    product_1_price = df.loc[df['product_ID'] == product_id, 'price'].values[0]\n",
        "    product_1_share = df.loc[df['product_ID'] == product_id, 'market_share'].values[0]\n",
        "\n",
        "    # Calculate cross-price elasticities for all other products\n",
        "    df['cross_price_elasticity'] = df.apply(\n",
        "        lambda row: cross_price_elasticity(alpha_est, product_1_price, row['market_share'], product_1_share)\n",
        "        if row['product_ID'] != product_id else np.nan, axis=1)\n",
        "\n",
        "    return df[['product_ID', 'cross_price_elasticity']]\n",
        "\n",
        "# Calculate cross-price elasticities for product 1 with all other products\n",
        "cross_price_elasticities_df = calculate_cross_price_elasticities(df, product_id=1)\n",
        "\n",
        "# Print the cross-price elasticities for product 1\n",
        "print(cross_price_elasticities_df)\n",
        "\n",
        "# Calculate the mean cross-price elasticity for diet and regular drinks\n",
        "mean_cross_elasticity_diet = cross_price_elasticities_df[df['nest'] == 'Diet']['cross_price_elasticity'].mean()\n",
        "mean_cross_elasticity_regular = cross_price_elasticities_df[df['nest'] != 'Diet']['cross_price_elasticity'].mean()\n",
        "\n",
        "print(f\"Mean Cross-Price Elasticity between Product 1 and Diet Drinks: {mean_cross_elasticity_diet}\")\n",
        "print(f\"Mean Cross-Price Elasticity between Product 1 and Regular Drinks: {mean_cross_elasticity_regular}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSS71s9EDSt8",
        "outputId": "b680e961-dc3a-49ff-c4c8-4b9e8eb1190d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     product_ID  cross_price_elasticity\n",
            "0             1                     NaN\n",
            "1             2                0.416372\n",
            "2             3                0.416372\n",
            "3             4                0.416372\n",
            "4             5                0.416372\n",
            "..          ...                     ...\n",
            "995           6                0.416372\n",
            "996           7                0.416372\n",
            "997           8                0.416372\n",
            "998           9                0.416372\n",
            "999          10                0.416372\n",
            "\n",
            "[1000 rows x 2 columns]\n",
            "Mean Cross-Price Elasticity between Product 1 and Diet Drinks: 0.4163720940885115\n",
            "Mean Cross-Price Elasticity between Product 1 and Regular Drinks: 0.4163720940885114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ny9p0diQDoPh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(e)."
      ],
      "metadata": {
        "id": "NuzDBYEZD5ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "roblem 1(e) involves writing a function to generate the Jacobian matrix of price derivatives for a given time period. This matrix, Δ(p), contains the derivatives of the market shares of all products with respect to the prices of all products in the same time period.\n",
        "\n",
        "Jacobian Matrix of Price Derivatives\n",
        "The Jacobian matrix Δ(p) is a square matrix where each element Δ𝑖𝑗 is the derivative of the market share of product 𝑗j with respect to the price of product 𝑖:\n",
        "\n",
        "The diagonal elements\n",
        "Δ𝑗𝑗  are the own-price derivatives:\n",
        "Δ𝑗𝑗=∂𝑠𝑗/∂𝑝𝑗=α⋅sj​ ⋅(1−sj)j\n",
        "\n",
        "The off-diagonal elements\n",
        "Δ𝑖𝑗   are the cross-price derivatives:\n",
        "Δ𝑖𝑗=∂𝑠𝑗∂𝑝𝑖=−α⋅sj​ ⋅si​ for i!=j\n"
      ],
      "metadata": {
        "id": "rG9akDAfD-5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to compute the Jacobian matrix of price derivatives for a given period\n",
        "def jacobian_matrix(time_period, df, alpha):\n",
        "    # Filter the dataframe for the given time period\n",
        "    df_period = df[df['t'] == time_period]\n",
        "\n",
        "    # Get the number of products in this period\n",
        "    num_products = df_period.shape[0]\n",
        "\n",
        "    # Initialize the Jacobian matrix (num_products x num_products)\n",
        "    jacobian = np.zeros((num_products, num_products))\n",
        "\n",
        "    # Loop over all pairs of products to compute the Jacobian elements\n",
        "    for i in range(num_products):\n",
        "        for j in range(num_products):\n",
        "            # Extract market shares for product i and product j\n",
        "            s_i = df_period.iloc[i]['market_share']\n",
        "            s_j = df_period.iloc[j]['market_share']\n",
        "\n",
        "            if i == j:\n",
        "                # Own-price derivative (diagonal element)\n",
        "                jacobian[i, j] = alpha * s_j * (1 - s_j)\n",
        "            else:\n",
        "                # Cross-price derivative (off-diagonal element)\n",
        "                jacobian[i, j] = -alpha * s_j * s_i\n",
        "\n",
        "    return jacobian\n",
        "\n",
        "# Calculate the Jacobian matrix for the last time period (t = 100)\n",
        "time_period = 100  # Last period\n",
        "alpha_est = result_iv.x[0]  # Alpha parameter from the IV model (estimated)\n",
        "\n",
        "# Generate the Jacobian matrix for the given period\n",
        "jacobian_last_period = jacobian_matrix(time_period, df, alpha_est)\n",
        "\n",
        "# Print the Jacobian matrix for the last time period\n",
        "print(f\"Jacobian matrix for time period {time_period}:\")\n",
        "print(jacobian_last_period)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNJwxxaMD9E8",
        "outputId": "8eb90117-5aad-4238-bea4-a66a9deef05d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jacobian matrix for time period 100:\n",
            "[[-7.84978749e-02  1.16387376e-04  8.55287265e-04  1.70211968e-03\n",
            "   2.05111003e-02  3.27488772e-03  3.72503045e-02  8.06115650e-03\n",
            "   3.41472680e-03  3.02690381e-03]\n",
            " [ 1.16387376e-04 -1.84689472e-03  1.88830417e-05  3.75794172e-05\n",
            "   4.52844299e-04  7.23030073e-05  8.22412636e-04  1.77974302e-04\n",
            "   7.53903762e-05  6.68280157e-05]\n",
            " [ 8.55287265e-04  1.88830417e-05 -1.34522567e-02  2.76157071e-04\n",
            "   3.32778326e-03  5.31327738e-04  6.04360264e-03  1.30786654e-03\n",
            "   5.54015657e-04  4.91094075e-04]\n",
            " [ 1.70211968e-03  3.75794172e-05  2.76157071e-04 -2.64981054e-02\n",
            "   6.62267009e-03  1.05740309e-03  1.20274619e-02  2.60280430e-03\n",
            "   1.10255465e-03  9.77333493e-04]\n",
            " [ 2.05111003e-02  4.52844299e-04  3.32778326e-03  6.62267009e-03\n",
            "  -2.46128183e-01  1.27420540e-02  1.44934860e-01  3.13646453e-02\n",
            "   1.32861451e-02  1.17771891e-02]\n",
            " [ 3.27488772e-03  7.23030073e-05  5.31327738e-04  1.05740309e-03\n",
            "   1.27420540e-02 -5.00054557e-02  2.31409035e-02  5.00780993e-03\n",
            "   2.12132127e-03  1.88039507e-03]\n",
            " [ 3.72503045e-02  8.22412636e-04  6.04360264e-03  1.20274619e-02\n",
            "   1.44934860e-01  2.31409035e-02 -3.28712525e-01  5.69614780e-02\n",
            "   2.41290299e-02  2.13886078e-02]\n",
            " [ 8.06115650e-03  1.77974302e-04  1.30786654e-03  2.60280430e-03\n",
            "   3.13646453e-02  5.00780993e-03  5.69614780e-02 -1.15769795e-01\n",
            "   5.22164552e-03  4.62860416e-03]\n",
            " [ 3.41472680e-03  7.53903762e-05  5.54015657e-04  1.10255465e-03\n",
            "   1.32861451e-02  2.12132127e-03  2.41290299e-02  5.22164552e-03\n",
            "  -5.20501284e-02  1.96068873e-03]\n",
            " [ 3.02690381e-03  6.68280157e-05  4.91094075e-04  9.77333493e-04\n",
            "   1.17771891e-02  1.88039507e-03  2.13886078e-02  4.62860416e-03\n",
            "   1.96068873e-03 -4.63612878e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2(a): Nested Logit Model"
      ],
      "metadata": {
        "id": "1vkl_w2XHltD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Estimating Equation for the Nested Logit Model (2a)\n",
        "The estimating equation for the nested logit model is:\n",
        "\n",
        "log⁡𝑠𝑗𝑡−logs0​=α* pjt​ +β1*sugarjt​ +β2* ​caffeinejt​ +γd * ​Dietj+γr* ​Regularj​\n",
        " +ξjt​\n",
        "\n",
        "2.  Instruments Needed to Estimate the Model\n",
        "In nested logit models, price 𝑝𝑗𝑡 is potentially endogenous, meaning it could be correlated with unobserved characteristics like 𝜉𝑗𝑡 (unobserved product quality), leading to biased estimates. To address this, we need instrumental variables (IV) that are:\n",
        "\n",
        "Correlated with price (relevance condition).\n",
        "Uncorrelated with unobserved product quality 𝜉𝑗𝑡(exogeneity condition).\n",
        "Instruments for Price:\n",
        "Caffeine Extract Price: The price of caffeine extract affects the cost of producing caffeinated products, which in turn influences the price of the final product. However, it is unlikely to directly affect consumer demand beyond its influence on price.\n",
        "Corn Syrup Price: Similarly, the cost of corn syrup influences the price of products, especially regular sodas, without directly influencing consumer preferences beyond its impact on price.\n",
        "These two instruments are appropriate because they affect price but are unlikely to be correlated with unobserved demand shocks (𝜉𝑗𝑡)."
      ],
      "metadata": {
        "id": "FvYWUd2dIsVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# First Stage: Regress Price on Instruments\n",
        "exog_vars = ['sugar', 'caffeine', 'caffeine_extract_price', 'corn_syrup_price']\n",
        "model_stage_1 = LinearRegression()\n",
        "model_stage_1.fit(df[exog_vars], df['price'])\n",
        "\n",
        "# Predicted Price from First Stage\n",
        "df['predicted_price'] = model_stage_1.predict(df[exog_vars])\n",
        "\n",
        "# Utility Function Using Predicted Price\n",
        "def utility_nested_iv(params, predicted_price, sugar, caffeine, nest):\n",
        "    alpha, beta1, beta2, gamma_d, gamma_r, sigma = params\n",
        "    diet = (nest == 'Diet').astype(int)\n",
        "    regular = (nest != 'Diet').astype(int)\n",
        "    return alpha * predicted_price + beta1 * sugar + beta2 * caffeine + gamma_d * diet + gamma_r * regular\n",
        "\n",
        "# Log-Likelihood Function\n",
        "def log_likelihood_nested_iv(params, df):\n",
        "    delta = utility_nested_iv(params, df['predicted_price'], df['sugar'], df['caffeine'], df['nest'])\n",
        "    df['total_share'] = total_nested_share(df, delta, params[-1])  # sigma is the last parameter\n",
        "    df['log_prob'] = np.log(df['total_share']) * df['market_share']\n",
        "    return -df['log_prob'].sum()\n",
        "\n",
        "# Initial Parameter Guesses\n",
        "initial_guess_iv = [0.1, 0.1, 0.1, 0.1, 0.1, 0.5]\n",
        "\n",
        "# Minimize the Negative Log-Likelihood\n",
        "result_iv_nested = minimize(log_likelihood_nested_iv, initial_guess_iv, args=(df,), method='BFGS')\n",
        "\n",
        "# Output Parameter Estimates\n",
        "print(\"Estimated Parameters (Nested Logit with IV):\", result_iv_nested.x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miv4KG6UL4zr",
        "outputId": "32a1bb65-d83d-48c0-e54b-903599ef453c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated Parameters (Nested Logit with IV): [-0.31311738  0.23655674  0.23054275  0.12446175  0.07553254  0.65623998]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2(b)."
      ],
      "metadata": {
        "id": "i1xyk_8yLBim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate own-price derivatives\n",
        "def own_price_derivative_nested(alpha, market_share):\n",
        "    return alpha * market_share * (1 - market_share)\n",
        "\n",
        "# Function to calculate own-price elasticity\n",
        "def own_price_elasticity_nested(alpha, price, market_share):\n",
        "    return own_price_derivative_nested(alpha, market_share) * (price / market_share)\n"
      ],
      "metadata": {
        "id": "ST_10SwvMXyk"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the estimated alpha from the nested logit results\n",
        "alpha_est = result_iv_nested.x[0]  # Assuming alpha is the first parameter in the result\n",
        "\n",
        "# Calculate the own-price derivatives and elasticities for each product\n",
        "df['own_price_derivative'] = own_price_derivative_nested(alpha_est, df['market_share'])\n",
        "df['own_price_elasticity'] = own_price_elasticity_nested(alpha_est, df['price'], df['market_share'])\n",
        "\n",
        "# Print the results for a few products\n",
        "print(df[['product_ID', 'own_price_derivative', 'own_price_elasticity']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So29yYc7MZua",
        "outputId": "df051808-61ed-41b2-a753-0dcf667cbd1f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   product_ID  own_price_derivative  own_price_elasticity\n",
            "0           1             -0.030933             -0.783285\n",
            "1           2             -0.023514             -0.844049\n",
            "2           3             -0.024541             -0.706328\n",
            "3           4             -0.002234             -0.479965\n",
            "4           5             -0.004903             -0.460958\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean own-price elasticity for Diet drinks\n",
        "mean_elasticity_diet = df[df['nest'] == 'Diet']['own_price_elasticity'].mean()\n",
        "\n",
        "# Calculate mean own-price elasticity for Regular drinks\n",
        "mean_elasticity_regular = df[df['nest'] != 'Diet']['own_price_elasticity'].mean()\n",
        "\n",
        "print(f\"Mean Own-Price Elasticity for Diet Drinks: {mean_elasticity_diet}\")\n",
        "print(f\"Mean Own-Price Elasticity for Regular Drinks: {mean_elasticity_regular}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo6xBNY7McEM",
        "outputId": "4089fd54-ce05-4afd-b552-6314da50d660"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Own-Price Elasticity for Diet Drinks: -0.6603706928226208\n",
            "Mean Own-Price Elasticity for Regular Drinks: -0.93262845421865\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2(c)."
      ],
      "metadata": {
        "id": "AdVI0_RbMerR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate cross-price derivatives\n",
        "def cross_price_derivative_nested(alpha, market_share_j, market_share_k):\n",
        "    return -alpha * market_share_j * market_share_k\n",
        "\n",
        "# Function to calculate cross-price elasticity\n",
        "def cross_price_elasticity_nested(alpha, price_k, market_share_j, market_share_k):\n",
        "    return cross_price_derivative_nested(alpha, market_share_j, market_share_k) * (price_k / market_share_j)\n"
      ],
      "metadata": {
        "id": "65oTgmuQMhB_"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the market share and price for product 1\n",
        "product_1 = df[df['product_ID'] == 1]\n",
        "product_1_price = product_1['price'].values[0]\n",
        "product_1_share = product_1['market_share'].values[0]\n",
        "\n",
        "# Calculate cross-price elasticities between product 1 and all other products\n",
        "df['cross_price_elasticity'] = df.apply(\n",
        "    lambda row: cross_price_elasticity_nested(alpha_est, row['price'], product_1_share, row['market_share'])\n",
        "    if row['product_ID'] != 1 else np.nan, axis=1)\n",
        "\n",
        "# Print cross-price elasticities for a few products\n",
        "print(df[['product_ID', 'cross_price_elasticity']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5mXkTSqMzju",
        "outputId": "a30ba5c1-e261-4f6a-dac4-1126f21e026f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   product_ID  cross_price_elasticity\n",
            "0           1                     NaN\n",
            "1           2                0.075181\n",
            "2           3                0.066229\n",
            "3           4                0.003475\n",
            "4           5                0.007453\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean cross-price elasticity for Diet sodas\n",
        "mean_cross_elasticity_diet = df[df['nest'] == 'Diet']['cross_price_elasticity'].mean()\n",
        "\n",
        "# Calculate mean cross-price elasticity for Regular sodas\n",
        "mean_cross_elasticity_regular = df[df['nest'] != 'Diet']['cross_price_elasticity'].mean()\n",
        "\n",
        "print(f\"Mean Cross-Price Elasticity between Product 1 and Diet Sodas: {mean_cross_elasticity_diet}\")\n",
        "print(f\"Mean Cross-Price Elasticity between Product 1 and Regular Sodas: {mean_cross_elasticity_regular}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFN9RUBTM1zb",
        "outputId": "94cc3f0c-652a-4553-9703-46d54d5313cf"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Cross-Price Elasticity between Product 1 and Diet Sodas: 0.05358650319346212\n",
            "Mean Cross-Price Elasticity between Product 1 and Regular Sodas: 0.1486740258913465\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2(d)."
      ],
      "metadata": {
        "id": "_DNu3i49Nf36"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Multinomial Logit Model (Problem 1)\n",
        "\n",
        "1(a). Estimated Parameters:\n",
        "𝛼=−0.3286 (price coefficient),\n",
        "𝛽1=0.8538 (sugar coefficient),\n",
        "𝛽2=0.8080 (caffeine coefficient),\n",
        "𝛾𝑑=11.6125 (Diet indicator),\n",
        "𝛾𝑟=8.8466 (Regular indicator).\n",
        "These parameters show the impact of price, sugar, caffeine, and diet/regular soda types on consumer utility.\n",
        "\n",
        "1(b). Own-Price Elasticities:\n",
        "\n",
        "Diet Drinks: -0.66\n",
        "Regular Drinks: -0.93\n",
        "The own-price elasticities for diet and regular drinks are relatively small in absolute terms. This implies that consumers are somewhat price-insensitive in the multinomial logit model.\n",
        "\n",
        "1(c). Own-Price Elasticities (Corrected with Instruments):\n",
        "\n",
        "Diet Drinks: -2.81\n",
        "Regular Drinks: -3.96\n",
        "These elasticities are significantly larger in absolute value, suggesting that once we account for the correlation between price and unobserved factors (using instruments), consumers are much more sensitive to price changes.\n",
        "\n",
        "1(d). Cross-Price Elasticities:\n",
        "\n",
        "Between Product 1 and Diet Drinks: 0.416\n",
        "Between Product 1 and Regular Drinks: 0.416\n",
        "The cross-price elasticities between Product 1 and both Diet and Regular drinks are the same, showing that consumers view products across different types similarly in terms of substitutability.\n",
        "\n",
        "\n",
        "2. Nested Logit Model with IV (Problem 2)\n",
        "\n",
        "2(a). Estimated Parameters (Nested Logit with IV):\n",
        "α=−0.3131 (price coefficient),\n",
        "𝛽1=0.2366 (sugar coefficient),\n",
        "𝛽2=0.2305 (caffeine coefficient),\n",
        "𝛾𝑑=0.1245(Diet indicator),\n",
        "𝛾𝑟=0.0755 (Regular indicator),\n",
        "𝜎=0.6562 (correlation parameter for products within the same nest).\n",
        "The correlation parameter 𝜎 is positive, showing that products within the same nest (Diet or Regular) have correlated errors. This means that consumers are more likely to substitute between products within the same nest (e.g., between two Diet sodas).\n",
        "\n",
        "2(b). Own-Price Elasticities:\n",
        "\n",
        "Diet Drinks: -0.66\n",
        "Regular Drinks: -0.93\n",
        "These own-price elasticities are the same as in 1(b), showing that the introduction of the nested structure doesn't significantly change price sensitivity for individual products.\n",
        "\n",
        "2(c). Cross-Price Elasticities:\n",
        "\n",
        "Between Product 1 and Diet Drinks: 0.0536\n",
        "Between Product 1 and Regular Drinks: 0.1487\n",
        "The cross-price elasticities in the nested logit model are much smaller than in the multinomial logit model. This is likely because the nested logit model allows for stronger substitution within the same group (i.e., within Diet drinks), making cross-group substitution (between Diet and Regular) less important.\n",
        "\n",
        "\n",
        "3. Comparison of Results (Problem 2(d))\n",
        "Own-Price Elasticities: In both models, the own-price elasticities for Diet and Regular drinks are similar, with consumers being moderately sensitive to price changes in both cases.\n",
        "The elasticity magnitudes are larger (more negative) in 1(c) when using instruments, which suggests that the multinomial logit model without controlling for endogeneity underestimates price sensitivity.\n",
        "\n",
        "Cross-Price Elasticities: The cross-price elasticities in the multinomial logit model are higher and equal for both Diet and Regular drinks. This suggests that consumers are equally likely to substitute between Product 1 and other Diet or Regular products.\n",
        "In the nested logit model, cross-price elasticities are lower, with a clear difference between Diet and Regular drinks. This indicates that the nested structure allows for greater within-group substitution (e.g., between two Diet sodas), making cross-group substitution less likely.\n",
        "\n",
        "4. Insights from the Comparison:\n",
        "Elasticity of Substitution: The nested logit model introduces the parameter\n",
        "𝜎, which accounts for the correlation in consumer preferences within the same product group (e.g., Diet sodas). As a result, the substitution patterns between products differ: Within-nest substitution (e.g., between two Diet sodas) is stronger, while cross-nest substitution (e.g., between Diet and Regular) is weaker. This explains the lower cross-price elasticities in the nested logit model compared to the multinomial logit model.\n",
        "Endogeneity:\n",
        "\n",
        "In the multinomial logit model, failing to account for endogeneity (as in 1(b)) results in lower price elasticities. After correcting for endogeneity (as in 1(c)), the elasticities become larger, indicating that price is endogenous and correlated with unobserved factors (like product quality).\n",
        "Realism of the Nested Logit Model:\n",
        "\n",
        "The nested logit model provides a more realistic representation of consumer behavior, as it allows for correlated preferences within product groups (Diet vs. Regular). This flexibility makes it a more appropriate model when products are naturally grouped into categories with similar characteristics.\n",
        "Conclusion:\n",
        "The nested logit model introduces a more sophisticated structure by allowing for within-group substitution, which impacts both own-price and cross-price elasticities. The results show that consumers are more likely to switch between similar products within the same group, leading to lower cross-price elasticities between Diet and Regular products in the nested logit model.\n"
      ],
      "metadata": {
        "id": "hbRC3M3uQag8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2(e)."
      ],
      "metadata": {
        "id": "bfU9joH_R0BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to compute the Jacobian matrix of price derivatives\n",
        "def jacobian_matrix(time_period, prices, market_shares, alpha):\n",
        "    \"\"\"\n",
        "    Generate the Jacobian matrix for the nested logit model.\n",
        "\n",
        "    Parameters:\n",
        "    - time_period: The period of time for which we compute the Jacobian.\n",
        "    - prices: Array of prices for the products in the given time period.\n",
        "    - market_shares: Array of market shares for the products in the given time period.\n",
        "    - alpha: The price coefficient estimated from the model.\n",
        "\n",
        "    Returns:\n",
        "    - jacobian: The Jacobian matrix of price derivatives.\n",
        "    \"\"\"\n",
        "    num_products = len(prices)  # Number of products in the given time period\n",
        "\n",
        "    # Initialize the Jacobian matrix\n",
        "    jacobian = np.zeros((num_products, num_products))\n",
        "\n",
        "    # Loop over all products to compute the Jacobian elements\n",
        "    for i in range(num_products):\n",
        "        for j in range(num_products):\n",
        "            s_i = market_shares[i]  # Market share for product i\n",
        "            s_j = market_shares[j]  # Market share for product j\n",
        "\n",
        "            if i == j:\n",
        "                # Own-price derivative (diagonal element)\n",
        "                jacobian[i, j] = alpha * s_j * (1 - s_j)\n",
        "            else:\n",
        "                # Cross-price derivative (off-diagonal element)\n",
        "                jacobian[i, j] = -alpha * s_j * s_i\n",
        "\n",
        "    return jacobian\n",
        "\n",
        "# Example usage:\n",
        "# Assume we have already filtered the dataset for time period t=100.\n",
        "# Here's how you would pass in the necessary data.\n",
        "\n",
        "# Assuming `df` is the dataset, filtered for t = 100\n",
        "time_period = 100  # The last period in the dataset\n",
        "alpha_est = result_iv_nested.x[0]  # Alpha (price coefficient) from the nested logit model\n",
        "\n",
        "# For demonstration, let's assume df has been filtered to only include rows for t = 100\n",
        "df_time_100 = df[df['t'] == time_period]\n",
        "prices_time_100 = df_time_100['price'].values\n",
        "market_shares_time_100 = df_time_100['market_share'].values\n",
        "\n",
        "# Generate the Jacobian matrix for time period t = 100\n",
        "jacobian_last_period = jacobian_matrix(time_period, prices_time_100, market_shares_time_100, alpha_est)\n",
        "\n",
        "# Print the Jacobian matrix for the last time period\n",
        "print(f\"Jacobian matrix for time period {time_period}:\")\n",
        "print(jacobian_last_period)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5nujtpDSlC-",
        "outputId": "9ea7ed41-47ee-473e-b038-1d440ac6683a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jacobian matrix for time period 100:\n",
            "[[-1.84645610e-02  2.73770699e-05  2.01183840e-04  4.00378898e-04\n",
            "   4.82469701e-03  7.70331224e-04  8.76215466e-03  1.89617510e-03\n",
            "   8.03224692e-04  7.11999529e-04]\n",
            " [ 2.73770699e-05 -4.34433421e-04  4.44173904e-06  8.83956975e-06\n",
            "   1.06519714e-04  1.70073813e-05  1.93450948e-04  4.18637749e-05\n",
            "   1.77336036e-05  1.57195335e-05]\n",
            " [ 2.01183840e-04  4.44173904e-06 -3.16428967e-03  6.49586896e-05\n",
            "   7.82773509e-04  1.24980879e-04  1.42159861e-03  3.07641213e-04\n",
            "   1.30317616e-04  1.15516968e-04]\n",
            " [ 4.00378898e-04  8.83956975e-06  6.49586896e-05 -6.23298255e-03\n",
            "   1.55780900e-03  2.48726274e-04  2.82914416e-03  6.12241272e-04\n",
            "   2.59346991e-04  2.29892006e-04]\n",
            " [ 4.82469701e-03  1.06519714e-04  7.82773509e-04  1.55780900e-03\n",
            "  -5.78951833e-02  2.99723316e-03  3.40921148e-02  7.37770808e-03\n",
            "   3.12521628e-03  2.77027405e-03]\n",
            " [ 7.70331224e-04  1.70073813e-05  1.24980879e-04  2.48726274e-04\n",
            "   2.99723316e-03 -1.17624686e-02  5.44328907e-03  1.17795561e-03\n",
            "   4.98985050e-04  4.42313495e-04]\n",
            " [ 8.76215466e-03  1.93450948e-04  1.42159861e-03  2.82914416e-03\n",
            "   3.40921148e-02  5.44328907e-03 -7.73209781e-02  1.33986899e-02\n",
            "   5.67571981e-03  5.03110758e-03]\n",
            " [ 1.89617510e-03  4.18637749e-05  3.07641213e-04  6.12241272e-04\n",
            "   7.37770808e-03  1.17795561e-03  1.33986899e-02 -2.72318002e-02\n",
            "   1.22825481e-03  1.08875742e-03]\n",
            " [ 8.03224692e-04  1.77336036e-05  1.30317616e-04  2.59346991e-04\n",
            "   3.12521628e-03  4.98985050e-04  5.67571981e-03  1.22825481e-03\n",
            "  -1.22434241e-02  4.61200468e-04]\n",
            " [ 7.11999529e-04  1.57195335e-05  1.15516968e-04  2.29892006e-04\n",
            "   2.77027405e-03  4.42313495e-04  5.03110758e-03  1.08875742e-03\n",
            "   4.61200468e-04 -1.09052739e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3(a). A simple supply side"
      ],
      "metadata": {
        "id": "ixyBysWKS9rL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Given: Total market size M_t\n",
        "M_t = 100000\n",
        "\n",
        "# Function to compute own-price derivatives\n",
        "def own_price_derivative_nested(alpha, market_share):\n",
        "    return alpha * market_share * (1 - market_share)\n",
        "\n",
        "# Function to calculate marginal cost and Lerner Index for all products\n",
        "def calculate_marginal_cost_and_lerner(df, alpha):\n",
        "    \"\"\"\n",
        "    Calculate marginal costs and Lerner Indices for all products across all periods.\n",
        "\n",
        "    Parameters:\n",
        "    df: DataFrame containing product data (prices, market shares, etc.)\n",
        "    alpha: The price coefficient from the nested logit model.\n",
        "\n",
        "    Returns:\n",
        "    df: DataFrame with calculated marginal costs and Lerner Indices.\n",
        "    \"\"\"\n",
        "    # Step 1: Calculate own-price derivatives\n",
        "    df['own_price_derivative'] = own_price_derivative_nested(alpha, df['market_share'])\n",
        "\n",
        "    # Step 2: Calculate quantity for each product\n",
        "    df['quantity'] = df['market_share'] * M_t\n",
        "\n",
        "    # Step 3: Calculate marginal cost c_jt\n",
        "    df['marginal_cost'] = df['price'] + df['quantity'] / (df['own_price_derivative'] * M_t)\n",
        "\n",
        "    # Step 4: Calculate Lerner Index\n",
        "    df['lerner_index'] = (df['price'] - df['marginal_cost']) / df['price']\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage:\n",
        "# Assuming `df` is the dataset containing prices, market shares, etc.\n",
        "# `alpha_est` is the price coefficient from the nested logit model (obtained in 2(a))\n",
        "\n",
        "alpha_est = -0.32866229  # Replace with the actual alpha value from your nested logit estimation\n",
        "\n",
        "# Load the dataset (assuming 'df' contains 'price', 'market_share', etc.)\n",
        "df = pd.read_csv('product_data.csv')\n",
        "\n",
        "# Calculate marginal costs and Lerner index for all products\n",
        "df = calculate_marginal_cost_and_lerner(df, alpha_est)\n",
        "\n",
        "# Calculate the mean Lerner Index\n",
        "mean_lerner_index = df['lerner_index'].mean()\n",
        "\n",
        "# Print results\n",
        "print(f\"Mean Lerner Index: {mean_lerner_index}\")\n",
        "print(df[['product_ID', 'price', 'marginal_cost', 'lerner_index']].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7GPMlIFT8OD",
        "outputId": "e8b03ce0-f34c-4f54-ddc3-d17ae0774ea7"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Lerner Index: 1.3374086307738406\n",
            "   product_ID     price  marginal_cost  lerner_index\n",
            "0           1  2.814362      -0.608721      1.216291\n",
            "1           2  2.935735      -0.377914      1.128729\n",
            "2           3  2.467309      -0.860621      1.348810\n",
            "3           4  1.543958      -1.520706      1.984940\n",
            "4           5  1.495961      -1.595872      2.066787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3(b)."
      ],
      "metadata": {
        "id": "srMk1V7hUHIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import fsolve\n",
        "\n",
        "# Function to compute own-price and cross-price derivatives\n",
        "def price_derivative(alpha, market_share):\n",
        "    return alpha * market_share * (1 - market_share)\n",
        "\n",
        "# Function to compute cross-price derivative\n",
        "def cross_price_derivative(alpha, market_share_i, market_share_j):\n",
        "    return -alpha * market_share_i * market_share_j\n",
        "\n",
        "# Function to simulate prices after the merger\n",
        "def simulate_merged_prices(alpha, p1, p2, c1, c2, s1, s2, M_t):\n",
        "    \"\"\"\n",
        "    Simulate the new prices for Products 1 and 2 after the merger.\n",
        "    \"\"\"\n",
        "\n",
        "    def system_of_equations(prices):\n",
        "        p1_new, p2_new = prices\n",
        "\n",
        "        # Derivatives\n",
        "        dp1_dp1 = price_derivative(alpha, s1)\n",
        "        dp2_dp2 = price_derivative(alpha, s2)\n",
        "        dp2_dp1 = cross_price_derivative(alpha, s2, s1)\n",
        "        dp1_dp2 = cross_price_derivative(alpha, s1, s2)\n",
        "\n",
        "        # First-order conditions for merged firm\n",
        "        f1 = s1 * M_t + (p1_new - c1) * dp1_dp1 * M_t + (p2_new - c2) * dp2_dp1 * M_t\n",
        "        f2 = s2 * M_t + (p2_new - c2) * dp2_dp2 * M_t + (p1_new - c1) * dp1_dp2 * M_t\n",
        "\n",
        "        return [f1, f2]\n",
        "\n",
        "    # Initial guess for new prices (starting from current prices)\n",
        "    initial_guess = [p1, p2]\n",
        "\n",
        "    # Solve for new prices\n",
        "    new_prices = fsolve(system_of_equations, initial_guess)\n",
        "\n",
        "    return new_prices\n",
        "\n",
        "# Example usage:\n",
        "# Parameters for Products 1 and 2\n",
        "alpha = -0.32866229  # Price sensitivity parameter\n",
        "M_t = 100000  # Market size\n",
        "\n",
        "# Prices, costs, and market shares before the merger (for t = 100)\n",
        "p1 = df[df['product_ID'] == 1]['price'].values[0]\n",
        "p2 = df[df['product_ID'] == 2]['price'].values[0]\n",
        "c1 = df[df['product_ID'] == 1]['marginal_cost'].values[0]\n",
        "c2 = df[df['product_ID'] == 2]['marginal_cost'].values[0]\n",
        "s1 = df[df['product_ID'] == 1]['market_share'].values[0]\n",
        "s2 = df[df['product_ID'] == 2]['market_share'].values[0]\n",
        "\n",
        "# Simulate the new prices after the merger\n",
        "p1_new, p2_new = simulate_merged_prices(alpha, p1, p2, c1, c2, s1, s2, M_t)\n",
        "\n",
        "print(f\"New price for Product 1: {p1_new}\")\n",
        "print(f\"New price for Product 2: {p2_new}\")\n",
        "# Prices, costs, and market shares before the merger (for t = 100)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1E_yrBPUMPT",
        "outputId": "6c6b789a-15cb-46fc-b1e4-0287f1b8dbd0"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New price for Product 1: 3.1612479741342456\n",
            "New price for Product 2: 3.392055479995622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already extracted the original prices p1 and p2,\n",
        "# and you have the new prices p1_new and p2_new from the simulation\n",
        "\n",
        "# Function to display the price changes\n",
        "def show_price_changes(p1, p2, p1_new, p2_new):\n",
        "    # Calculate the price changes\n",
        "    price_change_1 = p1_new - p1\n",
        "    price_change_2 = p2_new - p2\n",
        "\n",
        "    # Print the original prices, new prices, and price changes\n",
        "    print(f\"Pre-merger price for Product 1: {p1}\")\n",
        "    print(f\"Post-merger price for Product 1: {p1_new}\")\n",
        "    print(f\"Price change for Product 1: {price_change_1}\\n\")\n",
        "\n",
        "    print(f\"Pre-merger price for Product 2: {p2}\")\n",
        "    print(f\"Post-merger price for Product 2: {p2_new}\")\n",
        "    print(f\"Price change for Product 2: {price_change_2}\")\n",
        "\n",
        "# Example usage\n",
        "p1 = df[df['product_ID'] == 1]['price'].values[0]  # Pre-merger price for Product 1\n",
        "p2 = df[df['product_ID'] == 2]['price'].values[0]  # Pre-merger price for Product 2\n",
        "\n",
        "# Assuming you have already run the simulation to get p1_new and p2_new:\n",
        "p1_new = 3.1612479741342456  # New price for Product 1\n",
        "p2_new = 3.392055479995622   # New price for Product 2\n",
        "\n",
        "# Call the function to display the results\n",
        "show_price_changes(p1, p2, p1_new, p2_new)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB_zYzx0VRyh",
        "outputId": "648f7e78-ac13-4720-ed9f-5543b5cdb330"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-merger price for Product 1: 2.81436164900233\n",
            "Post-merger price for Product 1: 3.1612479741342456\n",
            "Price change for Product 1: 0.34688632513191564\n",
            "\n",
            "Pre-merger price for Product 2: 2.93573518294224\n",
            "Post-merger price for Product 2: 3.392055479995622\n",
            "Price change for Product 2: 0.4563202970533822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the merger, both prices are higher because the merged firm now maximizes joint profits, reducing competition between Product 1 and Product 2. In your simulation, the price of Product 2 increased more than Product 1, which may reflect stronger interdependencies between the two products' demand."
      ],
      "metadata": {
        "id": "YD0pPN2fWS0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3(c)."
      ],
      "metadata": {
        "id": "jpviPtScWUm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-merger prices for Products 1 and 2\n",
        "p1_pre = df[df['product_ID'] == 1]['price'].values[0]\n",
        "p2_pre = df[df['product_ID'] == 2]['price'].values[0]\n",
        "\n",
        "# Post-merger prices (from the simulation in 3(b))\n",
        "p1_post = p1_new  # New price for Product 1 after the merger\n",
        "p2_post = p2_new  # New price for Product 2 after the merger\n",
        "\n",
        "# Average price for Products 1 and 2 before and after the merger\n",
        "avg_price_pre_merge = (p1_pre + p2_pre) / 2\n",
        "avg_price_post_merge = (p1_post + p2_post) / 2\n",
        "\n",
        "print(f\"Average price for Products 1 and 2 before the merger: {avg_price_pre_merge}\")\n",
        "print(f\"Average price for Products 1 and 2 after the merger: {avg_price_post_merge}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9AcIANnWXhP",
        "outputId": "2f1bf16c-1c79-4483-c1de-b6fde27377a9"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average price for Products 1 and 2 before the merger: 2.8750484159722847\n",
            "Average price for Products 1 and 2 after the merger: 3.276651727064934\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the nest of Products 1 and 2 (assuming they're in the same nest)\n",
        "nest_merged = df[df['product_ID'] == 1]['nest'].values[0]  # Get the nest of Product 1 (same as Product 2)\n",
        "\n",
        "# Pre-merger average price for competing products in the same nest (excluding Products 1 and 2)\n",
        "competing_same_nest_pre = df[(df['nest'] == nest_merged) & (~df['product_ID'].isin([1, 2]))]['price'].mean()\n",
        "\n",
        "# Assuming the prices of competing products in the same nest remain the same after the merger\n",
        "# (this can change depending on your simulation of other prices)\n",
        "competing_same_nest_post = competing_same_nest_pre  # You can update this if you simulate new prices for other products\n",
        "\n",
        "print(f\"Average price for competing products in the same nest before the merger: {competing_same_nest_pre}\")\n",
        "print(f\"Average price for competing products in the same nest after the merger: {competing_same_nest_post}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLn0mvBJWoVh",
        "outputId": "1d73baf4-aa37-4170-d01c-6fe084f56a70"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average price for competing products in the same nest before the merger: 2.291027917217075\n",
            "Average price for competing products in the same nest after the merger: 2.291027917217075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Different nest (Diet or Regular, opposite of the merged firms' nest)\n",
        "nest_different = df[df['nest'] != nest_merged]['nest'].unique()[0]  # Get the opposite nest\n",
        "\n",
        "# Pre-merger average price for competing products in a different nest\n",
        "competing_different_nest_pre = df[df['nest'] == nest_different]['price'].mean()\n",
        "\n",
        "# Assuming the prices of competing products in the different nest remain the same after the merger\n",
        "# (this can change depending on your simulation of other prices)\n",
        "competing_different_nest_post = competing_different_nest_pre  # You can update this if you simulate new prices for other products\n",
        "\n",
        "print(f\"Average price for competing products in a different nest before the merger: {competing_different_nest_pre}\")\n",
        "print(f\"Average price for competing products in a different nest after the merger: {competing_different_nest_post}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcfnKVo-WoXA",
        "outputId": "204a844c-b4c8-4910-e240-c061ddf679f3"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average price for competing products in a different nest before the merger: 3.453345402367383\n",
            "Average price for competing products in a different nest after the merger: 3.453345402367383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average Price for Products 1 and 2 (the merging firms):\n",
        "\n",
        "Before the merger: 2.875\n",
        "After the merger: 3.277\n",
        "Price increase: +0.402 (approximately a 14% increase)\n",
        "The prices for Products 1 and 2 rose significantly after the merger, indicating that the merged firm has reduced competitive pressure between these two products and is now able to raise prices to maximize joint profits.\n",
        "\n",
        "Average Price for Competing Products in the Same Nest (products in the same category as Products 1 and 2):\n",
        "\n",
        "Before the merger: 2.291\n",
        "After the merger: 2.291\n",
        "No price change.\n",
        "There was no change in the prices of competing products in the same nest. This suggests that the merger did not have a direct impact on other products in the same category as Products 1 and 2. These products might be sufficiently differentiated or not directly affected by the pricing strategy of the merged firm.\n",
        "\n",
        "Average Price for Competing Products in a Different Nest (products in the opposite category):\n",
        "\n",
        "Before the merger: 3.453\n",
        "After the merger: 3.453\n",
        "No price change.\n",
        "Similarly, there was no change in the prices of competing products in the different nest (likely Diet products, assuming Products 1 and 2 are in the Regular nest). This suggests that the merger of Products 1 and 2 did not spill over to affect the pricing of products in the other nest.\n",
        "\n",
        "Conclusion:\n",
        "The merger resulted in a substantial price increase for the merging firms (Products 1 and 2), but there was no impact on the prices of other products in either the same nest or the different nest. This indicates that the price effects of the merger were localized to the products involved in the merger, with no observable spillover effects on other competing products."
      ],
      "metadata": {
        "id": "7K6GsQDwXRK5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3(d)."
      ],
      "metadata": {
        "id": "6ukgPaTTXaK-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import minimize, Bounds\n",
        "\n",
        "# Function to calculate total industry profit under collusion with elasticity\n",
        "def total_collusive_profit_with_elasticity(prices, costs, market_shares, M_t, elasticity):\n",
        "    total_profit = 0\n",
        "    for i in range(len(prices)):\n",
        "        # Adjust demand based on price elasticity (demand decreases as prices increase)\n",
        "        q_i = market_shares[i] * M_t * (prices[i] / df['price'].values[i]) ** (-elasticity)\n",
        "        total_profit += (prices[i] - costs[i]) * q_i  # Profit for product i\n",
        "    return -total_profit  # Negative because we minimize the function\n",
        "\n",
        "# Function to simulate collusive prices with elasticity\n",
        "def simulate_collusive_prices_with_elasticity(df, M_t, elasticity):\n",
        "    costs = df['marginal_cost'].values  # Marginal costs for all products\n",
        "    market_shares = df['market_share'].values  # Market shares for all products\n",
        "    initial_prices = df['price'].values  # Initial prices for starting point\n",
        "\n",
        "    # Set bounds to ensure reasonable prices (allow flexibility, but avoid extremes)\n",
        "    price_bounds = Bounds([1] * len(initial_prices), [15] * len(initial_prices))\n",
        "\n",
        "    # Objective function for collusion with elasticity (negative total profit for minimization)\n",
        "    result = minimize(total_collusive_profit_with_elasticity, initial_prices, args=(costs, market_shares, M_t, elasticity), method='L-BFGS-B', bounds=price_bounds)\n",
        "\n",
        "    # Return the optimized (collusive) prices\n",
        "    collusive_prices = result.x\n",
        "    return collusive_prices\n",
        "\n",
        "# Example usage for t=100\n",
        "M_t = 100000  # Total market size\n",
        "elasticity = 1.5  # Assuming moderate elasticity of demand (adjust as necessary)\n",
        "\n",
        "# Simulate collusive prices with elasticity for all products\n",
        "collusive_prices = simulate_collusive_prices_with_elasticity(df, M_t, elasticity)\n",
        "\n",
        "# Store the collusive prices in the DataFrame\n",
        "df['collusive_price'] = collusive_prices\n",
        "\n",
        "# Summary of results (for 3(c) and 3(d))\n",
        "summary_table = df[['product_ID', 'price', 'post_merger_price', 'collusive_price']]\n",
        "\n",
        "# Display the summary table\n",
        "print(summary_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYvCovxffvVM",
        "outputId": "a18676f0-13a2-4eee-a694-0c46111f7392"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   product_ID     price  post_merger_price  collusive_price\n",
            "0           1  3.486057           5.229085         4.926429\n",
            "1           2  2.443659           3.665489         8.997678\n",
            "2           3  2.245954           2.245954         3.814568\n",
            "3           4  2.939509           2.939509         7.320600\n",
            "4           5  2.000106           2.000106         5.170345\n",
            "5           6  2.475500           2.475500         3.345687\n",
            "6           7  3.005230           3.005230         6.459757\n",
            "7           8  3.985661           3.985661         8.009267\n",
            "8           9  3.060981           3.060981         6.014365\n",
            "9          10  2.529298           2.529298         7.409441\n"
          ]
        }
      ]
    }
  ]
}