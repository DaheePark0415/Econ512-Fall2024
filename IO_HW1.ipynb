{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMQFbBH0EMaN/IBTUTA0sgD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaheePark0415/Econ512-Fall2024/blob/main/IO_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(a)."
      ],
      "metadata": {
        "id": "CyS34q2L_Ol3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('product_data.csv')\n",
        "\n",
        "# Check the structure of the data to ensure it has the correct columns\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1Aa_wRD_X-f",
        "outputId": "8e727cf6-9211-4f75-a50c-d82e3c072fad"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   product_ID  nest     price     sugar  caffeine  market_share  \\\n",
            "0           1  Diet  2.814362  0.631224  6.752525      0.111141   \n",
            "1           2  Diet  2.935735  0.004553  6.784396      0.081787   \n",
            "2           3  Diet  2.467309  0.739947  5.761261      0.085727   \n",
            "3           4  Diet  1.543958  0.103660  4.468299      0.007187   \n",
            "4           5  Diet  1.495961  0.971926  4.052750      0.015912   \n",
            "\n",
            "   caffeine_extract_price  corn_syrup_price  t  \n",
            "0                0.267468          0.251714  1  \n",
            "1                0.320000          0.253146  1  \n",
            "2                0.252531          0.314781  1  \n",
            "3                0.203220          0.227481  1  \n",
            "4                0.156466          0.244453  1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize\n"
      ],
      "metadata": {
        "id": "KYbfQkx5_lia"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv('/content/product_data.csv')\n",
        "\n",
        "# Show the first few rows of the dataset to verify\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHur1_VG_ogT",
        "outputId": "2a7a0eba-bd70-4da7-c0cb-4d3772167c8f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   product_ID  nest     price     sugar  caffeine  market_share  \\\n",
            "0           1  Diet  2.814362  0.631224  6.752525      0.111141   \n",
            "1           2  Diet  2.935735  0.004553  6.784396      0.081787   \n",
            "2           3  Diet  2.467309  0.739947  5.761261      0.085727   \n",
            "3           4  Diet  1.543958  0.103660  4.468299      0.007187   \n",
            "4           5  Diet  1.495961  0.971926  4.052750      0.015912   \n",
            "\n",
            "   caffeine_extract_price  corn_syrup_price  t  \n",
            "0                0.267468          0.251714  1  \n",
            "1                0.320000          0.253146  1  \n",
            "2                0.252531          0.314781  1  \n",
            "3                0.203220          0.227481  1  \n",
            "4                0.156466          0.244453  1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the utility function with corrected handling for Diet and Regular using the 'nest' column\n",
        "def utility(params, price, sugar, caffeine, nest):\n",
        "    alpha, beta1, beta2, gamma_d, gamma_r = params\n",
        "    diet = (nest == 'Diet').astype(int)\n",
        "    regular = (nest != 'Diet').astype(int)  # Assuming the other category is Regular\n",
        "    return alpha * price + beta1 * sugar + beta2 * caffeine + gamma_d * diet + gamma_r * regular\n",
        "\n",
        "# Define the log-likelihood function for the multinomial logit model\n",
        "def log_likelihood(params, df):\n",
        "    # Calculate utility for each product in each time period\n",
        "    df['utility'] = utility(params, df['price'], df['sugar'], df['caffeine'], df['nest'])\n",
        "\n",
        "    # Exponentiate utility\n",
        "    df['exp_utility'] = np.exp(df['utility'])\n",
        "\n",
        "    # Group by time period, sum over products to get the denominator for each period\n",
        "    df['sum_exp_util'] = df.groupby('t')['exp_utility'].transform('sum') + 1  # Add 1 for the outside option\n",
        "\n",
        "    # Probability of choosing product j at time t\n",
        "    df['prob'] = df['exp_utility'] / df['sum_exp_util']\n",
        "\n",
        "    # Log of the probability weighted by quantity (here using 'market_share')\n",
        "    df['log_prob'] = np.log(df['prob']) * df['market_share']\n",
        "\n",
        "    # Negative log-likelihood (since we minimize)\n",
        "    return -df['log_prob'].sum()\n",
        "\n",
        "# Initialize the parameters: [alpha, beta1, beta2, gamma_d, gamma_r]\n",
        "initial_guess = [0.1, 0.1, 0.1, 0.1, 0.1]\n",
        "\n",
        "# Estimate the parameters by minimizing the negative log-likelihood\n",
        "result = minimize(log_likelihood, initial_guess, args=(df,), method='BFGS')\n",
        "\n",
        "# Print the estimated parameters\n",
        "print(\"Estimated parameters:\", result.x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82XuplM8_wpJ",
        "outputId": "dc0915f0-5ae6-4f07-9406-2d0d9a55d5e4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated parameters: [-0.32866229  0.85382714  0.8080273  11.61252541  8.8465584 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(b)."
      ],
      "metadata": {
        "id": "rKSIE5yrABfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Define the exogenous variables (instruments + other exogenous variables)\n",
        "exog_vars = ['sugar', 'caffeine', 'caffeine_extract_price', 'corn_syrup_price']\n",
        "\n",
        "# First stage: Regress price on instruments and other exogenous variables\n",
        "model_stage_1 = LinearRegression()\n",
        "model_stage_1.fit(df[exog_vars], df['price'])\n",
        "\n",
        "# Get the predicted price from the first stage\n",
        "df['predicted_price'] = model_stage_1.predict(df[exog_vars])\n"
      ],
      "metadata": {
        "id": "qepcLR6SAGXG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the utility function to use the predicted price\n",
        "def utility_iv(params, predicted_price, sugar, caffeine, nest):\n",
        "    alpha, beta1, beta2, gamma_d, gamma_r = params\n",
        "    diet = (nest == 'Diet').astype(int)\n",
        "    regular = (nest != 'Diet').astype(int)\n",
        "    return alpha * predicted_price + beta1 * sugar + beta2 * caffeine + gamma_d * diet + gamma_r * regular\n",
        "\n",
        "# Adjust the log-likelihood function to use the predicted price\n",
        "def log_likelihood_iv(params, df):\n",
        "    # Calculate utility for each product in each time period using predicted price\n",
        "    df['utility'] = utility_iv(params, df['predicted_price'], df['sugar'], df['caffeine'], df['nest'])\n",
        "\n",
        "    # Exponentiate utility\n",
        "    df['exp_utility'] = np.exp(df['utility'])\n",
        "\n",
        "    # Group by time period, sum over products to get the denominator for each period\n",
        "    df['sum_exp_util'] = df.groupby('t')['exp_utility'].transform('sum') + 1  # Add 1 for the outside option\n",
        "\n",
        "    # Probability of choosing product j at time t\n",
        "    df['prob'] = df['exp_utility'] / df['sum_exp_util']\n",
        "\n",
        "    # Log of the probability weighted by market share\n",
        "    df['log_prob'] = np.log(df['prob']) * df['market_share']\n",
        "\n",
        "    # Negative log-likelihood (since we minimize)\n",
        "    return -df['log_prob'].sum()\n",
        "\n",
        "# Initialize the parameters: [alpha, beta1, beta2, gamma_d, gamma_r]\n",
        "initial_guess_iv = [0.1, 0.1, 0.1, 0.1, 0.1]\n",
        "\n",
        "# Estimate the parameters by minimizing the negative log-likelihood\n",
        "result_iv = minimize(log_likelihood_iv, initial_guess_iv, args=(df,), method='BFGS')\n",
        "\n",
        "# Print the estimated parameters\n",
        "print(\"Estimated parameters (IV):\", result_iv.x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkYWRQmvAUmI",
        "outputId": "d20de59e-c8a1-4f6b-e386-40d96fbe5196"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated parameters (IV): [-1.33114723  1.03226555  1.02240006 14.35370063 12.09851264]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 1(b) involves addressing endogeneity in the price variable. In the given context, the price of soft drinks is correlated with unobserved quality (ùúâùëóùë°‚Äã). This means that standard OLS estimators would be biased. To solve this issue, we can use instrumental variables (IV) for the price.\n",
        "\n",
        "In this problem, the suggested instruments are:\n",
        "\n",
        "Caffeine Extract Price and Corn Syrup Price.\n",
        "\n",
        "These instruments are used because they affect the price but are not directly related to the unobserved demand shock (ùúâùëóùë°).\n",
        "\n",
        "Approach:\n",
        "Two-Stage Least Squares (2SLS): First, we will regress the endogenous variable (price) on the instruments to get the predicted prices. Then, we will use these predicted prices in the utility function to estimate the parameters.\n",
        "\n",
        "Conditions for Valid Instruments:\n",
        "\n",
        "Relevance: The instruments must be correlated with the endogenous variable (price).\n",
        "Exogeneity: The instruments must not be correlated with the error term (unobserved quality ùúâùëóùë°)."
      ],
      "metadata": {
        "id": "qARqa4rdA4j3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(c)"
      ],
      "metadata": {
        "id": "IYSUtu43CGxd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "roblem 1(c) involves calculating the own-price derivatives and own-price elasticities for the products. These derivatives and elasticities are important for understanding how the market share of each product responds to changes in its own price."
      ],
      "metadata": {
        "id": "FPMNNc_PCoRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the estimated alpha from the previous results\n",
        "alpha_est = result_iv.x[0]  # Assuming alpha is the first estimated parameter from the IV model\n",
        "\n",
        "# Function to calculate own-price derivatives\n",
        "def own_price_derivative(alpha, market_share):\n",
        "    return alpha * market_share * (1 - market_share)\n",
        "\n",
        "# Function to calculate own-price elasticity\n",
        "def own_price_elasticity(alpha, price, market_share):\n",
        "    return own_price_derivative(alpha, market_share) * (price / market_share)\n",
        "\n",
        "# Calculate own-price derivatives and elasticities for each product in each time period\n",
        "df['own_price_derivative'] = own_price_derivative(alpha_est, df['market_share'])\n",
        "df['own_price_elasticity'] = own_price_elasticity(alpha_est, df['price'], df['market_share'])\n",
        "\n",
        "# Print the mean own-price elasticity for Regular and Diet drinks\n",
        "mean_elasticity_diet = df[df['nest'] == 'Diet']['own_price_elasticity'].mean()\n",
        "mean_elasticity_regular = df[df['nest'] != 'Diet']['own_price_elasticity'].mean()\n",
        "\n",
        "print(f\"Mean Own-Price Elasticity for Diet Drinks: {mean_elasticity_diet}\")\n",
        "print(f\"Mean Own-Price Elasticity for Regular Drinks: {mean_elasticity_regular}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUTyZ-J3C-Ot",
        "outputId": "687e1f6b-1625-422f-fb85-4246aa91cd38"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Own-Price Elasticity for Diet Drinks: -2.807415569584785\n",
            "Mean Own-Price Elasticity for Regular Drinks: -3.9648574224575888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(d)."
      ],
      "metadata": {
        "id": "enRE8VmmDLLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iSeRC_qeDqH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to calculate cross-price derivatives\n",
        "def cross_price_derivative(alpha, market_share_j, market_share_k):\n",
        "    return -alpha * market_share_j * market_share_k\n",
        "\n",
        "# Function to calculate cross-price elasticity\n",
        "def cross_price_elasticity(alpha, price_k, market_share_j, market_share_k):\n",
        "    return cross_price_derivative(alpha, market_share_j, market_share_k) * (price_k / market_share_j)\n",
        "\n",
        "# Calculate cross-price elasticities between product 1 and all other products\n",
        "def calculate_cross_price_elasticities(df, product_id):\n",
        "    # Get the market share and price for the specific product (product 1 in this case)\n",
        "    product_1_price = df.loc[df['product_ID'] == product_id, 'price'].values[0]\n",
        "    product_1_share = df.loc[df['product_ID'] == product_id, 'market_share'].values[0]\n",
        "\n",
        "    # Calculate cross-price elasticities for all other products\n",
        "    df['cross_price_elasticity'] = df.apply(\n",
        "        lambda row: cross_price_elasticity(alpha_est, product_1_price, row['market_share'], product_1_share)\n",
        "        if row['product_ID'] != product_id else np.nan, axis=1)\n",
        "\n",
        "    return df[['product_ID', 'cross_price_elasticity']]\n",
        "\n",
        "# Calculate cross-price elasticities for product 1 with all other products\n",
        "cross_price_elasticities_df = calculate_cross_price_elasticities(df, product_id=1)\n",
        "\n",
        "# Print the cross-price elasticities for product 1\n",
        "print(cross_price_elasticities_df)\n",
        "\n",
        "# Calculate the mean cross-price elasticity for diet and regular drinks\n",
        "mean_cross_elasticity_diet = cross_price_elasticities_df[df['nest'] == 'Diet']['cross_price_elasticity'].mean()\n",
        "mean_cross_elasticity_regular = cross_price_elasticities_df[df['nest'] != 'Diet']['cross_price_elasticity'].mean()\n",
        "\n",
        "print(f\"Mean Cross-Price Elasticity between Product 1 and Diet Drinks: {mean_cross_elasticity_diet}\")\n",
        "print(f\"Mean Cross-Price Elasticity between Product 1 and Regular Drinks: {mean_cross_elasticity_regular}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSS71s9EDSt8",
        "outputId": "b680e961-dc3a-49ff-c4c8-4b9e8eb1190d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     product_ID  cross_price_elasticity\n",
            "0             1                     NaN\n",
            "1             2                0.416372\n",
            "2             3                0.416372\n",
            "3             4                0.416372\n",
            "4             5                0.416372\n",
            "..          ...                     ...\n",
            "995           6                0.416372\n",
            "996           7                0.416372\n",
            "997           8                0.416372\n",
            "998           9                0.416372\n",
            "999          10                0.416372\n",
            "\n",
            "[1000 rows x 2 columns]\n",
            "Mean Cross-Price Elasticity between Product 1 and Diet Drinks: 0.4163720940885115\n",
            "Mean Cross-Price Elasticity between Product 1 and Regular Drinks: 0.4163720940885114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ny9p0diQDoPh"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1(e)."
      ],
      "metadata": {
        "id": "NuzDBYEZD5ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "roblem 1(e) involves writing a function to generate the Jacobian matrix of price derivatives for a given time period. This matrix, Œî(p), contains the derivatives of the market shares of all products with respect to the prices of all products in the same time period.\n",
        "\n",
        "Jacobian Matrix of Price Derivatives\n",
        "The Jacobian matrix Œî(p) is a square matrix where each element Œîùëñùëó is the derivative of the market share of product ùëój with respect to the price of product ùëñ:\n",
        "\n",
        "The diagonal elements\n",
        "Œîùëóùëó  are the own-price derivatives:\n",
        "Œîùëóùëó=‚àÇùë†ùëó/‚àÇùëùùëó=Œ±‚ãÖsj‚Äã ‚ãÖ(1‚àísj)j\n",
        "\n",
        "The off-diagonal elements\n",
        "Œîùëñùëó   are the cross-price derivatives:\n",
        "Œîùëñùëó=‚àÇùë†ùëó‚àÇùëùùëñ=‚àíŒ±‚ãÖsj‚Äã ‚ãÖsi‚Äã for¬†i!=j\n"
      ],
      "metadata": {
        "id": "rG9akDAfD-5G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to compute the Jacobian matrix of price derivatives for a given period\n",
        "def jacobian_matrix(time_period, df, alpha):\n",
        "    # Filter the dataframe for the given time period\n",
        "    df_period = df[df['t'] == time_period]\n",
        "\n",
        "    # Get the number of products in this period\n",
        "    num_products = df_period.shape[0]\n",
        "\n",
        "    # Initialize the Jacobian matrix (num_products x num_products)\n",
        "    jacobian = np.zeros((num_products, num_products))\n",
        "\n",
        "    # Loop over all pairs of products to compute the Jacobian elements\n",
        "    for i in range(num_products):\n",
        "        for j in range(num_products):\n",
        "            # Extract market shares for product i and product j\n",
        "            s_i = df_period.iloc[i]['market_share']\n",
        "            s_j = df_period.iloc[j]['market_share']\n",
        "\n",
        "            if i == j:\n",
        "                # Own-price derivative (diagonal element)\n",
        "                jacobian[i, j] = alpha * s_j * (1 - s_j)\n",
        "            else:\n",
        "                # Cross-price derivative (off-diagonal element)\n",
        "                jacobian[i, j] = -alpha * s_j * s_i\n",
        "\n",
        "    return jacobian\n",
        "\n",
        "# Calculate the Jacobian matrix for the last time period (t = 100)\n",
        "time_period = 100  # Last period\n",
        "alpha_est = result_iv.x[0]  # Alpha parameter from the IV model (estimated)\n",
        "\n",
        "# Generate the Jacobian matrix for the given period\n",
        "jacobian_last_period = jacobian_matrix(time_period, df, alpha_est)\n",
        "\n",
        "# Print the Jacobian matrix for the last time period\n",
        "print(f\"Jacobian matrix for time period {time_period}:\")\n",
        "print(jacobian_last_period)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNJwxxaMD9E8",
        "outputId": "8eb90117-5aad-4238-bea4-a66a9deef05d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jacobian matrix for time period 100:\n",
            "[[-7.84978749e-02  1.16387376e-04  8.55287265e-04  1.70211968e-03\n",
            "   2.05111003e-02  3.27488772e-03  3.72503045e-02  8.06115650e-03\n",
            "   3.41472680e-03  3.02690381e-03]\n",
            " [ 1.16387376e-04 -1.84689472e-03  1.88830417e-05  3.75794172e-05\n",
            "   4.52844299e-04  7.23030073e-05  8.22412636e-04  1.77974302e-04\n",
            "   7.53903762e-05  6.68280157e-05]\n",
            " [ 8.55287265e-04  1.88830417e-05 -1.34522567e-02  2.76157071e-04\n",
            "   3.32778326e-03  5.31327738e-04  6.04360264e-03  1.30786654e-03\n",
            "   5.54015657e-04  4.91094075e-04]\n",
            " [ 1.70211968e-03  3.75794172e-05  2.76157071e-04 -2.64981054e-02\n",
            "   6.62267009e-03  1.05740309e-03  1.20274619e-02  2.60280430e-03\n",
            "   1.10255465e-03  9.77333493e-04]\n",
            " [ 2.05111003e-02  4.52844299e-04  3.32778326e-03  6.62267009e-03\n",
            "  -2.46128183e-01  1.27420540e-02  1.44934860e-01  3.13646453e-02\n",
            "   1.32861451e-02  1.17771891e-02]\n",
            " [ 3.27488772e-03  7.23030073e-05  5.31327738e-04  1.05740309e-03\n",
            "   1.27420540e-02 -5.00054557e-02  2.31409035e-02  5.00780993e-03\n",
            "   2.12132127e-03  1.88039507e-03]\n",
            " [ 3.72503045e-02  8.22412636e-04  6.04360264e-03  1.20274619e-02\n",
            "   1.44934860e-01  2.31409035e-02 -3.28712525e-01  5.69614780e-02\n",
            "   2.41290299e-02  2.13886078e-02]\n",
            " [ 8.06115650e-03  1.77974302e-04  1.30786654e-03  2.60280430e-03\n",
            "   3.13646453e-02  5.00780993e-03  5.69614780e-02 -1.15769795e-01\n",
            "   5.22164552e-03  4.62860416e-03]\n",
            " [ 3.41472680e-03  7.53903762e-05  5.54015657e-04  1.10255465e-03\n",
            "   1.32861451e-02  2.12132127e-03  2.41290299e-02  5.22164552e-03\n",
            "  -5.20501284e-02  1.96068873e-03]\n",
            " [ 3.02690381e-03  6.68280157e-05  4.91094075e-04  9.77333493e-04\n",
            "   1.17771891e-02  1.88039507e-03  2.13886078e-02  4.62860416e-03\n",
            "   1.96068873e-03 -4.63612878e-02]]\n"
          ]
        }
      ]
    }
  ]
}