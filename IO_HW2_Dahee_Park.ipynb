{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaheePark0415/Econ512-Fall2024/blob/main/IO_HW2_Dahee_Park.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RG5JSGicTpu2"
      },
      "outputs": [],
      "source": [
        "# importing necessary packages\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "from scipy.optimize import minimize\n",
        "import matplotlib.pyplot as plt\n",
        "from joblib import Parallel, delayed\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MYgtZG8Tpu3"
      },
      "source": [
        "# 1(a):\n",
        "Compute $$ \\bar{y}_{t}, σ_{y_{t}}, \\bar{p}_{t} $$ for each market.\n",
        "Compute $$ cor(\\bar{y}_{t}, \\bar{p}_{t}) $$\n",
        ". Do consumers in wealthier markets buy more expensive products on average?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "UgxsxcM6Tpu4",
        "outputId": "b6a817b5-3f7b-41b0-b37b-c4dc6f00e0f4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ParserError",
          "evalue": "Error tokenizing data. C error: Expected 3 fields in line 257573, saw 4\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ca1f66516f85>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdemo_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'consumer_census.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mincome_mean_var_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdemo_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'income'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'var'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmarket_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'product_data_ps2.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weighted_price'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'market_share'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmarket_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 3 fields in line 257573, saw 4\n"
          ]
        }
      ],
      "source": [
        "demo_data = pd.read_csv('consumer_census.csv')\n",
        "income_mean_var_price = demo_data.groupby('t')['income'].agg(['mean', 'var'])\n",
        "\n",
        "market_data = pd.read_csv('product_data_ps2.csv')\n",
        "market_data['weighted_price'] = market_data['market_share']*market_data['price']\n",
        "\n",
        "income_mean_var_price['mean_price'] = market_data.groupby('t')['weighted_price'].sum()\n",
        "market_data = market_data.drop(columns=['weighted_price'])\n",
        "\n",
        "income_mean_var_price = income_mean_var_price.rename(columns={'mean':'mean_income', 'var':'var_income'})\n",
        "print(income_mean_var_price.head(5))\n",
        "\n",
        "corr = income_mean_var_price['mean_income'].corr(income_mean_var_price['mean_price'])\n",
        "\n",
        "print(f'The correlation between mean income and average price among markets is {corr}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw664gMzTpu5"
      },
      "source": [
        "# 1(b) Draw Consumer Data\n",
        "A function 'draw_consumer' generates a simulated sample of consumers based on the observed distribution of income and unobserved heterogeneity for sugar and caffeine preferences.\n",
        "\n",
        "*   true_distribution : The observed distribution of income values from the census data\n",
        "*   S : the sample size, i.e. the number of consumers to be simulated\n",
        "*   seed : the random seed for reproducibility\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0EB6KQXTpu5",
        "outputId": "9ae15833-a92a-49ca-f388-fcc14a498a8d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_income</th>\n",
              "      <th>var_income</th>\n",
              "      <th>mean_nu_1</th>\n",
              "      <th>var_nu_1</th>\n",
              "      <th>mean_nu_2</th>\n",
              "      <th>var_nu_2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.917419</td>\n",
              "      <td>0.252275</td>\n",
              "      <td>0.060583</td>\n",
              "      <td>0.791416</td>\n",
              "      <td>0.152795</td>\n",
              "      <td>0.877388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.570960</td>\n",
              "      <td>0.239593</td>\n",
              "      <td>-0.103741</td>\n",
              "      <td>1.086306</td>\n",
              "      <td>0.128241</td>\n",
              "      <td>1.243061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.949333</td>\n",
              "      <td>0.239335</td>\n",
              "      <td>-0.108637</td>\n",
              "      <td>1.143517</td>\n",
              "      <td>-0.032944</td>\n",
              "      <td>0.780795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.430244</td>\n",
              "      <td>0.251779</td>\n",
              "      <td>0.035274</td>\n",
              "      <td>0.956122</td>\n",
              "      <td>0.021808</td>\n",
              "      <td>0.881465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4.450541</td>\n",
              "      <td>0.238198</td>\n",
              "      <td>0.091547</td>\n",
              "      <td>0.875472</td>\n",
              "      <td>0.027212</td>\n",
              "      <td>1.076421</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_income  var_income  mean_nu_1  var_nu_1  mean_nu_2  var_nu_2\n",
              "t                                                                   \n",
              "1     5.917419    0.252275   0.060583  0.791416   0.152795  0.877388\n",
              "2     4.570960    0.239593  -0.103741  1.086306   0.128241  1.243061\n",
              "3     5.949333    0.239335  -0.108637  1.143517  -0.032944  0.780795\n",
              "4     4.430244    0.251779   0.035274  0.956122   0.021808  0.881465\n",
              "5     4.450541    0.238198   0.091547  0.875472   0.027212  1.076421"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def gen_consumer(Market_number:int, Size:int, Seed:int)->float:\n",
        "    # This function draws customers from a market\n",
        "    # argument for seed is included for replicability\n",
        "\n",
        "    sample = demo_data[demo_data.t == Market_number].sample(n=Size, replace=True, random_state=Seed) # Sampling with replacement\n",
        "\n",
        "    np.random.seed(Seed)\n",
        "\n",
        "    sample['nu_1'], sample['nu_2'] = np.random.standard_normal(Size), np.random.standard_normal(Size)\n",
        "\n",
        "    return sample\n",
        "\n",
        "temp = {'mean_income':[], 'var_income':[], 'mean_nu_1':[], 'var_nu_1':[], 'mean_nu_2':[], 'var_nu_2':[]}\n",
        "\n",
        "for i in range(1, 51):\n",
        "    simulated_data = gen_consumer(i, 100, i) # As there is no instruction, I will use market number as the seed each market\n",
        "    temp['mean_income'].append(simulated_data['income'].mean())\n",
        "    temp['var_income'].append(simulated_data['income'].var())\n",
        "    temp['mean_nu_1'].append(simulated_data['nu_1'].mean())\n",
        "    temp['var_nu_1'].append(simulated_data['nu_1'].var())\n",
        "    temp['mean_nu_2'].append(simulated_data['nu_2'].mean())\n",
        "    temp['var_nu_2'].append(simulated_data['nu_2'].var())\n",
        "\n",
        "df = pd.DataFrame(temp)\n",
        "df.index += 1\n",
        "df.index.name = 't'\n",
        "\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZh-fGgvTpu5"
      },
      "source": [
        " Generating larger, comprehensive samples (500 consumers) for each market and combining them into one unified DataFrame (CONSUMER).\n",
        "\n",
        " This code creates a unified DataFrame called simulated_consumer that contains consumer data simulated for all markets (from 1 to 50), with 500 consumers per market. The resulting DataFrame organizes the consumer characteristics (income, nu_1, nu_2) along with the market identifier (t)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSulkJRJTpu5",
        "outputId": "b078ee5f-6cda-4797-f538-0bbb1751b0ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     income      nu_1      nu_2  t\n",
            "0  5.989803  1.624345 -1.719394  1\n",
            "1  5.200218 -0.611756  0.057121  1\n",
            "2  6.145651 -0.528172 -0.799547  1\n",
            "3  5.320450 -1.072969 -0.291595  1\n",
            "4  6.454278  0.865408 -0.258983  1\n"
          ]
        }
      ],
      "source": [
        "simulated_consumer = pd.DataFrame()\n",
        "\n",
        "for i in range(1, 51):\n",
        "    temp = gen_consumer(i, 500, i)\n",
        "    temp = temp.drop(columns=['consumer_ID'])\n",
        "    simulated_consumer = pd.concat([simulated_consumer, temp])\n",
        "\n",
        "simulated_consumer = simulated_consumer.reset_index(drop=True)[['income', 'nu_1', 'nu_2', 't']]\n",
        "print(simulated_consumer.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPAxo0hYTpu5"
      },
      "source": [
        "# 1(c) Estimate share equation\n",
        "The task is to calculate the probability that consumer $i$ in market $t$, with characteristics given by $ y_{it}, \\nu_{1it},$ and $\\nu_{2it}$, chooses product $j$. The probability is given by:\n",
        "\n",
        "$s_{ijt}(\\delta_t, \\theta_2) = \\frac{\\exp(\\delta_{jt} + \\mu_{ijt}(\\theta_2))}{1 + \\sum_{k \\in J_t} \\exp(\\delta_{kt} + \\mu_{ikt}(\\theta_2))}\n",
        "$\n",
        "\n",
        "where:\n",
        "- $ \\delta_{jt} $ represents the mean utility for product j in market t.\n",
        "- $ \\mu_{ijt}(\\theta_2)$ is the consumer-specific utility component influenced by the parameters $ \\theta_2 = \\{\\alpha, \\sigma_1, \\sigma_2\\}$\n",
        "\n",
        "The function should use the consumer and market data to compute these probabilities for all products and consumers in market $t$. The log-sum-exp trick should be applied to ensure numerical stability, especially when handling large or very small exponential values.\n",
        "\n",
        "$ \\delta_{t}= \\{\\delta_{1t}, \\ldots, \\delta_{J_{t},t}\\} $: This represents the vector of mean utilities for products $1$ to $j_{t}$ in market $t$.\n",
        "\n",
        "$ \\theta_{2} = \\{\\alpha, \\sigma_1, \\sigma_2\\} $: This vector contains the parameters where:\n",
        "\n",
        "The probabilities should be calculated using the log-sum-exp function to ensure numerical stability, especially when handling large or very small exponential valuesection to the Provided Code The code you shared computes these choice probabilities using the logit model approach, incorporating the log-sum-exp trick for stability.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80pE_vyvTpu6",
        "outputId": "3ca36d3e-5770-4d1b-b96c-a8b67aa8d925"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 31.2 ms\n",
            "Wall time: 27 ms\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prob_1</th>\n",
              "      <th>Prob_2</th>\n",
              "      <th>Prob_3</th>\n",
              "      <th>Prob_4</th>\n",
              "      <th>Prob_5</th>\n",
              "      <th>Prob_6</th>\n",
              "      <th>Prob_7</th>\n",
              "      <th>Prob_8</th>\n",
              "      <th>Prob_9</th>\n",
              "      <th>Prob_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Prob_41</th>\n",
              "      <th>Prob_42</th>\n",
              "      <th>Prob_43</th>\n",
              "      <th>Prob_44</th>\n",
              "      <th>Prob_45</th>\n",
              "      <th>Prob_46</th>\n",
              "      <th>Prob_47</th>\n",
              "      <th>Prob_48</th>\n",
              "      <th>Prob_49</th>\n",
              "      <th>Prob_50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.011320</td>\n",
              "      <td>0.016083</td>\n",
              "      <td>0.011806</td>\n",
              "      <td>0.014005</td>\n",
              "      <td>0.011482</td>\n",
              "      <td>0.008297</td>\n",
              "      <td>0.012041</td>\n",
              "      <td>0.013920</td>\n",
              "      <td>0.014621</td>\n",
              "      <td>0.016126</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023780</td>\n",
              "      <td>0.016176</td>\n",
              "      <td>0.020872</td>\n",
              "      <td>0.047673</td>\n",
              "      <td>0.035726</td>\n",
              "      <td>0.052284</td>\n",
              "      <td>0.025130</td>\n",
              "      <td>0.026186</td>\n",
              "      <td>0.025864</td>\n",
              "      <td>0.019614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.021976</td>\n",
              "      <td>0.019592</td>\n",
              "      <td>0.017874</td>\n",
              "      <td>0.016092</td>\n",
              "      <td>0.016833</td>\n",
              "      <td>0.021871</td>\n",
              "      <td>0.021555</td>\n",
              "      <td>0.025404</td>\n",
              "      <td>0.017821</td>\n",
              "      <td>0.018589</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017527</td>\n",
              "      <td>0.020119</td>\n",
              "      <td>0.016583</td>\n",
              "      <td>0.022393</td>\n",
              "      <td>0.025021</td>\n",
              "      <td>0.021257</td>\n",
              "      <td>0.021935</td>\n",
              "      <td>0.021409</td>\n",
              "      <td>0.017491</td>\n",
              "      <td>0.016397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.020071</td>\n",
              "      <td>0.019344</td>\n",
              "      <td>0.017782</td>\n",
              "      <td>0.016605</td>\n",
              "      <td>0.017289</td>\n",
              "      <td>0.018142</td>\n",
              "      <td>0.019947</td>\n",
              "      <td>0.022351</td>\n",
              "      <td>0.018184</td>\n",
              "      <td>0.019095</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018817</td>\n",
              "      <td>0.019707</td>\n",
              "      <td>0.017812</td>\n",
              "      <td>0.024801</td>\n",
              "      <td>0.026044</td>\n",
              "      <td>0.024907</td>\n",
              "      <td>0.022063</td>\n",
              "      <td>0.021729</td>\n",
              "      <td>0.019213</td>\n",
              "      <td>0.017745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.023202</td>\n",
              "      <td>0.019891</td>\n",
              "      <td>0.019596</td>\n",
              "      <td>0.017150</td>\n",
              "      <td>0.018990</td>\n",
              "      <td>0.022885</td>\n",
              "      <td>0.022593</td>\n",
              "      <td>0.025033</td>\n",
              "      <td>0.018877</td>\n",
              "      <td>0.019428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017032</td>\n",
              "      <td>0.020325</td>\n",
              "      <td>0.016557</td>\n",
              "      <td>0.019300</td>\n",
              "      <td>0.022372</td>\n",
              "      <td>0.018705</td>\n",
              "      <td>0.020444</td>\n",
              "      <td>0.019827</td>\n",
              "      <td>0.016977</td>\n",
              "      <td>0.016741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.015551</td>\n",
              "      <td>0.017538</td>\n",
              "      <td>0.012884</td>\n",
              "      <td>0.013320</td>\n",
              "      <td>0.011706</td>\n",
              "      <td>0.013660</td>\n",
              "      <td>0.015902</td>\n",
              "      <td>0.020850</td>\n",
              "      <td>0.014791</td>\n",
              "      <td>0.016237</td>\n",
              "      <td>...</td>\n",
              "      <td>0.020312</td>\n",
              "      <td>0.018059</td>\n",
              "      <td>0.017734</td>\n",
              "      <td>0.039050</td>\n",
              "      <td>0.035611</td>\n",
              "      <td>0.038046</td>\n",
              "      <td>0.026087</td>\n",
              "      <td>0.026304</td>\n",
              "      <td>0.021083</td>\n",
              "      <td>0.016606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>0.022450</td>\n",
              "      <td>0.019598</td>\n",
              "      <td>0.018051</td>\n",
              "      <td>0.015925</td>\n",
              "      <td>0.017042</td>\n",
              "      <td>0.022069</td>\n",
              "      <td>0.021938</td>\n",
              "      <td>0.025895</td>\n",
              "      <td>0.017853</td>\n",
              "      <td>0.018677</td>\n",
              "      <td>...</td>\n",
              "      <td>0.017161</td>\n",
              "      <td>0.020159</td>\n",
              "      <td>0.016234</td>\n",
              "      <td>0.022017</td>\n",
              "      <td>0.025129</td>\n",
              "      <td>0.020976</td>\n",
              "      <td>0.021799</td>\n",
              "      <td>0.021179</td>\n",
              "      <td>0.017152</td>\n",
              "      <td>0.016141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>0.013997</td>\n",
              "      <td>0.017787</td>\n",
              "      <td>0.015824</td>\n",
              "      <td>0.017468</td>\n",
              "      <td>0.016408</td>\n",
              "      <td>0.010381</td>\n",
              "      <td>0.014587</td>\n",
              "      <td>0.014553</td>\n",
              "      <td>0.017875</td>\n",
              "      <td>0.018967</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023198</td>\n",
              "      <td>0.017682</td>\n",
              "      <td>0.021849</td>\n",
              "      <td>0.033625</td>\n",
              "      <td>0.027869</td>\n",
              "      <td>0.038219</td>\n",
              "      <td>0.022204</td>\n",
              "      <td>0.022758</td>\n",
              "      <td>0.024969</td>\n",
              "      <td>0.021646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>0.028305</td>\n",
              "      <td>0.020158</td>\n",
              "      <td>0.023149</td>\n",
              "      <td>0.018094</td>\n",
              "      <td>0.022925</td>\n",
              "      <td>0.030569</td>\n",
              "      <td>0.026674</td>\n",
              "      <td>0.027700</td>\n",
              "      <td>0.020073</td>\n",
              "      <td>0.019970</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014099</td>\n",
              "      <td>0.020606</td>\n",
              "      <td>0.014477</td>\n",
              "      <td>0.012064</td>\n",
              "      <td>0.016436</td>\n",
              "      <td>0.011423</td>\n",
              "      <td>0.016946</td>\n",
              "      <td>0.016003</td>\n",
              "      <td>0.013652</td>\n",
              "      <td>0.015233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>0.024514</td>\n",
              "      <td>0.019839</td>\n",
              "      <td>0.018912</td>\n",
              "      <td>0.016041</td>\n",
              "      <td>0.017704</td>\n",
              "      <td>0.025795</td>\n",
              "      <td>0.023643</td>\n",
              "      <td>0.028017</td>\n",
              "      <td>0.018042</td>\n",
              "      <td>0.018638</td>\n",
              "      <td>...</td>\n",
              "      <td>0.015998</td>\n",
              "      <td>0.020469</td>\n",
              "      <td>0.015351</td>\n",
              "      <td>0.018793</td>\n",
              "      <td>0.022836</td>\n",
              "      <td>0.017359</td>\n",
              "      <td>0.020808</td>\n",
              "      <td>0.020025</td>\n",
              "      <td>0.015708</td>\n",
              "      <td>0.015351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>0.018962</td>\n",
              "      <td>0.018680</td>\n",
              "      <td>0.015219</td>\n",
              "      <td>0.014429</td>\n",
              "      <td>0.014022</td>\n",
              "      <td>0.017590</td>\n",
              "      <td>0.018932</td>\n",
              "      <td>0.023896</td>\n",
              "      <td>0.016235</td>\n",
              "      <td>0.017467</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018689</td>\n",
              "      <td>0.019268</td>\n",
              "      <td>0.016894</td>\n",
              "      <td>0.030066</td>\n",
              "      <td>0.030893</td>\n",
              "      <td>0.028852</td>\n",
              "      <td>0.024319</td>\n",
              "      <td>0.024030</td>\n",
              "      <td>0.019039</td>\n",
              "      <td>0.016278</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 50 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Prob_1    Prob_2    Prob_3    Prob_4    Prob_5    Prob_6    Prob_7  \\\n",
              "0    0.011320  0.016083  0.011806  0.014005  0.011482  0.008297  0.012041   \n",
              "1    0.021976  0.019592  0.017874  0.016092  0.016833  0.021871  0.021555   \n",
              "2    0.020071  0.019344  0.017782  0.016605  0.017289  0.018142  0.019947   \n",
              "3    0.023202  0.019891  0.019596  0.017150  0.018990  0.022885  0.022593   \n",
              "4    0.015551  0.017538  0.012884  0.013320  0.011706  0.013660  0.015902   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "495  0.022450  0.019598  0.018051  0.015925  0.017042  0.022069  0.021938   \n",
              "496  0.013997  0.017787  0.015824  0.017468  0.016408  0.010381  0.014587   \n",
              "497  0.028305  0.020158  0.023149  0.018094  0.022925  0.030569  0.026674   \n",
              "498  0.024514  0.019839  0.018912  0.016041  0.017704  0.025795  0.023643   \n",
              "499  0.018962  0.018680  0.015219  0.014429  0.014022  0.017590  0.018932   \n",
              "\n",
              "       Prob_8    Prob_9   Prob_10  ...   Prob_41   Prob_42   Prob_43  \\\n",
              "0    0.013920  0.014621  0.016126  ...  0.023780  0.016176  0.020872   \n",
              "1    0.025404  0.017821  0.018589  ...  0.017527  0.020119  0.016583   \n",
              "2    0.022351  0.018184  0.019095  ...  0.018817  0.019707  0.017812   \n",
              "3    0.025033  0.018877  0.019428  ...  0.017032  0.020325  0.016557   \n",
              "4    0.020850  0.014791  0.016237  ...  0.020312  0.018059  0.017734   \n",
              "..        ...       ...       ...  ...       ...       ...       ...   \n",
              "495  0.025895  0.017853  0.018677  ...  0.017161  0.020159  0.016234   \n",
              "496  0.014553  0.017875  0.018967  ...  0.023198  0.017682  0.021849   \n",
              "497  0.027700  0.020073  0.019970  ...  0.014099  0.020606  0.014477   \n",
              "498  0.028017  0.018042  0.018638  ...  0.015998  0.020469  0.015351   \n",
              "499  0.023896  0.016235  0.017467  ...  0.018689  0.019268  0.016894   \n",
              "\n",
              "      Prob_44   Prob_45   Prob_46   Prob_47   Prob_48   Prob_49   Prob_50  \n",
              "0    0.047673  0.035726  0.052284  0.025130  0.026186  0.025864  0.019614  \n",
              "1    0.022393  0.025021  0.021257  0.021935  0.021409  0.017491  0.016397  \n",
              "2    0.024801  0.026044  0.024907  0.022063  0.021729  0.019213  0.017745  \n",
              "3    0.019300  0.022372  0.018705  0.020444  0.019827  0.016977  0.016741  \n",
              "4    0.039050  0.035611  0.038046  0.026087  0.026304  0.021083  0.016606  \n",
              "..        ...       ...       ...       ...       ...       ...       ...  \n",
              "495  0.022017  0.025129  0.020976  0.021799  0.021179  0.017152  0.016141  \n",
              "496  0.033625  0.027869  0.038219  0.022204  0.022758  0.024969  0.021646  \n",
              "497  0.012064  0.016436  0.011423  0.016946  0.016003  0.013652  0.015233  \n",
              "498  0.018793  0.022836  0.017359  0.020808  0.020025  0.015708  0.015351  \n",
              "499  0.030066  0.030893  0.028852  0.024319  0.024030  0.019039  0.016278  \n",
              "\n",
              "[500 rows x 50 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "def calculate_indiv_choice_prob(delta: np.array, theta: np.array, cons_data: pd.DataFrame, prod_data: pd.DataFrame) -> pd.DataFrame:\n",
        "    # returns individual consumers' prob. vector of choosing the products\n",
        "    # inputs: (estimated) delta, (estimated) theta, (simulated) consumer info, and product(Market) info\n",
        "    # Use equation given to calcaulte prob. of choosing a product\n",
        "\n",
        "    alpha, sigma1, sigma2 = theta\n",
        "\n",
        "    prod_data['alpha_price'], prod_data['sigma1_sugar'], prod_data['sigma2_caffeine'] = prod_data['price'].multiply(alpha), prod_data['sugar'].multiply(sigma1), prod_data['caffeine'].multiply(sigma2)\n",
        "\n",
        "    utility_labels = ['utility_'+str(j) for j in range(1, 51)]\n",
        "    share_labels = ['Prob_'+str(j) for j in range(1, 51)]\n",
        "\n",
        "    cons_data[utility_labels] = np.matmul(cons_data[['income', 'nu_1', 'nu_2']].values, prod_data[['alpha_price', 'sigma1_sugar', 'sigma2_caffeine']].values.T) + np.tile(delta, len(cons_data)).reshape(len(cons_data), len(delta))\n",
        "        # The above line calculates \\delta + \\mu with the assumed parameter values\n",
        "\n",
        "    cons_data['IncVal'] = np.log(cons_data[utility_labels].apply(np.exp).sum(axis = 1)+1)\n",
        "\n",
        "    cons_data[share_labels] = np.exp(cons_data[utility_labels].values-np.tile(cons_data['IncVal'].values, (50, 1)).T)\n",
        "\n",
        "    cons_data = cons_data[share_labels]\n",
        "\n",
        "    return cons_data\n",
        "\n",
        "calculate_indiv_choice_prob(50*[1], [.1, .1, .1], simulated_consumer[simulated_consumer.t == 1], market_data[market_data.t == 1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXBG8BrGTpu6"
      },
      "source": [
        "# 1(d). Compute the conditional shares $S_{ijt}$\n",
        "The task in 1(d) is to compute the choice probabilities for consumers across all markets and return a unified DataFrame containing these probabilities. The goal is to implement a function, generate_total_df, which maps given parameters and product attributes to the resulting choice probabilities for each product in each market. This function essentially extends the method developed in 1(c) to cover all markets (from 1 to 50) comprehensively.\n",
        "\n",
        "*  Iterating through all markets (1 to 50).\n",
        "*  Computing these probabilities based on product attributes and model parameters.\n",
        "*  Combining the results into a single, unified DataFrame that contains choice probabilities for each consumer in each market.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHaxRGEQTpu6",
        "outputId": "8e746fb2-31bb-402f-8140-8b430ef557e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: total: 10.7 s\n",
            "Wall time: 2.61 s\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prob_1</th>\n",
              "      <th>Prob_2</th>\n",
              "      <th>Prob_3</th>\n",
              "      <th>Prob_4</th>\n",
              "      <th>Prob_5</th>\n",
              "      <th>Prob_6</th>\n",
              "      <th>Prob_7</th>\n",
              "      <th>Prob_8</th>\n",
              "      <th>Prob_9</th>\n",
              "      <th>Prob_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Prob_41</th>\n",
              "      <th>Prob_42</th>\n",
              "      <th>Prob_43</th>\n",
              "      <th>Prob_44</th>\n",
              "      <th>Prob_45</th>\n",
              "      <th>Prob_46</th>\n",
              "      <th>Prob_47</th>\n",
              "      <th>Prob_48</th>\n",
              "      <th>Prob_49</th>\n",
              "      <th>Prob_50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.011167</td>\n",
              "      <td>0.016010</td>\n",
              "      <td>0.008614</td>\n",
              "      <td>0.011992</td>\n",
              "      <td>0.006659</td>\n",
              "      <td>0.014940</td>\n",
              "      <td>0.011940</td>\n",
              "      <td>0.019120</td>\n",
              "      <td>0.011355</td>\n",
              "      <td>0.012018</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023610</td>\n",
              "      <td>0.016467</td>\n",
              "      <td>0.019658</td>\n",
              "      <td>0.049733</td>\n",
              "      <td>0.034503</td>\n",
              "      <td>0.038958</td>\n",
              "      <td>0.029779</td>\n",
              "      <td>0.032066</td>\n",
              "      <td>0.022819</td>\n",
              "      <td>0.015901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.011167</td>\n",
              "      <td>0.016010</td>\n",
              "      <td>0.008614</td>\n",
              "      <td>0.011992</td>\n",
              "      <td>0.006659</td>\n",
              "      <td>0.014940</td>\n",
              "      <td>0.011940</td>\n",
              "      <td>0.019120</td>\n",
              "      <td>0.011355</td>\n",
              "      <td>0.012018</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023610</td>\n",
              "      <td>0.016467</td>\n",
              "      <td>0.019658</td>\n",
              "      <td>0.049733</td>\n",
              "      <td>0.034503</td>\n",
              "      <td>0.038958</td>\n",
              "      <td>0.029779</td>\n",
              "      <td>0.032066</td>\n",
              "      <td>0.022819</td>\n",
              "      <td>0.015901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.011167</td>\n",
              "      <td>0.016010</td>\n",
              "      <td>0.008614</td>\n",
              "      <td>0.011992</td>\n",
              "      <td>0.006659</td>\n",
              "      <td>0.014940</td>\n",
              "      <td>0.011940</td>\n",
              "      <td>0.019120</td>\n",
              "      <td>0.011355</td>\n",
              "      <td>0.012018</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023610</td>\n",
              "      <td>0.016467</td>\n",
              "      <td>0.019658</td>\n",
              "      <td>0.049733</td>\n",
              "      <td>0.034503</td>\n",
              "      <td>0.038958</td>\n",
              "      <td>0.029779</td>\n",
              "      <td>0.032066</td>\n",
              "      <td>0.022819</td>\n",
              "      <td>0.015901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.011167</td>\n",
              "      <td>0.016010</td>\n",
              "      <td>0.008614</td>\n",
              "      <td>0.011992</td>\n",
              "      <td>0.006659</td>\n",
              "      <td>0.014940</td>\n",
              "      <td>0.011940</td>\n",
              "      <td>0.019120</td>\n",
              "      <td>0.011355</td>\n",
              "      <td>0.012018</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023610</td>\n",
              "      <td>0.016467</td>\n",
              "      <td>0.019658</td>\n",
              "      <td>0.049733</td>\n",
              "      <td>0.034503</td>\n",
              "      <td>0.038958</td>\n",
              "      <td>0.029779</td>\n",
              "      <td>0.032066</td>\n",
              "      <td>0.022819</td>\n",
              "      <td>0.015901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.011167</td>\n",
              "      <td>0.016010</td>\n",
              "      <td>0.008614</td>\n",
              "      <td>0.011992</td>\n",
              "      <td>0.006659</td>\n",
              "      <td>0.014940</td>\n",
              "      <td>0.011940</td>\n",
              "      <td>0.019120</td>\n",
              "      <td>0.011355</td>\n",
              "      <td>0.012018</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023610</td>\n",
              "      <td>0.016467</td>\n",
              "      <td>0.019658</td>\n",
              "      <td>0.049733</td>\n",
              "      <td>0.034503</td>\n",
              "      <td>0.038958</td>\n",
              "      <td>0.029779</td>\n",
              "      <td>0.032066</td>\n",
              "      <td>0.022819</td>\n",
              "      <td>0.015901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>0.007747</td>\n",
              "      <td>0.008908</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.015061</td>\n",
              "      <td>0.008732</td>\n",
              "      <td>0.006141</td>\n",
              "      <td>0.008557</td>\n",
              "      <td>0.009395</td>\n",
              "      <td>0.014914</td>\n",
              "      <td>0.011239</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044125</td>\n",
              "      <td>0.032571</td>\n",
              "      <td>0.028406</td>\n",
              "      <td>0.020437</td>\n",
              "      <td>0.046219</td>\n",
              "      <td>0.016794</td>\n",
              "      <td>0.016745</td>\n",
              "      <td>0.040449</td>\n",
              "      <td>0.012979</td>\n",
              "      <td>0.015360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>0.007747</td>\n",
              "      <td>0.008908</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.015061</td>\n",
              "      <td>0.008732</td>\n",
              "      <td>0.006141</td>\n",
              "      <td>0.008557</td>\n",
              "      <td>0.009395</td>\n",
              "      <td>0.014914</td>\n",
              "      <td>0.011239</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044125</td>\n",
              "      <td>0.032571</td>\n",
              "      <td>0.028406</td>\n",
              "      <td>0.020437</td>\n",
              "      <td>0.046219</td>\n",
              "      <td>0.016794</td>\n",
              "      <td>0.016745</td>\n",
              "      <td>0.040449</td>\n",
              "      <td>0.012979</td>\n",
              "      <td>0.015360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>0.007747</td>\n",
              "      <td>0.008908</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.015061</td>\n",
              "      <td>0.008732</td>\n",
              "      <td>0.006141</td>\n",
              "      <td>0.008557</td>\n",
              "      <td>0.009395</td>\n",
              "      <td>0.014914</td>\n",
              "      <td>0.011239</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044125</td>\n",
              "      <td>0.032571</td>\n",
              "      <td>0.028406</td>\n",
              "      <td>0.020437</td>\n",
              "      <td>0.046219</td>\n",
              "      <td>0.016794</td>\n",
              "      <td>0.016745</td>\n",
              "      <td>0.040449</td>\n",
              "      <td>0.012979</td>\n",
              "      <td>0.015360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>0.007747</td>\n",
              "      <td>0.008908</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.015061</td>\n",
              "      <td>0.008732</td>\n",
              "      <td>0.006141</td>\n",
              "      <td>0.008557</td>\n",
              "      <td>0.009395</td>\n",
              "      <td>0.014914</td>\n",
              "      <td>0.011239</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044125</td>\n",
              "      <td>0.032571</td>\n",
              "      <td>0.028406</td>\n",
              "      <td>0.020437</td>\n",
              "      <td>0.046219</td>\n",
              "      <td>0.016794</td>\n",
              "      <td>0.016745</td>\n",
              "      <td>0.040449</td>\n",
              "      <td>0.012979</td>\n",
              "      <td>0.015360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>0.007747</td>\n",
              "      <td>0.008908</td>\n",
              "      <td>0.011236</td>\n",
              "      <td>0.015061</td>\n",
              "      <td>0.008732</td>\n",
              "      <td>0.006141</td>\n",
              "      <td>0.008557</td>\n",
              "      <td>0.009395</td>\n",
              "      <td>0.014914</td>\n",
              "      <td>0.011239</td>\n",
              "      <td>...</td>\n",
              "      <td>0.044125</td>\n",
              "      <td>0.032571</td>\n",
              "      <td>0.028406</td>\n",
              "      <td>0.020437</td>\n",
              "      <td>0.046219</td>\n",
              "      <td>0.016794</td>\n",
              "      <td>0.016745</td>\n",
              "      <td>0.040449</td>\n",
              "      <td>0.012979</td>\n",
              "      <td>0.015360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 50 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Prob_1    Prob_2    Prob_3    Prob_4    Prob_5    Prob_6    Prob_7  \\\n",
              "0      0.011167  0.016010  0.008614  0.011992  0.006659  0.014940  0.011940   \n",
              "1      0.011167  0.016010  0.008614  0.011992  0.006659  0.014940  0.011940   \n",
              "2      0.011167  0.016010  0.008614  0.011992  0.006659  0.014940  0.011940   \n",
              "3      0.011167  0.016010  0.008614  0.011992  0.006659  0.014940  0.011940   \n",
              "4      0.011167  0.016010  0.008614  0.011992  0.006659  0.014940  0.011940   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "24995  0.007747  0.008908  0.011236  0.015061  0.008732  0.006141  0.008557   \n",
              "24996  0.007747  0.008908  0.011236  0.015061  0.008732  0.006141  0.008557   \n",
              "24997  0.007747  0.008908  0.011236  0.015061  0.008732  0.006141  0.008557   \n",
              "24998  0.007747  0.008908  0.011236  0.015061  0.008732  0.006141  0.008557   \n",
              "24999  0.007747  0.008908  0.011236  0.015061  0.008732  0.006141  0.008557   \n",
              "\n",
              "         Prob_8    Prob_9   Prob_10  ...   Prob_41   Prob_42   Prob_43  \\\n",
              "0      0.019120  0.011355  0.012018  ...  0.023610  0.016467  0.019658   \n",
              "1      0.019120  0.011355  0.012018  ...  0.023610  0.016467  0.019658   \n",
              "2      0.019120  0.011355  0.012018  ...  0.023610  0.016467  0.019658   \n",
              "3      0.019120  0.011355  0.012018  ...  0.023610  0.016467  0.019658   \n",
              "4      0.019120  0.011355  0.012018  ...  0.023610  0.016467  0.019658   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "24995  0.009395  0.014914  0.011239  ...  0.044125  0.032571  0.028406   \n",
              "24996  0.009395  0.014914  0.011239  ...  0.044125  0.032571  0.028406   \n",
              "24997  0.009395  0.014914  0.011239  ...  0.044125  0.032571  0.028406   \n",
              "24998  0.009395  0.014914  0.011239  ...  0.044125  0.032571  0.028406   \n",
              "24999  0.009395  0.014914  0.011239  ...  0.044125  0.032571  0.028406   \n",
              "\n",
              "        Prob_44   Prob_45   Prob_46   Prob_47   Prob_48   Prob_49   Prob_50  \n",
              "0      0.049733  0.034503  0.038958  0.029779  0.032066  0.022819  0.015901  \n",
              "1      0.049733  0.034503  0.038958  0.029779  0.032066  0.022819  0.015901  \n",
              "2      0.049733  0.034503  0.038958  0.029779  0.032066  0.022819  0.015901  \n",
              "3      0.049733  0.034503  0.038958  0.029779  0.032066  0.022819  0.015901  \n",
              "4      0.049733  0.034503  0.038958  0.029779  0.032066  0.022819  0.015901  \n",
              "...         ...       ...       ...       ...       ...       ...       ...  \n",
              "24995  0.020437  0.046219  0.016794  0.016745  0.040449  0.012979  0.015360  \n",
              "24996  0.020437  0.046219  0.016794  0.016745  0.040449  0.012979  0.015360  \n",
              "24997  0.020437  0.046219  0.016794  0.016745  0.040449  0.012979  0.015360  \n",
              "24998  0.020437  0.046219  0.016794  0.016745  0.040449  0.012979  0.015360  \n",
              "24999  0.020437  0.046219  0.016794  0.016745  0.040449  0.012979  0.015360  \n",
              "\n",
              "[25000 rows x 50 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "def calculate_delta(params: np.array, prod_data: pd.DataFrame) -> np.array:\n",
        "    bar_alpha, bar_beta1, bar_beta2, gamma = params\n",
        "\n",
        "    prod_data['delta'] = bar_alpha*prod_data['price']+bar_beta1*prod_data['sugar']+bar_beta2*prod_data['caffeine'] + gamma\n",
        "\n",
        "    return prod_data['delta'].values\n",
        "\n",
        "\n",
        "params = np.array([-1, 0.5, 0.5, -1.5])\n",
        "theta1 = np.array([0, 0, 0])\n",
        "theta2 = np.array([0, 1, 1])\n",
        "\n",
        "estimation1 = pd.DataFrame()\n",
        "estimation2 = pd.DataFrame()\n",
        "\n",
        "for i in range(1, 51):\n",
        "    delta = calculate_delta(params, market_data[market_data.t == i])\n",
        "\n",
        "    estimation1 = pd.concat([estimation1, calculate_indiv_choice_prob(delta, theta1, simulated_consumer[simulated_consumer.t == i], market_data[market_data.t == i])])\n",
        "    estimation2 = pd.concat([estimation2, calculate_indiv_choice_prob(delta, theta2, simulated_consumer[simulated_consumer.t == i], market_data[market_data.t == i])])\n",
        "\n",
        "estimation1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90ragZyZTpu6",
        "outputId": "dd247029-49f9-4443-eb5a-d31621b16b7a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Prob_1</th>\n",
              "      <th>Prob_2</th>\n",
              "      <th>Prob_3</th>\n",
              "      <th>Prob_4</th>\n",
              "      <th>Prob_5</th>\n",
              "      <th>Prob_6</th>\n",
              "      <th>Prob_7</th>\n",
              "      <th>Prob_8</th>\n",
              "      <th>Prob_9</th>\n",
              "      <th>Prob_10</th>\n",
              "      <th>...</th>\n",
              "      <th>Prob_41</th>\n",
              "      <th>Prob_42</th>\n",
              "      <th>Prob_43</th>\n",
              "      <th>Prob_44</th>\n",
              "      <th>Prob_45</th>\n",
              "      <th>Prob_46</th>\n",
              "      <th>Prob_47</th>\n",
              "      <th>Prob_48</th>\n",
              "      <th>Prob_49</th>\n",
              "      <th>Prob_50</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9.481767e-07</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>1.304996e-04</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>9.518978e-08</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>6.289774e-05</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>...</td>\n",
              "      <td>4.799781e-03</td>\n",
              "      <td>4.698196e-05</td>\n",
              "      <td>2.790341e-03</td>\n",
              "      <td>1.314967e-01</td>\n",
              "      <td>3.656440e-03</td>\n",
              "      <td>4.231553e-01</td>\n",
              "      <td>0.000815</td>\n",
              "      <td>1.494974e-03</td>\n",
              "      <td>0.009421</td>\n",
              "      <td>1.753159e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.219858e-02</td>\n",
              "      <td>0.018125</td>\n",
              "      <td>0.021085</td>\n",
              "      <td>1.632048e-02</td>\n",
              "      <td>0.018327</td>\n",
              "      <td>6.429871e-02</td>\n",
              "      <td>0.029183</td>\n",
              "      <td>0.033798</td>\n",
              "      <td>1.641691e-02</td>\n",
              "      <td>0.014824</td>\n",
              "      <td>...</td>\n",
              "      <td>9.669341e-03</td>\n",
              "      <td>1.871244e-02</td>\n",
              "      <td>1.051951e-02</td>\n",
              "      <td>5.222534e-03</td>\n",
              "      <td>8.238249e-03</td>\n",
              "      <td>3.717767e-03</td>\n",
              "      <td>0.012481</td>\n",
              "      <td>1.171316e-02</td>\n",
              "      <td>0.008167</td>\n",
              "      <td>1.047164e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.427066e-03</td>\n",
              "      <td>0.004374</td>\n",
              "      <td>0.007460</td>\n",
              "      <td>9.053870e-03</td>\n",
              "      <td>0.010160</td>\n",
              "      <td>2.835338e-03</td>\n",
              "      <td>0.003561</td>\n",
              "      <td>0.001740</td>\n",
              "      <td>6.835791e-03</td>\n",
              "      <td>0.005941</td>\n",
              "      <td>...</td>\n",
              "      <td>5.487379e-03</td>\n",
              "      <td>3.976754e-03</td>\n",
              "      <td>6.960281e-03</td>\n",
              "      <td>2.023498e-03</td>\n",
              "      <td>1.628341e-03</td>\n",
              "      <td>2.733385e-03</td>\n",
              "      <td>0.002464</td>\n",
              "      <td>2.580688e-03</td>\n",
              "      <td>0.005708</td>\n",
              "      <td>7.916284e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.993477e-02</td>\n",
              "      <td>0.007628</td>\n",
              "      <td>0.019881</td>\n",
              "      <td>1.172298e-02</td>\n",
              "      <td>0.023395</td>\n",
              "      <td>3.676733e-02</td>\n",
              "      <td>0.016814</td>\n",
              "      <td>0.010035</td>\n",
              "      <td>1.085307e-02</td>\n",
              "      <td>0.008457</td>\n",
              "      <td>...</td>\n",
              "      <td>2.631320e-03</td>\n",
              "      <td>7.449502e-03</td>\n",
              "      <td>3.823312e-03</td>\n",
              "      <td>3.919912e-04</td>\n",
              "      <td>8.866834e-04</td>\n",
              "      <td>3.468392e-04</td>\n",
              "      <td>0.002126</td>\n",
              "      <td>1.875965e-03</td>\n",
              "      <td>0.002192</td>\n",
              "      <td>4.795282e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.775084e-04</td>\n",
              "      <td>0.002348</td>\n",
              "      <td>0.000470</td>\n",
              "      <td>1.623042e-03</td>\n",
              "      <td>0.000340</td>\n",
              "      <td>2.409619e-04</td>\n",
              "      <td>0.000522</td>\n",
              "      <td>0.001093</td>\n",
              "      <td>1.330592e-03</td>\n",
              "      <td>0.001741</td>\n",
              "      <td>...</td>\n",
              "      <td>1.695993e-02</td>\n",
              "      <td>2.339526e-03</td>\n",
              "      <td>1.006614e-02</td>\n",
              "      <td>2.174532e-01</td>\n",
              "      <td>4.195573e-02</td>\n",
              "      <td>2.224850e-01</td>\n",
              "      <td>0.016600</td>\n",
              "      <td>2.212891e-02</td>\n",
              "      <td>0.020641</td>\n",
              "      <td>6.279948e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24995</th>\n",
              "      <td>1.517968e-05</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>9.138470e-07</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>8.827298e-05</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>1.863703e-07</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>...</td>\n",
              "      <td>2.756517e-09</td>\n",
              "      <td>2.643435e-08</td>\n",
              "      <td>1.043556e-07</td>\n",
              "      <td>3.910582e-07</td>\n",
              "      <td>3.338714e-09</td>\n",
              "      <td>1.207973e-07</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>7.286007e-08</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>7.606610e-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24996</th>\n",
              "      <td>8.176602e-03</td>\n",
              "      <td>0.025262</td>\n",
              "      <td>0.014461</td>\n",
              "      <td>1.098348e-02</td>\n",
              "      <td>0.050706</td>\n",
              "      <td>1.012722e-02</td>\n",
              "      <td>0.043539</td>\n",
              "      <td>0.007240</td>\n",
              "      <td>6.239207e-02</td>\n",
              "      <td>0.044021</td>\n",
              "      <td>...</td>\n",
              "      <td>2.711065e-03</td>\n",
              "      <td>2.645724e-03</td>\n",
              "      <td>1.642079e-03</td>\n",
              "      <td>8.155743e-03</td>\n",
              "      <td>6.358945e-03</td>\n",
              "      <td>9.866453e-03</td>\n",
              "      <td>0.003968</td>\n",
              "      <td>2.670280e-04</td>\n",
              "      <td>0.003542</td>\n",
              "      <td>5.548271e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24997</th>\n",
              "      <td>1.364514e-04</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>1.531100e-05</td>\n",
              "      <td>0.000381</td>\n",
              "      <td>6.265511e-04</td>\n",
              "      <td>0.000156</td>\n",
              "      <td>0.000247</td>\n",
              "      <td>1.113264e-05</td>\n",
              "      <td>0.000044</td>\n",
              "      <td>...</td>\n",
              "      <td>6.447523e-08</td>\n",
              "      <td>3.918095e-07</td>\n",
              "      <td>9.113588e-07</td>\n",
              "      <td>6.289079e-06</td>\n",
              "      <td>1.144191e-07</td>\n",
              "      <td>2.982211e-06</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>2.454040e-07</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>9.300956e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24998</th>\n",
              "      <td>3.441870e-04</td>\n",
              "      <td>0.000665</td>\n",
              "      <td>0.000889</td>\n",
              "      <td>2.393128e-03</td>\n",
              "      <td>0.000262</td>\n",
              "      <td>1.247085e-04</td>\n",
              "      <td>0.000380</td>\n",
              "      <td>0.000348</td>\n",
              "      <td>2.764109e-03</td>\n",
              "      <td>0.000995</td>\n",
              "      <td>...</td>\n",
              "      <td>1.286722e-01</td>\n",
              "      <td>3.703463e-02</td>\n",
              "      <td>2.075068e-02</td>\n",
              "      <td>5.516682e-03</td>\n",
              "      <td>1.071923e-01</td>\n",
              "      <td>5.819204e-03</td>\n",
              "      <td>0.002571</td>\n",
              "      <td>6.111626e-02</td>\n",
              "      <td>0.001348</td>\n",
              "      <td>3.059243e-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24999</th>\n",
              "      <td>8.574476e-03</td>\n",
              "      <td>0.006385</td>\n",
              "      <td>0.006810</td>\n",
              "      <td>3.955907e-03</td>\n",
              "      <td>0.018581</td>\n",
              "      <td>1.693287e-02</td>\n",
              "      <td>0.011678</td>\n",
              "      <td>0.012171</td>\n",
              "      <td>4.177665e-03</td>\n",
              "      <td>0.006985</td>\n",
              "      <td>...</td>\n",
              "      <td>3.496512e-04</td>\n",
              "      <td>7.478524e-04</td>\n",
              "      <td>1.009830e-03</td>\n",
              "      <td>2.780454e-03</td>\n",
              "      <td>5.232547e-04</td>\n",
              "      <td>1.832025e-03</td>\n",
              "      <td>0.003933</td>\n",
              "      <td>4.880299e-04</td>\n",
              "      <td>0.004755</td>\n",
              "      <td>2.872912e-03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows × 50 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Prob_1    Prob_2    Prob_3        Prob_4    Prob_5        Prob_6  \\\n",
              "0      9.481767e-07  0.000058  0.000010  1.304996e-04  0.000013  9.518978e-08   \n",
              "1      3.219858e-02  0.018125  0.021085  1.632048e-02  0.018327  6.429871e-02   \n",
              "2      3.427066e-03  0.004374  0.007460  9.053870e-03  0.010160  2.835338e-03   \n",
              "3      1.993477e-02  0.007628  0.019881  1.172298e-02  0.023395  3.676733e-02   \n",
              "4      3.775084e-04  0.002348  0.000470  1.623042e-03  0.000340  2.409619e-04   \n",
              "...             ...       ...       ...           ...       ...           ...   \n",
              "24995  1.517968e-05  0.000002  0.000004  9.138470e-07  0.000018  8.827298e-05   \n",
              "24996  8.176602e-03  0.025262  0.014461  1.098348e-02  0.050706  1.012722e-02   \n",
              "24997  1.364514e-04  0.000050  0.000055  1.531100e-05  0.000381  6.265511e-04   \n",
              "24998  3.441870e-04  0.000665  0.000889  2.393128e-03  0.000262  1.247085e-04   \n",
              "24999  8.574476e-03  0.006385  0.006810  3.955907e-03  0.018581  1.693287e-02   \n",
              "\n",
              "         Prob_7    Prob_8        Prob_9   Prob_10  ...       Prob_41  \\\n",
              "0      0.000002  0.000001  6.289774e-05  0.000091  ...  4.799781e-03   \n",
              "1      0.029183  0.033798  1.641691e-02  0.014824  ...  9.669341e-03   \n",
              "2      0.003561  0.001740  6.835791e-03  0.005941  ...  5.487379e-03   \n",
              "3      0.016814  0.010035  1.085307e-02  0.008457  ...  2.631320e-03   \n",
              "4      0.000522  0.001093  1.330592e-03  0.001741  ...  1.695993e-02   \n",
              "...         ...       ...           ...       ...  ...           ...   \n",
              "24995  0.000006  0.000038  1.863703e-07  0.000001  ...  2.756517e-09   \n",
              "24996  0.043539  0.007240  6.239207e-02  0.044021  ...  2.711065e-03   \n",
              "24997  0.000156  0.000247  1.113264e-05  0.000044  ...  6.447523e-08   \n",
              "24998  0.000380  0.000348  2.764109e-03  0.000995  ...  1.286722e-01   \n",
              "24999  0.011678  0.012171  4.177665e-03  0.006985  ...  3.496512e-04   \n",
              "\n",
              "            Prob_42       Prob_43       Prob_44       Prob_45       Prob_46  \\\n",
              "0      4.698196e-05  2.790341e-03  1.314967e-01  3.656440e-03  4.231553e-01   \n",
              "1      1.871244e-02  1.051951e-02  5.222534e-03  8.238249e-03  3.717767e-03   \n",
              "2      3.976754e-03  6.960281e-03  2.023498e-03  1.628341e-03  2.733385e-03   \n",
              "3      7.449502e-03  3.823312e-03  3.919912e-04  8.866834e-04  3.468392e-04   \n",
              "4      2.339526e-03  1.006614e-02  2.174532e-01  4.195573e-02  2.224850e-01   \n",
              "...             ...           ...           ...           ...           ...   \n",
              "24995  2.643435e-08  1.043556e-07  3.910582e-07  3.338714e-09  1.207973e-07   \n",
              "24996  2.645724e-03  1.642079e-03  8.155743e-03  6.358945e-03  9.866453e-03   \n",
              "24997  3.918095e-07  9.113588e-07  6.289079e-06  1.144191e-07  2.982211e-06   \n",
              "24998  3.703463e-02  2.075068e-02  5.516682e-03  1.071923e-01  5.819204e-03   \n",
              "24999  7.478524e-04  1.009830e-03  2.780454e-03  5.232547e-04  1.832025e-03   \n",
              "\n",
              "        Prob_47       Prob_48   Prob_49       Prob_50  \n",
              "0      0.000815  1.494974e-03  0.009421  1.753159e-03  \n",
              "1      0.012481  1.171316e-02  0.008167  1.047164e-02  \n",
              "2      0.002464  2.580688e-03  0.005708  7.916284e-03  \n",
              "3      0.002126  1.875965e-03  0.002192  4.795282e-03  \n",
              "4      0.016600  2.212891e-02  0.020641  6.279948e-03  \n",
              "...         ...           ...       ...           ...  \n",
              "24995  0.000002  7.286007e-08  0.000005  7.606610e-07  \n",
              "24996  0.003968  2.670280e-04  0.003542  5.548271e-03  \n",
              "24997  0.000018  2.454040e-07  0.000033  9.300956e-06  \n",
              "24998  0.002571  6.111626e-02  0.001348  3.059243e-03  \n",
              "24999  0.003933  4.880299e-04  0.004755  2.872912e-03  \n",
              "\n",
              "[25000 rows x 50 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "estimation2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2-BcQk1Tpu6"
      },
      "source": [
        "# 1(e). estimate market share\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZwB9KwnTpu6",
        "outputId": "0524633e-1a19-4a42-c862-19fc8ba7fed3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_ID</th>\n",
              "      <th>price</th>\n",
              "      <th>sugar</th>\n",
              "      <th>caffeine</th>\n",
              "      <th>corn_syrup_price</th>\n",
              "      <th>caffeine_extract_price</th>\n",
              "      <th>quantity</th>\n",
              "      <th>t</th>\n",
              "      <th>market_share</th>\n",
              "      <th>estimated_market_share</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2.021334</td>\n",
              "      <td>1.580856</td>\n",
              "      <td>6.074459</td>\n",
              "      <td>0.199022</td>\n",
              "      <td>0.264899</td>\n",
              "      <td>223</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0223</td>\n",
              "      <td>0.011505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.980251</td>\n",
              "      <td>3.033151</td>\n",
              "      <td>5.260598</td>\n",
              "      <td>0.199022</td>\n",
              "      <td>0.264899</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0039</td>\n",
              "      <td>0.006248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.655560</td>\n",
              "      <td>1.718876</td>\n",
              "      <td>4.685728</td>\n",
              "      <td>0.199022</td>\n",
              "      <td>0.264899</td>\n",
              "      <td>83</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0083</td>\n",
              "      <td>0.005534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.566470</td>\n",
              "      <td>2.637858</td>\n",
              "      <td>4.250370</td>\n",
              "      <td>0.199022</td>\n",
              "      <td>0.264899</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0016</td>\n",
              "      <td>0.005016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.517629</td>\n",
              "      <td>1.476214</td>\n",
              "      <td>4.137802</td>\n",
              "      <td>0.199022</td>\n",
              "      <td>0.264899</td>\n",
              "      <td>141</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0141</td>\n",
              "      <td>0.005074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2495</th>\n",
              "      <td>46</td>\n",
              "      <td>2.368628</td>\n",
              "      <td>3.699026</td>\n",
              "      <td>5.598460</td>\n",
              "      <td>0.210564</td>\n",
              "      <td>0.255062</td>\n",
              "      <td>252</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0252</td>\n",
              "      <td>0.005890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2496</th>\n",
              "      <td>47</td>\n",
              "      <td>1.719465</td>\n",
              "      <td>4.031755</td>\n",
              "      <td>3.961574</td>\n",
              "      <td>0.210564</td>\n",
              "      <td>0.255062</td>\n",
              "      <td>12</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0012</td>\n",
              "      <td>0.005546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2497</th>\n",
              "      <td>48</td>\n",
              "      <td>2.529186</td>\n",
              "      <td>7.770437</td>\n",
              "      <td>3.606250</td>\n",
              "      <td>0.210564</td>\n",
              "      <td>0.255062</td>\n",
              "      <td>1158</td>\n",
              "      <td>50</td>\n",
              "      <td>0.1158</td>\n",
              "      <td>0.103717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>49</td>\n",
              "      <td>1.674552</td>\n",
              "      <td>3.751779</td>\n",
              "      <td>3.642175</td>\n",
              "      <td>0.210564</td>\n",
              "      <td>0.255062</td>\n",
              "      <td>30</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.004842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2499</th>\n",
              "      <td>50</td>\n",
              "      <td>2.017268</td>\n",
              "      <td>3.825394</td>\n",
              "      <td>4.590952</td>\n",
              "      <td>0.210564</td>\n",
              "      <td>0.255062</td>\n",
              "      <td>63</td>\n",
              "      <td>50</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.004616</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2500 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      product_ID     price     sugar  caffeine  corn_syrup_price  \\\n",
              "0              1  2.021334  1.580856  6.074459          0.199022   \n",
              "1              2  1.980251  3.033151  5.260598          0.199022   \n",
              "2              3  1.655560  1.718876  4.685728          0.199022   \n",
              "3              4  1.566470  2.637858  4.250370          0.199022   \n",
              "4              5  1.517629  1.476214  4.137802          0.199022   \n",
              "...          ...       ...       ...       ...               ...   \n",
              "2495          46  2.368628  3.699026  5.598460          0.210564   \n",
              "2496          47  1.719465  4.031755  3.961574          0.210564   \n",
              "2497          48  2.529186  7.770437  3.606250          0.210564   \n",
              "2498          49  1.674552  3.751779  3.642175          0.210564   \n",
              "2499          50  2.017268  3.825394  4.590952          0.210564   \n",
              "\n",
              "      caffeine_extract_price  quantity   t  market_share  \\\n",
              "0                   0.264899       223   1        0.0223   \n",
              "1                   0.264899        39   1        0.0039   \n",
              "2                   0.264899        83   1        0.0083   \n",
              "3                   0.264899        16   1        0.0016   \n",
              "4                   0.264899       141   1        0.0141   \n",
              "...                      ...       ...  ..           ...   \n",
              "2495                0.255062       252  50        0.0252   \n",
              "2496                0.255062        12  50        0.0012   \n",
              "2497                0.255062      1158  50        0.1158   \n",
              "2498                0.255062        30  50        0.0030   \n",
              "2499                0.255062        63  50        0.0063   \n",
              "\n",
              "      estimated_market_share  \n",
              "0                   0.011505  \n",
              "1                   0.006248  \n",
              "2                   0.005534  \n",
              "3                   0.005016  \n",
              "4                   0.005074  \n",
              "...                      ...  \n",
              "2495                0.005890  \n",
              "2496                0.005546  \n",
              "2497                0.103717  \n",
              "2498                0.004842  \n",
              "2499                0.004616  \n",
              "\n",
              "[2500 rows x 10 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def estimated_share(delta:np.array, theta:np.array, cons_data: pd.DataFrame, prod_data: pd.DataFrame) -> np.array:\n",
        "\n",
        "    return calculate_indiv_choice_prob(delta, theta, cons_data, prod_data).mean(axis = 0).values\n",
        "\n",
        "params = np.array([-1, 0.5, 0.5, -1.5])\n",
        "theta2 = np.array([0, 1, 1])\n",
        "\n",
        "estimation = pd.DataFrame()\n",
        "\n",
        "for j in range(1, 51):\n",
        "    delta = calculate_delta(params, market_data[market_data.t == j])\n",
        "    temp = market_data[market_data.t == j].copy()\n",
        "    temp['estimated_market_share'] = estimated_share(delta, theta2, simulated_consumer[simulated_consumer.t == j], market_data[market_data.t == j])\n",
        "    estimation = pd.concat([estimation, temp])\n",
        "estimation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p5CBU1WUTpu7",
        "outputId": "3a887389-b815-40ec-d0b8-c54d390301ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   estimated_income_mean  estimated_weighted_price\n",
            "t                                                 \n",
            "1               6.019233                  0.037948\n",
            "2               4.586257                  0.035876\n",
            "3               5.960620                  0.039291\n",
            "4               4.426046                  0.039019\n",
            "5               4.423433                  0.041452\n",
            "The correlation between estimated mean income and average price among markets is 0.0685560918680415\n"
          ]
        }
      ],
      "source": [
        "estimated_income_price = pd.DataFrame()\n",
        "estimated_income_price['estimated_income_mean'] = simulated_consumer.groupby('t')['income'].mean()\n",
        "\n",
        "estimation['estimated_weighted_price'] = estimation['estimated_market_share']*estimation['price']\n",
        "estimated_income_price['estimated_weighted_price'] = estimation.groupby('t')['estimated_weighted_price'].mean()\n",
        "\n",
        "print(estimated_income_price.head(5))\n",
        "\n",
        "corr = estimated_income_price['estimated_income_mean'].corr(estimated_income_price['estimated_weighted_price'])\n",
        "\n",
        "print(f'The correlation between estimated mean income and average price among markets is {corr}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ7C20MlTpu7"
      },
      "source": [
        "# 2(a). Solve  δ  by contraction mapping with sample size 100\n",
        "\n",
        "This line updates the δ values using the contraction mapping equation: \\\n",
        "  $ \\delta^{new}_{jt} = \\delta_{jt} + log(s^{obs}_{jt}) - log(s^{est}_{jt})$ \\\n",
        "This equation adjusts the values to minimize the difference between observed and estimated shares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHIOiFhATpu7"
      },
      "outputs": [],
      "source": [
        "#1. Function Definition:\n",
        "# The function solve_delta implements an iterative procedure, known as the contraction mapping, to solve for the mean utility values (δ)\n",
        "# that match the observed market shares with the estimated shares based on a discrete choice model.\n",
        "# A tolerance level for convergence (default value is 1e-4). It determines how close the new and old values of δ need to be before the function stops iterating.\n",
        "def solve_delta(theta:np.array, delta:np.array, cons_data:pd.DataFrame, prod_data:pd.DataFrame, tol=1e-4)->np.array:\n",
        "    error = 1\n",
        "\n",
        "    while error>tol:\n",
        "        new_delta = delta+np.log(prod_data['market_share'].values)-np.log(estimated_share(delta, theta, cons_data, prod_data))\n",
        "        error = np.linalg.norm(new_delta-delta)\n",
        "        delta = new_delta\n",
        "\n",
        "    return delta\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_spn-ZRpTpu7"
      },
      "source": [
        "The code provided simulates and estimates the distribution of the  δ1  value (mean utility for the first product) across 100 different simulations, using the solve_delta function and parallel processing for efficiency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiLZ0h8vTpu7",
        "outputId": "95c1aa5e-9f0e-45d8-b81f-c49521cdc04d"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample mean of delta_1 is 2.94702849054161 and sample variance is 0.7348973737689057\n",
            "CPU times: total: 734 ms\n",
            "Wall time: 32.8 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Initializing delta\n",
        "'''\n",
        "Given that update_delta is a contraction mapping, any initial guess would not effect the convergence result after sufficient number of update.\n",
        "\n",
        "'''\n",
        "\n",
        "theta = np.array([0, 1, 1])\n",
        "\n",
        "deltas = Parallel(n_jobs=-1, backend='loky')(delayed(solve_delta)(theta, np.array(50*[1]), gen_consumer(1, 100, t), market_data[market_data.t == 1]) for t in range(100))\n",
        "\n",
        "delta_0s = [deltas[i][0] for i in range(100)]\n",
        "plt.hist(delta_0s, bins = 50, density = True)\n",
        "plt.title('distribution of delta_1 when the sample size is 100')\n",
        "plt.show()\n",
        "print(f'sample mean of delta_1 is {np.mean(np.array(delta_0s))} and sample variance is {np.var(np.array(delta_0s))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2(b) sample size 500\n",
        "\n",
        "It uses a sample size of 500 consumers per simulation (instead of 100), to estimate the distribution of the $ 𝛿_{1} $ value across 100 different simulations."
      ],
      "metadata": {
        "id": "GSFyxWaIU2pi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJV7rI7PTpu7",
        "outputId": "7ce31219-fb26-43d9-b0a5-89643ce9eddb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sample mean of delta_1 is 2.8061515913204587 and sample variance is 0.17705003977501083\n",
            "CPU times: total: 578 ms\n",
            "Wall time: 33.1 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Initializing delta\n",
        "'''\n",
        "Given that update_delta is a contraction mapping, any initial guess would not effect the convergence result after sufficient number of update.\n",
        "\n",
        "'''\n",
        "\n",
        "theta = np.array([0, 1, 1])\n",
        "\n",
        "deltas = Parallel(n_jobs=-1, backend='loky')(delayed(solve_delta)(theta, np.array(50*[1]), gen_consumer(1, 500, t), market_data[market_data.t == 1]) for t in range(100))\n",
        "\n",
        "delta_0s = [deltas[i][0] for i in range(100)]\n",
        "plt.hist(delta_0s, bins = 50, density = True)\n",
        "plt.title('distribution of delta_1 when the sample size is 500')\n",
        "plt.show()\n",
        "print(f'sample mean of delta_1 is {np.mean(np.array(delta_0s))} and sample variance is {np.var(np.array(delta_0s))}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2zm-JaKTpu7"
      },
      "source": [
        "# 3(a)\n",
        "The code provided for Problem 3(a) involves creating instruments for a regression model using instrumental variables (IV) and calculating the necessary matrices for IV estimation. The code applies Ordinary Least Squares (OLS) to estimate predicted prices ( p̂  ) and constructs instrument matrices for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVrlW628Tpu7"
      },
      "outputs": [],
      "source": [
        "def IV_caffeine(row):\n",
        "    t, caf = row['t'], row['caffeine']\n",
        "    temp = Market_data[Market_data.t == t]\n",
        "    temp['square'] = Market_data['caffeine'].apply(lambda x: (x-caf)**2)\n",
        "\n",
        "    return temp[['square']].sum()\n",
        "\n",
        "def IV_sugar(row):\n",
        "    t, sug = row['t'], row['sugar']\n",
        "    temp = Market_data[Market_data.t == t]\n",
        "    temp['square'] = Market_data['sugar'].apply(lambda x: (x-sug)**2)\n",
        "\n",
        "    return temp[['square']].sum()\n",
        "\n",
        "Market_data = market_data.copy()\n",
        "\n",
        "Market_data['IV_sugar'], Market_data['IV_caffeine'] = Market_data['corn_syrup_price']*Market_data['sugar'], Market_data['caffeine_extract_price']*Market_data['caffeine']\n",
        "X = sm.add_constant(Market_data[['IV_sugar', 'IV_caffeine']].values)\n",
        "model = sm.OLS(Market_data['price'].values, X)\n",
        "results = model.fit()\n",
        "Market_data['p_hat'] = results.predict(X)\n",
        "Market_data = pd.merge(Market_data, demo_data.groupby('t').mean()[['income']], on = 't', how = 'left')\n",
        "Market_data['p_hat_mean_income'] = Market_data['p_hat']*Market_data['income']\n",
        "Market_data['caffeine_squaresum'] = Market_data.apply(IV_caffeine, axis = 1)\n",
        "Market_data['sugar_squaresum'] = Market_data.apply(IV_sugar, axis = 1)\n",
        "\n",
        "X = sm.add_constant(Market_data[['price', 'sugar', 'caffeine']].values)\n",
        "Z = sm.add_constant(Market_data[['sugar', 'caffeine', 'p_hat', 'p_hat_mean_income', 'caffeine_squaresum', 'sugar_squaresum']].values) # Instrument matrix\n",
        "W = np.linalg.inv(Z.T@Z/2500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3Q-IdKBTpu7"
      },
      "source": [
        "# 3(b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f0pDEbtSTpu8"
      },
      "outputs": [],
      "source": [
        "#generate 10000 consumers form each market\n",
        "\n",
        "simulated_consumer = pd.DataFrame()\n",
        "\n",
        "for i in range(1, 51):\n",
        "    temp = gen_consumer(i, 10000, i)\n",
        "    temp = temp.drop(columns=['consumer_ID'])\n",
        "    simulated_consumer = pd.concat([simulated_consumer, temp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S4sNXazTpu8",
        "outputId": "3f41a7ea-d28d-4d6f-c853-fa14f1079c7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The value of q(theta) evaluated at (-.5, 2, 2) is 25.7088346721915\n",
            "CPU times: total: 2.73 s\n",
            "Wall time: 3min 32s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "def GMM(theta:np.array)->float:\n",
        "    global GMM_deltas, alpha, beta1, beta2, gamma\n",
        "\n",
        "    try:\n",
        "        GMM_deltas = Parallel(n_jobs=-1, backend='loky')(delayed(solve_delta)(theta, GMM_deltas[t-1], simulated_consumer[simulated_consumer.t == t], market_data[market_data.t == t]) for t in range(1, 51))\n",
        "    except:\n",
        "        GMM_deltas = Parallel(n_jobs=-1, backend='loky')(delayed(solve_delta)(theta, np.array(50*[1]), simulated_consumer[simulated_consumer.t == t], market_data[market_data.t == t]) for t in range(1, 51))\n",
        "\n",
        "\n",
        "    long_GMM_deltas = np.concatenate(GMM_deltas)\n",
        "    alpha, beta1, beta2, gamma = np.linalg.inv(X.T@Z@W@Z.T@X)@(X.T@Z@W@Z.T@long_GMM_deltas)\n",
        "    temp_market = Market_data[['price', 'sugar', 'caffeine']].copy()\n",
        "    temp_market['xi_hat'] = long_GMM_deltas - temp_market['price'].multiply(alpha) - temp_market['sugar'].multiply(beta1) - temp_market['caffeine'].multiply(beta2)-gamma\n",
        "\n",
        "    return (Z.T@temp_market['xi_hat'].values/2500).T@W@(Z.T@temp_market['xi_hat'].values/2500)\n",
        "\n",
        "print(f'The value of q(theta) evaluated at (-.5, 2, 2) is {GMM(np.array([-.5, 2, 2]))}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5_r5bIOTpu8"
      },
      "source": [
        "# 3(c). compute the analytical gradient of the GMM objective function\n",
        "\n",
        "To calculate the analystic derivative, we have to calculate certain drivatives. For expositional purposes, I drop $t$, the time index.\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\hat{s}_i}{\\partial \\delta_i} = \\hat{s}_i(1-\\hat{s}_i)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\hat{s}_i}{\\partial \\delta_j} = -\\hat{s}_i \\hat{s}_j\n",
        "$$\n",
        "\n",
        "and for $\\kappa \\in \\{\\alpha, \\sigma_1, \\sigma_2\\}$,\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\hat{s}_j}{\\partial \\kappa} = \\frac{1}{cons\\_ pop}\\sum_i\\left( \\frac{\\partial\\mu_{ij}}{\\partial \\kappa} P_{ij} -P_{ij}\\sum_{j'} P_{ij'} \\frac{\\partial \\mu_{ij'}}{\\partial \\kappa} \\right)\n",
        "$$\n",
        "\n",
        "where $P_{ij}$ is the probability of consumer $i$ choosing $j$.\n",
        "\n",
        "and The partial derivatives of $ μ_{ij} $ with respect to the parameters ($ α, σ_{1}, \\sigma_{2}$) are:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial\\mu_{ij}}{\\partial \\alpha} = p_jy_{i},~\\frac{\\partial\\mu_{ij}}{\\partial \\sigma_1} = sug_j\\nu_{i1},~\\frac{\\partial\\mu_{ij}}{\\partial \\sigma_2}=caf_j\\nu_{i2}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8fYLwLkTpu8",
        "outputId": "06ac814d-b08a-42ca-b00b-7f957ea76d80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Analytic derivative calculated at (-.5, 2, 2) is [-17.43676975   2.69449155   7.88585598]\n"
          ]
        }
      ],
      "source": [
        "def Analytic_derivative(theta:np.array)->np.array:\n",
        "\n",
        "    GMM(theta) # to retrive delta\n",
        "\n",
        "    long_GMM_deltas = np.concatenate(GMM_deltas)\n",
        "    alpha, beta1, beta2, gamma = np.linalg.inv(X.T@Z@W@Z.T@X)@(X.T@Z@W@Z.T@long_GMM_deltas)\n",
        "    temp_market = Market_data[['price', 'sugar', 'caffeine']].copy()\n",
        "    temp_market['xi_hat'] = long_GMM_deltas - temp_market['price'].multiply(alpha) - temp_market['sugar'].multiply(beta1) - temp_market['caffeine'].multiply(beta2)-gamma\n",
        "\n",
        "\n",
        "    temp = pd.DataFrame()\n",
        "\n",
        "    share_labels = ['Prob_'+str(j) for j in range(1, 51)]\n",
        "    temp_income_price_labels = ['Temp_Income_Price_'+str(j) for j in range(1, 51)]\n",
        "    temp_sug_nu1_labels = ['Temp_Sug_Nu1_'+str(j) for j in range(1, 51)]\n",
        "    temp_caf_nu2_labels = ['Temp_Caf_Nu2_'+str(j) for j in range(1, 51)]\n",
        "\n",
        "    income_price_labels = ['Income_Price_'+str(j) for j in range(1, 51)]\n",
        "    sug_nu1_labels = ['Sug_Nu1_'+str(j) for j in range(1, 51)]\n",
        "    caf_nu2_labels = ['Caf_Nu2_'+str(j) for j in range(1, 51)]\n",
        "\n",
        "    for t in range(1, 51):\n",
        "\n",
        "        length = len(simulated_consumer[simulated_consumer.t == t])\n",
        "\n",
        "        period_share = estimated_share(GMM_deltas[t-1], theta, simulated_consumer[simulated_consumer.t == t], market_data[market_data.t == t])\n",
        "        S_matrix = -period_share.reshape(50, 1)@period_share.reshape(50, 1).T + np.diag(period_share)\n",
        "\n",
        "        temp = pd.concat([simulated_consumer[simulated_consumer.t == t], calculate_indiv_choice_prob(GMM_deltas[t-1], theta, simulated_consumer[simulated_consumer.t == t], market_data[market_data.t == t])], axis = 1)\n",
        "\n",
        "        temp_income_price = temp[['income']].values*market_data[market_data.t == 1][['price']].values.T\n",
        "        temp[temp_income_price_labels] = np.multiply(temp[share_labels].values, temp_income_price)\n",
        "\n",
        "        temp_sug_nu1 = temp[['nu_1']].values*market_data[market_data.t == 1][['sugar']].values.T\n",
        "        temp[temp_sug_nu1_labels] = np.multiply(temp[share_labels].values, temp_sug_nu1)\n",
        "\n",
        "        temp_caf_nu2 = temp[['nu_2']].values*market_data[market_data.t == 1][['caffeine']].values.T\n",
        "        temp[temp_caf_nu2_labels] = np.multiply(temp[share_labels].values, temp_caf_nu2)\n",
        "\n",
        "        sum_income_price, sum_sug_nu1, sum_caf_nu2 = \\\n",
        "            temp[temp_income_price_labels].sum(axis = 1).values.reshape(length, 1), temp[temp_sug_nu1_labels].sum(axis = 1).values.reshape(length, 1), temp[temp_caf_nu2_labels].sum(axis = 1).values.reshape(length, 1)\n",
        "\n",
        "        temp[income_price_labels] = np.multiply(temp[share_labels].values, temp_income_price - sum_income_price)\n",
        "        temp[sug_nu1_labels] = np.multiply(temp[share_labels].values, temp_sug_nu1 - sum_sug_nu1)\n",
        "        temp[caf_nu2_labels] = np.multiply(temp[share_labels].values, temp_caf_nu2 - sum_caf_nu2)\n",
        "\n",
        "        mean_income_price, mean_sug_nu1, mean_caf_nu2 = \\\n",
        "            temp[income_price_labels].mean().values, temp[sug_nu1_labels].mean().values, temp[caf_nu2_labels].mean().values\n",
        "\n",
        "        if t == 1:\n",
        "            result = np.linalg.inv(S_matrix)@np.stack((temp[income_price_labels].mean().values, temp[sug_nu1_labels].mean().values, temp[caf_nu2_labels].mean().values), axis = 1)\n",
        "        else:\n",
        "            result = np.vstack((result, np.linalg.inv(S_matrix)@np.stack((temp[income_price_labels].mean().values, temp[sug_nu1_labels].mean().values, temp[caf_nu2_labels].mean().values), axis = 1)))\n",
        "\n",
        "    return 2/2500*(Z.T@result).T@W@(Z.T@temp_market['xi_hat'].values/2500).T\n",
        "\n",
        "\n",
        "print(f'The Analytic derivative calculated at (-.5, 2, 2) is {Analytic_derivative(np.array([-.5, 2, 2]))}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOYh57vZTpu8"
      },
      "source": [
        "theta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGLaMAhtTpu8",
        "outputId": "b77f998e-dd82-410e-b147-f4f4e269fec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "partial derivative with respect to the first argument is -88.58625214730218 when the step size is 0.1\n",
            "partial derivative with respect to the second argument is 9.11373537770963 when the step size is 0.1\n",
            "partial derivative with respect to the thrid argument is 27.004038443488838 when the step size is 0.1\n"
          ]
        }
      ],
      "source": [
        "def Numerical_derivative(theta:np.array, h:float)->np.array:\n",
        "    temp_value = GMM(theta)\n",
        "    return (GMM(theta + np.array([h, 0, 0]))-temp_value)/h, (GMM(theta + np.array([0, h, 0]))-temp_value)/h, (GMM(theta + np.array([0, 0, h]))-temp_value)/h\n",
        "\n",
        "h = .1\n",
        "\n",
        "a, b, c = Numerical_derivative(np.array([-.5, 2, 2]), h)\n",
        "\n",
        "print(f'partial derivative with respect to the first argument is {a} when the step size is {h}')\n",
        "print(f'partial derivative with respect to the second argument is {b} when the step size is {h}')\n",
        "print(f'partial derivative with respect to the thrid argument is {c} when the step size is {h}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NF6oEo1JTpu8",
        "outputId": "c4203a0f-2d3d-490f-915b-ed816b471c23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Current function value: 1.048891\n",
            "         Iterations: 3\n",
            "         Function evaluations: 24\n",
            "         Gradient evaluations: 12\n",
            "GMM estimation of theta is [-0.27435772  2.32169077  1.00706632]\n",
            "alpha, beta1, beta2, gamma is (0.6412051696774483, 0.8713209093508283, 0.6433588805205304, 0.5640095709331518)\n"
          ]
        }
      ],
      "source": [
        "result = minimize(GMM, np.array([-.5, 2, 2]), method = 'BFGS', jac = Analytic_derivative, options={'xatol': 1e-8, 'disp': True, 'maxiter': 10000})\n",
        "\n",
        "print(f'GMM estimation of theta is {result.x}')\n",
        "print(f'alpha, beta1, beta2, gamma is {alpha, beta1, beta2, gamma}')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ECON512",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}